{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bu3aAcmYaLHl"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "import numpy as np, torch.nn as nn, pandas as pd,\\\n",
    "torch.nn.functional as F, matplotlib.pyplot as plt,\\\n",
    "seaborn as sn\n",
    "import torch, logging, os, re, random, pickle, logging\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, \n",
    "    roc_auc_score, \n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "import argparse\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from src.pipeline import pipeline\n",
    "from src.training_utils import training_utils\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data as tdataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "EXP_HPARAMS = {\n",
    "    \"params\": (\n",
    "        {},\n",
    "    ),\n",
    "    \"seeds\": (3957,),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the comment right before cal_linearAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Kk9mysTT3UZ"
   },
   "outputs": [],
   "source": [
    "class TrainTest():\n",
    "    def __init__(self, model, optimizer, scheduler, criterion):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def train(\n",
    "        self, train_loader,\n",
    "        num_epochs, device, eval_interval,\n",
    "        clip=None, model_path=None, save_per_epoch=None,\n",
    "        results_path=None, defaults=None, **kwargs\n",
    "    ):\n",
    "        total_itrs = num_epochs*len(train_loader)\n",
    "        itr = 0\n",
    "        self.model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (real_imgs, labels) in enumerate(train_loader):\n",
    "                real_imgs, labels = real_imgs.to(device), labels.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(real_imgs)\n",
    "                tr_loss = self.criterion(output, labels.view(-1))\n",
    "                # nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                print(f'Training: {itr}/{total_itrs} -- loss: {tr_loss.item()}')\n",
    "                tr_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                itr += 1\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def save_results(self, results_path, name, results):\n",
    "        results_dir = '/'.join(results_path.split('/')[:-1])\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.makedirs(results_dir)\n",
    "        with open(os.path.join(results_dir, f'results_{name}.pkl'), 'wb') as save_file:\n",
    "            pickle.dump(results, save_file)\n",
    "\n",
    "    def test(self, test_loader, device, all_labels, results_path=None, defaults=None):\n",
    "        true_labels, pred_labels = [], []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (real_imgs, labels) in enumerate(test_loader):\n",
    "                real_imgs, labels = real_imgs.to(device), labels.to(device)\n",
    "                test_output = self.model(real_imgs)\n",
    "                _, temp_pred = test_output.max(dim=1)\n",
    "                true_labels.append(labels.view(-1))\n",
    "                pred_labels.append(temp_pred)\n",
    "        pred_labels = torch.cat(pred_labels).cpu()\n",
    "        true_labels = torch.cat(true_labels).cpu()\n",
    "        test_accuracy = torch.sum(pred_labels == true_labels).item() / true_labels.size()[0]\n",
    "        prf = precision_recall_fscore_support(\n",
    "            true_labels,\n",
    "            pred_labels,\n",
    "            labels=all_labels,\n",
    "            average='weighted'\n",
    "        )\n",
    "        confm = confusion_matrix(true_labels, pred_labels, labels=all_labels)\n",
    "        self.ts_metrics = {\n",
    "            'accuracy':test_accuracy,\n",
    "            'precision':prf[0],\n",
    "            'recall':prf[1],\n",
    "            'f1_score':prf[2],\n",
    "            'confusion_matrix':confm\n",
    "        }\n",
    "        if results_path:\n",
    "            self.save_results(results_path, f'test', self.ts_metrics)\n",
    "\n",
    "class LinearAccuracy(nn.Module):\n",
    "    def __init__(self, encoder, encoder_dim, output_dim):\n",
    "        super(LinearAccuracy, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.linear = nn.Linear(encoder_dim, output_dim)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        gen_latents = self.encoder(imgs)\n",
    "        gen_latents = self.linear(gen_latents)\n",
    "        latent_softmax = F.log_softmax(gen_latents)\n",
    "        return latent_softmax\n",
    "\n",
    "def cal_accuracy(pred_labels, true_labels):\n",
    "    _, pred_labels = pred_labels.max(dim=1)\n",
    "    true_labels = true_labels.view(-1)\n",
    "    return torch.sum(pred_labels == true_labels).item() / true_labels.size()[0]\n",
    "\n",
    "def img_generator(model, dataloader, real_dir, gen_dir):\n",
    "    os.makedirs(real_dir, exist_ok=True)\n",
    "    os.makedirs(gen_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "    counter = 0\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        for i, (real_imgs, labels) in enumerate(dataloader):\n",
    "            labels = labels.to(device)\n",
    "            gen_imgs, noise = model.generate_imgs(cls=labels)\n",
    "            for j in range(gen_imgs.size(0)):\n",
    "                real_path = os.path.join(real_dir, f'real_{counter}.png')\n",
    "                gen_path = os.path.join(gen_dir, f'gen_{counter}.png')\n",
    "                save_image(real_imgs[j], real_path)\n",
    "                save_image(gen_imgs[j], gen_path)\n",
    "                counter += 1\n",
    "\n",
    "def get_loader(data_path, image_size, batch_size, train=False):\n",
    "    dataset = MNIST(\n",
    "        data_path,\n",
    "        download=True,\n",
    "        train=train,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    )\n",
    "    loader = tdataset.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "def run_experiments(data_path, dataset='MNIST', model_architecture='bigbigan',include_sx=True, include_sz=True, include_sxz=True):\n",
    "    for hparams_overwrite_list, seed in itertools.product(EXP_HPARAMS[\"params\"], EXP_HPARAMS[\"seeds\"]):\n",
    "        config = training_utils.get_config(dataset)\n",
    "        hparams_str = \"\"\n",
    "        for k, v in hparams_overwrite_list.items():\n",
    "            config[k] = v\n",
    "            hparams_str += str(k) + \"-\" + str(v) + \"_\"\n",
    "        config[\"model_architecture\"] = model_architecture\n",
    "        config[\"hparams_str\"] = hparams_str.strip(\"_\")\n",
    "        config[\"seed\"] = seed\n",
    "        config['has_sx'] = include_sx\n",
    "        config['has_sz'] = include_sz\n",
    "        config['has_sxz'] = include_sxz\n",
    "        training_utils.set_random_seed(seed=config['seed'], device=config['device'])\n",
    "        training_pipeline = pipeline.BigBiGANPipeline.from_config(data_path=data_path, config=config)\n",
    "        training_pipeline.train_model()\n",
    "        return training_pipeline\n",
    "\n",
    "# This funciton will train a classifier based on BigGiGAN encoder and a linear layer\n",
    "# Set path to train and test files\n",
    "def cal_linearAcc(model):\n",
    "    cuda_flag = True if torch.cuda.is_available() else False\n",
    "    lr = .1\n",
    "    num_epochs = 15\n",
    "    eval_interval = 40\n",
    "    save_model = True\n",
    "    device = torch.device('cuda' if cuda_flag else 'cpu')\n",
    "    encoder = model.encoder\n",
    "    linear_model = LinearAccuracy(encoder, 100, 10).to(device)\n",
    "    for name, p in linear_model.named_parameters():\n",
    "        if \"encoder\" in name:\n",
    "            p.requires_grad = False\n",
    "    optimizer = SGD(linear_model.parameters(), lr=lr, momentum=0.9)\n",
    "    scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    # Set path (directory) to train and test files here (Note: files retrieved from torchvision)\n",
    "    train_loader = get_loader('./mnist/', 32, 256, train=True)\n",
    "    traintest = TrainTest(linear_model, optimizer, scheduler, F.nll_loss)\n",
    "    traintest.train(\n",
    "        train_loader,\n",
    "        num_epochs,\n",
    "        device,\n",
    "        eval_interval,\n",
    "        model_path='./models/',\n",
    "        save_per_epoch=4,\n",
    "        results_path='./results/',\n",
    "        clip=5\n",
    "    )\n",
    "    traintest.test(\n",
    "        test_loader, \n",
    "        device, \n",
    "        list(range(10)),\n",
    "        results_path='./results/'\n",
    "    )\n",
    "    return traintest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose which loss do you want to ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_OzedzEwIKKF",
    "outputId": "e6cb2623-9327-407a-97df-ad71f7dcaeb4"
   },
   "outputs": [],
   "source": [
    "ignore_loss = 1 # include_all = 0, ignore_sx = 1, ignore_sz = 2, ignore_sx_and_sz = 3\n",
    "if ignore_loss == 0:\n",
    "    print('all losses included')\n",
    "    pipline = run_experiments('./mnist/')\n",
    "elif ignore_loss == 1:\n",
    "    print('sx loss ignored')\n",
    "    pipline = run_experiments('./mnist/', include_sx=False)\n",
    "elif ignore_loss == 2:\n",
    "    print('sz loss ignored')\n",
    "    pipline = run_experiments('./mnist/', include_sz=False)\n",
    "elif ignore_loss == 3:\n",
    "    print('sx and sz losses ignored')\n",
    "    pipline = run_experiments('./mnist/', include_sx=False, include_sz=False)\n",
    "else:\n",
    "    print('all losses included')\n",
    "    pipline = run_experiments('./mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9B-0_j35BuPg",
    "outputId": "2f5f828b-7491-4509-9759-9d12d80a004f"
   },
   "outputs": [],
   "source": [
    "model = pipline.model\n",
    "model.eval()\n",
    "# base_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set path (directory) to train and test files here (Note: files retrieved from torchvision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmBmpTy2pvad"
   },
   "outputs": [],
   "source": [
    "test_loader = get_loader('./mnist/', 32, 256, train=False)\n",
    "img_generator(model, test_loader, './real_images/', './gen_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gOvKsMQJ-M5",
    "outputId": "2083c602-edde-4cce-c20c-4eab0483887f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!zip -r /content/sx_gen.zip /content/gen_images\n",
    "!zip -r /content/sx_real.zip /content/real_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AWFUxE1ufvIH",
    "outputId": "ea6e84dd-3d80-4668-be86-b7dc6ee9f2a7"
   },
   "outputs": [],
   "source": [
    "train_tester = cal_linearAcc(model)\n",
    "print(train_tester.ts_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5Zo7rO8l8EE",
    "outputId": "68694951-0d77-4954-9a8b-3978520be354"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PrvhpcTKXSi0",
    "outputId": "f8f32633-57ec-4e71-fd85-94946f7dac44"
   },
   "outputs": [],
   "source": [
    "!python -m pytorch_fid -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set path to images zip files if they are not in a seperate directory. Otherwise, set the direstory path in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43ouVySZUsCA"
   },
   "outputs": [],
   "source": [
    "!unzip sx_gen.zip -d ./sx_gen\n",
    "!unzip sz_gen.zip -d ./sz_gen\n",
    "!unzip sxsz_gen.zip -d ./sxsz_gen\n",
    "!unzip all_gen.zip -d ./all_gen\n",
    "!unzip all_real.zip -d ./all_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRb4GHSkU7rc",
    "outputId": "0519abab-70b3-4903-c9c9-306b44ad6cd4"
   },
   "outputs": [],
   "source": [
    "!python -m pytorch_fid sxsz_gen/content/gen_images/ all_real/content/real_images/ --device cuda:0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set path to saved pickle results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/sxsz_results_test.pkl', 'rb') as results_file:\n",
    "    test_results = pickle.load(results_file)\n",
    "classes = [f'digit: {x}' for x in list(range(10))]\n",
    "plt.figure()\n",
    "test_confm = pd.DataFrame(test_results['confusion_matrix'], classes, classes)\n",
    "sn.set(font_scale=1)\n",
    "sn.heatmap(\n",
    "    test_confm, \n",
    "    annot= False, \n",
    "    annot_kws = {\"size\": 10}\n",
    ")\n",
    "plt.autoscale(True)\n",
    "plt.savefig(os.path.join('./results/', 'sxsz-test-confusion-matrix.png'), dpi=300, bbox_inches=\"tight\")\n",
    "print(f'{\"*\"*20} Test Metrics: {\"*\"*20}\\n'\n",
    "      f'Accuracy: {test_results[\"accuracy\"]:.3f}\\n'\n",
    "      f'Weighted Precision: {test_results[\"precision\"]:.3f}\\n'\n",
    "      f'Weighted Recall: {test_results[\"recall\"]:.3f}\\n'\n",
    "      f'Weighted F1-score: {test_results[\"f1_score\"]:.3f}\\n'\n",
    "      f'{\"*\"*55}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
