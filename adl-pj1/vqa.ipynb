{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path to images zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJMcisX_m37d",
    "outputId": "eea952d5-f441-47c0-fbf7-146114f153a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyu_depth_images/\n",
      "nyu_depth_images/image1.png\n",
      "nyu_depth_images/image10.png\n",
      "nyu_depth_images/image100.png\n",
      "nyu_depth_images/image1000.png\n",
      "nyu_depth_images/image1001.png\n",
      "nyu_depth_images/image1002.png\n",
      "nyu_depth_images/image1003.png\n",
      "nyu_depth_images/image1004.png\n",
      "nyu_depth_images/image1005.png\n",
      "nyu_depth_images/image1006.png\n",
      "nyu_depth_images/image1007.png\n",
      "nyu_depth_images/image1008.png\n",
      "nyu_depth_images/image1009.png\n",
      "nyu_depth_images/image101.png\n",
      "nyu_depth_images/image1010.png\n",
      "nyu_depth_images/image1011.png\n",
      "nyu_depth_images/image1012.png\n",
      "nyu_depth_images/image1013.png\n",
      "nyu_depth_images/image1014.png\n",
      "nyu_depth_images/image1015.png\n",
      "nyu_depth_images/image1016.png\n",
      "nyu_depth_images/image1017.png\n",
      "nyu_depth_images/image1018.png\n",
      "nyu_depth_images/image1019.png\n",
      "nyu_depth_images/image102.png\n",
      "nyu_depth_images/image1020.png\n",
      "nyu_depth_images/image1021.png\n",
      "nyu_depth_images/image1022.png\n",
      "nyu_depth_images/image1023.png\n",
      "nyu_depth_images/image1024.png\n",
      "nyu_depth_images/image1025.png\n",
      "nyu_depth_images/image1026.png\n",
      "nyu_depth_images/image1027.png\n",
      "nyu_depth_images/image1028.png\n",
      "nyu_depth_images/image1029.png\n",
      "nyu_depth_images/image103.png\n",
      "nyu_depth_images/image1030.png\n",
      "nyu_depth_images/image1031.png\n",
      "nyu_depth_images/image1032.png\n",
      "nyu_depth_images/image1033.png\n",
      "nyu_depth_images/image1034.png\n",
      "nyu_depth_images/image1035.png\n",
      "nyu_depth_images/image1036.png\n",
      "nyu_depth_images/image1037.png\n",
      "nyu_depth_images/image1038.png\n",
      "nyu_depth_images/image1039.png\n",
      "nyu_depth_images/image104.png\n",
      "nyu_depth_images/image1040.png\n",
      "nyu_depth_images/image1041.png\n",
      "nyu_depth_images/image1042.png\n",
      "nyu_depth_images/image1043.png\n",
      "nyu_depth_images/image1044.png\n",
      "nyu_depth_images/image1045.png\n",
      "nyu_depth_images/image1046.png\n",
      "nyu_depth_images/image1047.png\n",
      "nyu_depth_images/image1048.png\n",
      "nyu_depth_images/image1049.png\n",
      "nyu_depth_images/image105.png\n",
      "nyu_depth_images/image1050.png\n",
      "nyu_depth_images/image1051.png\n",
      "nyu_depth_images/image1052.png\n",
      "nyu_depth_images/image1053.png\n",
      "nyu_depth_images/image1054.png\n",
      "nyu_depth_images/image1055.png\n",
      "nyu_depth_images/image1056.png\n",
      "nyu_depth_images/image1057.png\n",
      "nyu_depth_images/image1058.png\n",
      "nyu_depth_images/image1059.png\n",
      "nyu_depth_images/image106.png\n",
      "nyu_depth_images/image1060.png\n",
      "nyu_depth_images/image1061.png\n",
      "nyu_depth_images/image1062.png\n",
      "nyu_depth_images/image1063.png\n",
      "nyu_depth_images/image1064.png\n",
      "nyu_depth_images/image1065.png\n",
      "nyu_depth_images/image1066.png\n",
      "nyu_depth_images/image1067.png\n",
      "nyu_depth_images/image1068.png\n",
      "nyu_depth_images/image1069.png\n",
      "nyu_depth_images/image107.png\n",
      "nyu_depth_images/image1070.png\n",
      "nyu_depth_images/image1071.png\n",
      "nyu_depth_images/image1072.png\n",
      "nyu_depth_images/image1073.png\n",
      "nyu_depth_images/image1074.png\n",
      "nyu_depth_images/image1075.png\n",
      "nyu_depth_images/image1076.png\n",
      "nyu_depth_images/image1077.png\n",
      "nyu_depth_images/image1078.png\n",
      "nyu_depth_images/image1079.png\n",
      "nyu_depth_images/image108.png\n",
      "nyu_depth_images/image1080.png\n",
      "nyu_depth_images/image1081.png\n",
      "nyu_depth_images/image1082.png\n",
      "nyu_depth_images/image1083.png\n",
      "nyu_depth_images/image1084.png\n",
      "nyu_depth_images/image1085.png\n",
      "nyu_depth_images/image1086.png\n",
      "nyu_depth_images/image1087.png\n",
      "nyu_depth_images/image1088.png\n",
      "nyu_depth_images/image1089.png\n",
      "nyu_depth_images/image109.png\n",
      "nyu_depth_images/image1090.png\n",
      "nyu_depth_images/image1091.png\n",
      "nyu_depth_images/image1092.png\n",
      "nyu_depth_images/image1093.png\n",
      "nyu_depth_images/image1094.png\n",
      "nyu_depth_images/image1095.png\n",
      "nyu_depth_images/image1096.png\n",
      "nyu_depth_images/image1097.png\n",
      "nyu_depth_images/image1098.png\n",
      "nyu_depth_images/image1099.png\n",
      "nyu_depth_images/image11.png\n",
      "nyu_depth_images/image110.png\n",
      "nyu_depth_images/image1100.png\n",
      "nyu_depth_images/image1101.png\n",
      "nyu_depth_images/image1102.png\n",
      "nyu_depth_images/image1103.png\n",
      "nyu_depth_images/image1104.png\n",
      "nyu_depth_images/image1105.png\n",
      "nyu_depth_images/image1106.png\n",
      "nyu_depth_images/image1107.png\n",
      "nyu_depth_images/image1108.png\n",
      "nyu_depth_images/image1109.png\n",
      "nyu_depth_images/image111.png\n",
      "nyu_depth_images/image1110.png\n",
      "nyu_depth_images/image1111.png\n",
      "nyu_depth_images/image1112.png\n",
      "nyu_depth_images/image1113.png\n",
      "nyu_depth_images/image1114.png\n",
      "nyu_depth_images/image1115.png\n",
      "nyu_depth_images/image1116.png\n",
      "nyu_depth_images/image1117.png\n",
      "nyu_depth_images/image1118.png\n",
      "nyu_depth_images/image1119.png\n",
      "nyu_depth_images/image112.png\n",
      "nyu_depth_images/image1120.png\n",
      "nyu_depth_images/image1121.png\n",
      "nyu_depth_images/image1122.png\n",
      "nyu_depth_images/image1123.png\n",
      "nyu_depth_images/image1124.png\n",
      "nyu_depth_images/image1125.png\n",
      "nyu_depth_images/image1126.png\n",
      "nyu_depth_images/image1127.png\n",
      "nyu_depth_images/image1128.png\n",
      "nyu_depth_images/image1129.png\n",
      "nyu_depth_images/image113.png\n",
      "nyu_depth_images/image1130.png\n",
      "nyu_depth_images/image1131.png\n",
      "nyu_depth_images/image1132.png\n",
      "nyu_depth_images/image1133.png\n",
      "nyu_depth_images/image1134.png\n",
      "nyu_depth_images/image1135.png\n",
      "nyu_depth_images/image1136.png\n",
      "nyu_depth_images/image1137.png\n",
      "nyu_depth_images/image1138.png\n",
      "nyu_depth_images/image1139.png\n",
      "nyu_depth_images/image114.png\n",
      "nyu_depth_images/image1140.png\n",
      "nyu_depth_images/image1141.png\n",
      "nyu_depth_images/image1142.png\n",
      "nyu_depth_images/image1143.png\n",
      "nyu_depth_images/image1144.png\n",
      "nyu_depth_images/image1145.png\n",
      "nyu_depth_images/image1146.png\n",
      "nyu_depth_images/image1147.png\n",
      "nyu_depth_images/image1148.png\n",
      "nyu_depth_images/image1149.png\n",
      "nyu_depth_images/image115.png\n",
      "nyu_depth_images/image1150.png\n",
      "nyu_depth_images/image1151.png\n",
      "nyu_depth_images/image1152.png\n",
      "nyu_depth_images/image1153.png\n",
      "nyu_depth_images/image1154.png\n",
      "nyu_depth_images/image1155.png\n",
      "nyu_depth_images/image1156.png\n",
      "nyu_depth_images/image1157.png\n",
      "nyu_depth_images/image1158.png\n",
      "nyu_depth_images/image1159.png\n",
      "nyu_depth_images/image116.png\n",
      "nyu_depth_images/image1160.png\n",
      "nyu_depth_images/image1161.png\n",
      "nyu_depth_images/image1162.png\n",
      "nyu_depth_images/image1163.png\n",
      "nyu_depth_images/image1164.png\n",
      "nyu_depth_images/image1165.png\n",
      "nyu_depth_images/image1166.png\n",
      "nyu_depth_images/image1167.png\n",
      "nyu_depth_images/image1168.png\n",
      "nyu_depth_images/image1169.png\n",
      "nyu_depth_images/image117.png\n",
      "nyu_depth_images/image1170.png\n",
      "nyu_depth_images/image1171.png\n",
      "nyu_depth_images/image1172.png\n",
      "nyu_depth_images/image1173.png\n",
      "nyu_depth_images/image1174.png\n",
      "nyu_depth_images/image1175.png\n",
      "nyu_depth_images/image1176.png\n",
      "nyu_depth_images/image1177.png\n",
      "nyu_depth_images/image1178.png\n",
      "nyu_depth_images/image1179.png\n",
      "nyu_depth_images/image118.png\n",
      "nyu_depth_images/image1180.png\n",
      "nyu_depth_images/image1181.png\n",
      "nyu_depth_images/image1182.png\n",
      "nyu_depth_images/image1183.png\n",
      "nyu_depth_images/image1184.png\n",
      "nyu_depth_images/image1185.png\n",
      "nyu_depth_images/image1186.png\n",
      "nyu_depth_images/image1187.png\n",
      "nyu_depth_images/image1188.png\n",
      "nyu_depth_images/image1189.png\n",
      "nyu_depth_images/image119.png\n",
      "nyu_depth_images/image1190.png\n",
      "nyu_depth_images/image1191.png\n",
      "nyu_depth_images/image1192.png\n",
      "nyu_depth_images/image1193.png\n",
      "nyu_depth_images/image1194.png\n",
      "nyu_depth_images/image1195.png\n",
      "nyu_depth_images/image1196.png\n",
      "nyu_depth_images/image1197.png\n",
      "nyu_depth_images/image1198.png\n",
      "nyu_depth_images/image1199.png\n",
      "nyu_depth_images/image12.png\n",
      "nyu_depth_images/image120.png\n",
      "nyu_depth_images/image1200.png\n",
      "nyu_depth_images/image1201.png\n",
      "nyu_depth_images/image1202.png\n",
      "nyu_depth_images/image1203.png\n",
      "nyu_depth_images/image1204.png\n",
      "nyu_depth_images/image1205.png\n",
      "nyu_depth_images/image1206.png\n",
      "nyu_depth_images/image1207.png\n",
      "nyu_depth_images/image1208.png\n",
      "nyu_depth_images/image1209.png\n",
      "nyu_depth_images/image121.png\n",
      "nyu_depth_images/image1210.png\n",
      "nyu_depth_images/image1211.png\n",
      "nyu_depth_images/image1212.png\n",
      "nyu_depth_images/image1213.png\n",
      "nyu_depth_images/image1214.png\n",
      "nyu_depth_images/image1215.png\n",
      "nyu_depth_images/image1216.png\n",
      "nyu_depth_images/image1217.png\n",
      "nyu_depth_images/image1218.png\n",
      "nyu_depth_images/image1219.png\n",
      "nyu_depth_images/image122.png\n",
      "nyu_depth_images/image1220.png\n",
      "nyu_depth_images/image1221.png\n",
      "nyu_depth_images/image1222.png\n",
      "nyu_depth_images/image1223.png\n",
      "nyu_depth_images/image1224.png\n",
      "nyu_depth_images/image1225.png\n",
      "nyu_depth_images/image1226.png\n",
      "nyu_depth_images/image1227.png\n",
      "nyu_depth_images/image1228.png\n",
      "nyu_depth_images/image1229.png\n",
      "nyu_depth_images/image123.png\n",
      "nyu_depth_images/image1230.png\n",
      "nyu_depth_images/image1231.png\n",
      "nyu_depth_images/image1232.png\n",
      "nyu_depth_images/image1233.png\n",
      "nyu_depth_images/image1234.png\n",
      "nyu_depth_images/image1235.png\n",
      "nyu_depth_images/image1236.png\n",
      "nyu_depth_images/image1237.png\n",
      "nyu_depth_images/image1238.png\n",
      "nyu_depth_images/image1239.png\n",
      "nyu_depth_images/image124.png\n",
      "nyu_depth_images/image1240.png\n",
      "nyu_depth_images/image1241.png\n",
      "nyu_depth_images/image1242.png\n",
      "nyu_depth_images/image1243.png\n",
      "nyu_depth_images/image1244.png\n",
      "nyu_depth_images/image1245.png\n",
      "nyu_depth_images/image1246.png\n",
      "nyu_depth_images/image1247.png\n",
      "nyu_depth_images/image1248.png\n",
      "nyu_depth_images/image1249.png\n",
      "nyu_depth_images/image125.png\n",
      "nyu_depth_images/image1250.png\n",
      "nyu_depth_images/image1251.png\n",
      "nyu_depth_images/image1252.png\n",
      "nyu_depth_images/image1253.png\n",
      "nyu_depth_images/image1254.png\n",
      "nyu_depth_images/image1255.png\n",
      "nyu_depth_images/image1256.png\n",
      "nyu_depth_images/image1257.png\n",
      "nyu_depth_images/image1258.png\n",
      "nyu_depth_images/image1259.png\n",
      "nyu_depth_images/image126.png\n",
      "nyu_depth_images/image1260.png\n",
      "nyu_depth_images/image1261.png\n",
      "nyu_depth_images/image1262.png\n",
      "nyu_depth_images/image1263.png\n",
      "nyu_depth_images/image1264.png\n",
      "nyu_depth_images/image1265.png\n",
      "nyu_depth_images/image1266.png\n",
      "nyu_depth_images/image1267.png\n",
      "nyu_depth_images/image1268.png\n",
      "nyu_depth_images/image1269.png\n",
      "nyu_depth_images/image127.png\n",
      "nyu_depth_images/image1270.png\n",
      "nyu_depth_images/image1271.png\n",
      "nyu_depth_images/image1272.png\n",
      "nyu_depth_images/image1273.png\n",
      "nyu_depth_images/image1274.png\n",
      "nyu_depth_images/image1275.png\n",
      "nyu_depth_images/image1276.png\n",
      "nyu_depth_images/image1277.png\n",
      "nyu_depth_images/image1278.png\n",
      "nyu_depth_images/image1279.png\n",
      "nyu_depth_images/image128.png\n",
      "nyu_depth_images/image1280.png\n",
      "nyu_depth_images/image1281.png\n",
      "nyu_depth_images/image1282.png\n",
      "nyu_depth_images/image1283.png\n",
      "nyu_depth_images/image1284.png\n",
      "nyu_depth_images/image1285.png\n",
      "nyu_depth_images/image1286.png\n",
      "nyu_depth_images/image1287.png\n",
      "nyu_depth_images/image1288.png\n",
      "nyu_depth_images/image1289.png\n",
      "nyu_depth_images/image129.png\n",
      "nyu_depth_images/image1290.png\n",
      "nyu_depth_images/image1291.png\n",
      "nyu_depth_images/image1292.png\n",
      "nyu_depth_images/image1293.png\n",
      "nyu_depth_images/image1294.png\n",
      "nyu_depth_images/image1295.png\n",
      "nyu_depth_images/image1296.png\n",
      "nyu_depth_images/image1297.png\n",
      "nyu_depth_images/image1298.png\n",
      "nyu_depth_images/image1299.png\n",
      "nyu_depth_images/image13.png\n",
      "nyu_depth_images/image130.png\n",
      "nyu_depth_images/image1300.png\n",
      "nyu_depth_images/image1301.png\n",
      "nyu_depth_images/image1302.png\n",
      "nyu_depth_images/image1303.png\n",
      "nyu_depth_images/image1304.png\n",
      "nyu_depth_images/image1305.png\n",
      "nyu_depth_images/image1306.png\n",
      "nyu_depth_images/image1307.png\n",
      "nyu_depth_images/image1308.png\n",
      "nyu_depth_images/image1309.png\n",
      "nyu_depth_images/image131.png\n",
      "nyu_depth_images/image1310.png\n",
      "nyu_depth_images/image1311.png\n",
      "nyu_depth_images/image1312.png\n",
      "nyu_depth_images/image1313.png\n",
      "nyu_depth_images/image1314.png\n",
      "nyu_depth_images/image1315.png\n",
      "nyu_depth_images/image1316.png\n",
      "nyu_depth_images/image1317.png\n",
      "nyu_depth_images/image1318.png\n",
      "nyu_depth_images/image1319.png\n",
      "nyu_depth_images/image132.png\n",
      "nyu_depth_images/image1320.png\n",
      "nyu_depth_images/image1321.png\n",
      "nyu_depth_images/image1322.png\n",
      "nyu_depth_images/image1323.png\n",
      "nyu_depth_images/image1324.png\n",
      "nyu_depth_images/image1325.png\n",
      "nyu_depth_images/image1326.png\n",
      "nyu_depth_images/image1327.png\n",
      "nyu_depth_images/image1328.png\n",
      "nyu_depth_images/image1329.png\n",
      "nyu_depth_images/image133.png\n",
      "nyu_depth_images/image1330.png\n",
      "nyu_depth_images/image1331.png\n",
      "nyu_depth_images/image1332.png\n",
      "nyu_depth_images/image1333.png\n",
      "nyu_depth_images/image1334.png\n",
      "nyu_depth_images/image1335.png\n",
      "nyu_depth_images/image1336.png\n",
      "nyu_depth_images/image1337.png\n",
      "nyu_depth_images/image1338.png\n",
      "nyu_depth_images/image1339.png\n",
      "nyu_depth_images/image134.png\n",
      "nyu_depth_images/image1340.png\n",
      "nyu_depth_images/image1341.png\n",
      "nyu_depth_images/image1342.png\n",
      "nyu_depth_images/image1343.png\n",
      "nyu_depth_images/image1344.png\n",
      "nyu_depth_images/image1345.png\n",
      "nyu_depth_images/image1346.png\n",
      "nyu_depth_images/image1347.png\n",
      "nyu_depth_images/image1348.png\n",
      "nyu_depth_images/image1349.png\n",
      "nyu_depth_images/image135.png\n",
      "nyu_depth_images/image1350.png\n",
      "nyu_depth_images/image1351.png\n",
      "nyu_depth_images/image1352.png\n",
      "nyu_depth_images/image1353.png\n",
      "nyu_depth_images/image1354.png\n",
      "nyu_depth_images/image1355.png\n",
      "nyu_depth_images/image1356.png\n",
      "nyu_depth_images/image1357.png\n",
      "nyu_depth_images/image1358.png\n",
      "nyu_depth_images/image1359.png\n",
      "nyu_depth_images/image136.png\n",
      "nyu_depth_images/image1360.png\n",
      "nyu_depth_images/image1361.png\n",
      "nyu_depth_images/image1362.png\n",
      "nyu_depth_images/image1363.png\n",
      "nyu_depth_images/image1364.png\n",
      "nyu_depth_images/image1365.png\n",
      "nyu_depth_images/image1366.png\n",
      "nyu_depth_images/image1367.png\n",
      "nyu_depth_images/image1368.png\n",
      "nyu_depth_images/image1369.png\n",
      "nyu_depth_images/image137.png\n",
      "nyu_depth_images/image1370.png\n",
      "nyu_depth_images/image1371.png\n",
      "nyu_depth_images/image1372.png\n",
      "nyu_depth_images/image1373.png\n",
      "nyu_depth_images/image1374.png\n",
      "nyu_depth_images/image1375.png\n",
      "nyu_depth_images/image1376.png\n",
      "nyu_depth_images/image1377.png\n",
      "nyu_depth_images/image1378.png\n",
      "nyu_depth_images/image1379.png\n",
      "nyu_depth_images/image138.png\n",
      "nyu_depth_images/image1380.png\n",
      "nyu_depth_images/image1381.png\n",
      "nyu_depth_images/image1382.png\n",
      "nyu_depth_images/image1383.png\n",
      "nyu_depth_images/image1384.png\n",
      "nyu_depth_images/image1385.png\n",
      "nyu_depth_images/image1386.png\n",
      "nyu_depth_images/image1387.png\n",
      "nyu_depth_images/image1388.png\n",
      "nyu_depth_images/image1389.png\n",
      "nyu_depth_images/image139.png\n",
      "nyu_depth_images/image1390.png\n",
      "nyu_depth_images/image1391.png\n",
      "nyu_depth_images/image1392.png\n",
      "nyu_depth_images/image1393.png\n",
      "nyu_depth_images/image1394.png\n",
      "nyu_depth_images/image1395.png\n",
      "nyu_depth_images/image1396.png\n",
      "nyu_depth_images/image1397.png\n",
      "nyu_depth_images/image1398.png\n",
      "nyu_depth_images/image1399.png\n",
      "nyu_depth_images/image14.png\n",
      "nyu_depth_images/image140.png\n",
      "nyu_depth_images/image1400.png\n",
      "nyu_depth_images/image1401.png\n",
      "nyu_depth_images/image1402.png\n",
      "nyu_depth_images/image1403.png\n",
      "nyu_depth_images/image1404.png\n",
      "nyu_depth_images/image1405.png\n",
      "nyu_depth_images/image1406.png\n",
      "nyu_depth_images/image1407.png\n",
      "nyu_depth_images/image1408.png\n",
      "nyu_depth_images/image1409.png\n",
      "nyu_depth_images/image141.png\n",
      "nyu_depth_images/image1410.png\n",
      "nyu_depth_images/image1411.png\n",
      "nyu_depth_images/image1412.png\n",
      "nyu_depth_images/image1413.png\n",
      "nyu_depth_images/image1414.png\n",
      "nyu_depth_images/image1415.png\n",
      "nyu_depth_images/image1416.png\n",
      "nyu_depth_images/image1417.png\n",
      "nyu_depth_images/image1418.png\n",
      "nyu_depth_images/image1419.png\n",
      "nyu_depth_images/image142.png\n",
      "nyu_depth_images/image1420.png\n",
      "nyu_depth_images/image1421.png\n",
      "nyu_depth_images/image1422.png\n",
      "nyu_depth_images/image1423.png\n",
      "nyu_depth_images/image1424.png\n",
      "nyu_depth_images/image1425.png\n",
      "nyu_depth_images/image1426.png\n",
      "nyu_depth_images/image1427.png\n",
      "nyu_depth_images/image1428.png\n",
      "nyu_depth_images/image1429.png\n",
      "nyu_depth_images/image143.png\n",
      "nyu_depth_images/image1430.png\n",
      "nyu_depth_images/image1431.png\n",
      "nyu_depth_images/image1432.png\n",
      "nyu_depth_images/image1433.png\n",
      "nyu_depth_images/image1434.png\n",
      "nyu_depth_images/image1435.png\n",
      "nyu_depth_images/image1436.png\n",
      "nyu_depth_images/image1437.png\n",
      "nyu_depth_images/image1438.png\n",
      "nyu_depth_images/image1439.png\n",
      "nyu_depth_images/image144.png\n",
      "nyu_depth_images/image1440.png\n",
      "nyu_depth_images/image1441.png\n",
      "nyu_depth_images/image1442.png\n",
      "nyu_depth_images/image1443.png\n",
      "nyu_depth_images/image1444.png\n",
      "nyu_depth_images/image1445.png\n",
      "nyu_depth_images/image1446.png\n",
      "nyu_depth_images/image1447.png\n",
      "nyu_depth_images/image1448.png\n",
      "nyu_depth_images/image1449.png\n",
      "nyu_depth_images/image145.png\n",
      "nyu_depth_images/image146.png\n",
      "nyu_depth_images/image147.png\n",
      "nyu_depth_images/image148.png\n",
      "nyu_depth_images/image149.png\n",
      "nyu_depth_images/image15.png\n",
      "nyu_depth_images/image150.png\n",
      "nyu_depth_images/image151.png\n",
      "nyu_depth_images/image152.png\n",
      "nyu_depth_images/image153.png\n",
      "nyu_depth_images/image154.png\n",
      "nyu_depth_images/image155.png\n",
      "nyu_depth_images/image156.png\n",
      "nyu_depth_images/image157.png\n",
      "nyu_depth_images/image158.png\n",
      "nyu_depth_images/image159.png\n",
      "nyu_depth_images/image16.png\n",
      "nyu_depth_images/image160.png\n",
      "nyu_depth_images/image161.png\n",
      "nyu_depth_images/image162.png\n",
      "nyu_depth_images/image163.png\n",
      "nyu_depth_images/image164.png\n",
      "nyu_depth_images/image165.png\n",
      "nyu_depth_images/image166.png\n",
      "nyu_depth_images/image167.png\n",
      "nyu_depth_images/image168.png\n",
      "nyu_depth_images/image169.png\n",
      "nyu_depth_images/image17.png\n",
      "nyu_depth_images/image170.png\n",
      "nyu_depth_images/image171.png\n",
      "nyu_depth_images/image172.png\n",
      "nyu_depth_images/image173.png\n",
      "nyu_depth_images/image174.png\n",
      "nyu_depth_images/image175.png\n",
      "nyu_depth_images/image176.png\n",
      "nyu_depth_images/image177.png\n",
      "nyu_depth_images/image178.png\n",
      "nyu_depth_images/image179.png\n",
      "nyu_depth_images/image18.png\n",
      "nyu_depth_images/image180.png\n",
      "nyu_depth_images/image181.png\n",
      "nyu_depth_images/image182.png\n",
      "nyu_depth_images/image183.png\n",
      "nyu_depth_images/image184.png\n",
      "nyu_depth_images/image185.png\n",
      "nyu_depth_images/image186.png\n",
      "nyu_depth_images/image187.png\n",
      "nyu_depth_images/image188.png\n",
      "nyu_depth_images/image189.png\n",
      "nyu_depth_images/image19.png\n",
      "nyu_depth_images/image190.png\n",
      "nyu_depth_images/image191.png\n",
      "nyu_depth_images/image192.png\n",
      "nyu_depth_images/image193.png\n",
      "nyu_depth_images/image194.png\n",
      "nyu_depth_images/image195.png\n",
      "nyu_depth_images/image196.png\n",
      "nyu_depth_images/image197.png\n",
      "nyu_depth_images/image198.png\n",
      "nyu_depth_images/image199.png\n",
      "nyu_depth_images/image2.png\n",
      "nyu_depth_images/image20.png\n",
      "nyu_depth_images/image200.png\n",
      "nyu_depth_images/image201.png\n",
      "nyu_depth_images/image202.png\n",
      "nyu_depth_images/image203.png\n",
      "nyu_depth_images/image204.png\n",
      "nyu_depth_images/image205.png\n",
      "nyu_depth_images/image206.png\n",
      "nyu_depth_images/image207.png\n",
      "nyu_depth_images/image208.png\n",
      "nyu_depth_images/image209.png\n",
      "nyu_depth_images/image21.png\n",
      "nyu_depth_images/image210.png\n",
      "nyu_depth_images/image211.png\n",
      "nyu_depth_images/image212.png\n",
      "nyu_depth_images/image213.png\n",
      "nyu_depth_images/image214.png\n",
      "nyu_depth_images/image215.png\n",
      "nyu_depth_images/image216.png\n",
      "nyu_depth_images/image217.png\n",
      "nyu_depth_images/image218.png\n",
      "nyu_depth_images/image219.png\n",
      "nyu_depth_images/image22.png\n",
      "nyu_depth_images/image220.png\n",
      "nyu_depth_images/image221.png\n",
      "nyu_depth_images/image222.png\n",
      "nyu_depth_images/image223.png\n",
      "nyu_depth_images/image224.png\n",
      "nyu_depth_images/image225.png\n",
      "nyu_depth_images/image226.png\n",
      "nyu_depth_images/image227.png\n",
      "nyu_depth_images/image228.png\n",
      "nyu_depth_images/image229.png\n",
      "nyu_depth_images/image23.png\n",
      "nyu_depth_images/image230.png\n",
      "nyu_depth_images/image231.png\n",
      "nyu_depth_images/image232.png\n",
      "nyu_depth_images/image233.png\n",
      "nyu_depth_images/image234.png\n",
      "nyu_depth_images/image235.png\n",
      "nyu_depth_images/image236.png\n",
      "nyu_depth_images/image237.png\n",
      "nyu_depth_images/image238.png\n",
      "nyu_depth_images/image239.png\n",
      "nyu_depth_images/image24.png\n",
      "nyu_depth_images/image240.png\n",
      "nyu_depth_images/image241.png\n",
      "nyu_depth_images/image242.png\n",
      "nyu_depth_images/image243.png\n",
      "nyu_depth_images/image244.png\n",
      "nyu_depth_images/image245.png\n",
      "nyu_depth_images/image246.png\n",
      "nyu_depth_images/image247.png\n",
      "nyu_depth_images/image248.png\n",
      "nyu_depth_images/image249.png\n",
      "nyu_depth_images/image25.png\n",
      "nyu_depth_images/image250.png\n",
      "nyu_depth_images/image251.png\n",
      "nyu_depth_images/image252.png\n",
      "nyu_depth_images/image253.png\n",
      "nyu_depth_images/image254.png\n",
      "nyu_depth_images/image255.png\n",
      "nyu_depth_images/image256.png\n",
      "nyu_depth_images/image257.png\n",
      "nyu_depth_images/image258.png\n",
      "nyu_depth_images/image259.png\n",
      "nyu_depth_images/image26.png\n",
      "nyu_depth_images/image260.png\n",
      "nyu_depth_images/image261.png\n",
      "nyu_depth_images/image262.png\n",
      "nyu_depth_images/image263.png\n",
      "nyu_depth_images/image264.png\n",
      "nyu_depth_images/image265.png\n",
      "nyu_depth_images/image266.png\n",
      "nyu_depth_images/image267.png\n",
      "nyu_depth_images/image268.png\n",
      "nyu_depth_images/image269.png\n",
      "nyu_depth_images/image27.png\n",
      "nyu_depth_images/image270.png\n",
      "nyu_depth_images/image271.png\n",
      "nyu_depth_images/image272.png\n",
      "nyu_depth_images/image273.png\n",
      "nyu_depth_images/image274.png\n",
      "nyu_depth_images/image275.png\n",
      "nyu_depth_images/image276.png\n",
      "nyu_depth_images/image277.png\n",
      "nyu_depth_images/image278.png\n",
      "nyu_depth_images/image279.png\n",
      "nyu_depth_images/image28.png\n",
      "nyu_depth_images/image280.png\n",
      "nyu_depth_images/image281.png\n",
      "nyu_depth_images/image282.png\n",
      "nyu_depth_images/image283.png\n",
      "nyu_depth_images/image284.png\n",
      "nyu_depth_images/image285.png\n",
      "nyu_depth_images/image286.png\n",
      "nyu_depth_images/image287.png\n",
      "nyu_depth_images/image288.png\n",
      "nyu_depth_images/image289.png\n",
      "nyu_depth_images/image29.png\n",
      "nyu_depth_images/image290.png\n",
      "nyu_depth_images/image291.png\n",
      "nyu_depth_images/image292.png\n",
      "nyu_depth_images/image293.png\n",
      "nyu_depth_images/image294.png\n",
      "nyu_depth_images/image295.png\n",
      "nyu_depth_images/image296.png\n",
      "nyu_depth_images/image297.png\n",
      "nyu_depth_images/image298.png\n",
      "nyu_depth_images/image299.png\n",
      "nyu_depth_images/image3.png\n",
      "nyu_depth_images/image30.png\n",
      "nyu_depth_images/image300.png\n",
      "nyu_depth_images/image301.png\n",
      "nyu_depth_images/image302.png\n",
      "nyu_depth_images/image303.png\n",
      "nyu_depth_images/image304.png\n",
      "nyu_depth_images/image305.png\n",
      "nyu_depth_images/image306.png\n",
      "nyu_depth_images/image307.png\n",
      "nyu_depth_images/image308.png\n",
      "nyu_depth_images/image309.png\n",
      "nyu_depth_images/image31.png\n",
      "nyu_depth_images/image310.png\n",
      "nyu_depth_images/image311.png\n",
      "nyu_depth_images/image312.png\n",
      "nyu_depth_images/image313.png\n",
      "nyu_depth_images/image314.png\n",
      "nyu_depth_images/image315.png\n",
      "nyu_depth_images/image316.png\n",
      "nyu_depth_images/image317.png\n",
      "nyu_depth_images/image318.png\n",
      "nyu_depth_images/image319.png\n",
      "nyu_depth_images/image32.png\n",
      "nyu_depth_images/image320.png\n",
      "nyu_depth_images/image321.png\n",
      "nyu_depth_images/image322.png\n",
      "nyu_depth_images/image323.png\n",
      "nyu_depth_images/image324.png\n",
      "nyu_depth_images/image325.png\n",
      "nyu_depth_images/image326.png\n",
      "nyu_depth_images/image327.png\n",
      "nyu_depth_images/image328.png\n",
      "nyu_depth_images/image329.png\n",
      "nyu_depth_images/image33.png\n",
      "nyu_depth_images/image330.png\n",
      "nyu_depth_images/image331.png\n",
      "nyu_depth_images/image332.png\n",
      "nyu_depth_images/image333.png\n",
      "nyu_depth_images/image334.png\n",
      "nyu_depth_images/image335.png\n",
      "nyu_depth_images/image336.png\n",
      "nyu_depth_images/image337.png\n",
      "nyu_depth_images/image338.png\n",
      "nyu_depth_images/image339.png\n",
      "nyu_depth_images/image34.png\n",
      "nyu_depth_images/image340.png\n",
      "nyu_depth_images/image341.png\n",
      "nyu_depth_images/image342.png\n",
      "nyu_depth_images/image343.png\n",
      "nyu_depth_images/image344.png\n",
      "nyu_depth_images/image345.png\n",
      "nyu_depth_images/image346.png\n",
      "nyu_depth_images/image347.png\n",
      "nyu_depth_images/image348.png\n",
      "nyu_depth_images/image349.png\n",
      "nyu_depth_images/image35.png\n",
      "nyu_depth_images/image350.png\n",
      "nyu_depth_images/image351.png\n",
      "nyu_depth_images/image352.png\n",
      "nyu_depth_images/image353.png\n",
      "nyu_depth_images/image354.png\n",
      "nyu_depth_images/image355.png\n",
      "nyu_depth_images/image356.png\n",
      "nyu_depth_images/image357.png\n",
      "nyu_depth_images/image358.png\n",
      "nyu_depth_images/image359.png\n",
      "nyu_depth_images/image36.png\n",
      "nyu_depth_images/image360.png\n",
      "nyu_depth_images/image361.png\n",
      "nyu_depth_images/image362.png\n",
      "nyu_depth_images/image363.png\n",
      "nyu_depth_images/image364.png\n",
      "nyu_depth_images/image365.png\n",
      "nyu_depth_images/image366.png\n",
      "nyu_depth_images/image367.png\n",
      "nyu_depth_images/image368.png\n",
      "nyu_depth_images/image369.png\n",
      "nyu_depth_images/image37.png\n",
      "nyu_depth_images/image370.png\n",
      "nyu_depth_images/image371.png\n",
      "nyu_depth_images/image372.png\n",
      "nyu_depth_images/image373.png\n",
      "nyu_depth_images/image374.png\n",
      "nyu_depth_images/image375.png\n",
      "nyu_depth_images/image376.png\n",
      "nyu_depth_images/image377.png\n",
      "nyu_depth_images/image378.png\n",
      "nyu_depth_images/image379.png\n",
      "nyu_depth_images/image38.png\n",
      "nyu_depth_images/image380.png\n",
      "nyu_depth_images/image381.png\n",
      "nyu_depth_images/image382.png\n",
      "nyu_depth_images/image383.png\n",
      "nyu_depth_images/image384.png\n",
      "nyu_depth_images/image385.png\n",
      "nyu_depth_images/image386.png\n",
      "nyu_depth_images/image387.png\n",
      "nyu_depth_images/image388.png\n",
      "nyu_depth_images/image389.png\n",
      "nyu_depth_images/image39.png\n",
      "nyu_depth_images/image390.png\n",
      "nyu_depth_images/image391.png\n",
      "nyu_depth_images/image392.png\n",
      "nyu_depth_images/image393.png\n",
      "nyu_depth_images/image394.png\n",
      "nyu_depth_images/image395.png\n",
      "nyu_depth_images/image396.png\n",
      "nyu_depth_images/image397.png\n",
      "nyu_depth_images/image398.png\n",
      "nyu_depth_images/image399.png\n",
      "nyu_depth_images/image4.png\n",
      "nyu_depth_images/image40.png\n",
      "nyu_depth_images/image400.png\n",
      "nyu_depth_images/image401.png\n",
      "nyu_depth_images/image402.png\n",
      "nyu_depth_images/image403.png\n",
      "nyu_depth_images/image404.png\n",
      "nyu_depth_images/image405.png\n",
      "nyu_depth_images/image406.png\n",
      "nyu_depth_images/image407.png\n",
      "nyu_depth_images/image408.png\n",
      "nyu_depth_images/image409.png\n",
      "nyu_depth_images/image41.png\n",
      "nyu_depth_images/image410.png\n",
      "nyu_depth_images/image411.png\n",
      "nyu_depth_images/image412.png\n",
      "nyu_depth_images/image413.png\n",
      "nyu_depth_images/image414.png\n",
      "nyu_depth_images/image415.png\n",
      "nyu_depth_images/image416.png\n",
      "nyu_depth_images/image417.png\n",
      "nyu_depth_images/image418.png\n",
      "nyu_depth_images/image419.png\n",
      "nyu_depth_images/image42.png\n",
      "nyu_depth_images/image420.png\n",
      "nyu_depth_images/image421.png\n",
      "nyu_depth_images/image422.png\n",
      "nyu_depth_images/image423.png\n",
      "nyu_depth_images/image424.png\n",
      "nyu_depth_images/image425.png\n",
      "nyu_depth_images/image426.png\n",
      "nyu_depth_images/image427.png\n",
      "nyu_depth_images/image428.png\n",
      "nyu_depth_images/image429.png\n",
      "nyu_depth_images/image43.png\n",
      "nyu_depth_images/image430.png\n",
      "nyu_depth_images/image431.png\n",
      "nyu_depth_images/image432.png\n",
      "nyu_depth_images/image433.png\n",
      "nyu_depth_images/image434.png\n",
      "nyu_depth_images/image435.png\n",
      "nyu_depth_images/image436.png\n",
      "nyu_depth_images/image437.png\n",
      "nyu_depth_images/image438.png\n",
      "nyu_depth_images/image439.png\n",
      "nyu_depth_images/image44.png\n",
      "nyu_depth_images/image440.png\n",
      "nyu_depth_images/image441.png\n",
      "nyu_depth_images/image442.png\n",
      "nyu_depth_images/image443.png\n",
      "nyu_depth_images/image444.png\n",
      "nyu_depth_images/image445.png\n",
      "nyu_depth_images/image446.png\n",
      "nyu_depth_images/image447.png\n",
      "nyu_depth_images/image448.png\n",
      "nyu_depth_images/image449.png\n",
      "nyu_depth_images/image45.png\n",
      "nyu_depth_images/image450.png\n",
      "nyu_depth_images/image451.png\n",
      "nyu_depth_images/image452.png\n",
      "nyu_depth_images/image453.png\n",
      "nyu_depth_images/image454.png\n",
      "nyu_depth_images/image455.png\n",
      "nyu_depth_images/image456.png\n",
      "nyu_depth_images/image457.png\n",
      "nyu_depth_images/image458.png\n",
      "nyu_depth_images/image459.png\n",
      "nyu_depth_images/image46.png\n",
      "nyu_depth_images/image460.png\n",
      "nyu_depth_images/image461.png\n",
      "nyu_depth_images/image462.png\n",
      "nyu_depth_images/image463.png\n",
      "nyu_depth_images/image464.png\n",
      "nyu_depth_images/image465.png\n",
      "nyu_depth_images/image466.png\n",
      "nyu_depth_images/image467.png\n",
      "nyu_depth_images/image468.png\n",
      "nyu_depth_images/image469.png\n",
      "nyu_depth_images/image47.png\n",
      "nyu_depth_images/image470.png\n",
      "nyu_depth_images/image471.png\n",
      "nyu_depth_images/image472.png\n",
      "nyu_depth_images/image473.png\n",
      "nyu_depth_images/image474.png\n",
      "nyu_depth_images/image475.png\n",
      "nyu_depth_images/image476.png\n",
      "nyu_depth_images/image477.png\n",
      "nyu_depth_images/image478.png\n",
      "nyu_depth_images/image479.png\n",
      "nyu_depth_images/image48.png\n",
      "nyu_depth_images/image480.png\n",
      "nyu_depth_images/image481.png\n",
      "nyu_depth_images/image482.png\n",
      "nyu_depth_images/image483.png\n",
      "nyu_depth_images/image484.png\n",
      "nyu_depth_images/image485.png\n",
      "nyu_depth_images/image486.png\n",
      "nyu_depth_images/image487.png\n",
      "nyu_depth_images/image488.png\n",
      "nyu_depth_images/image489.png\n",
      "nyu_depth_images/image49.png\n",
      "nyu_depth_images/image490.png\n",
      "nyu_depth_images/image491.png\n",
      "nyu_depth_images/image492.png\n",
      "nyu_depth_images/image493.png\n",
      "nyu_depth_images/image494.png\n",
      "nyu_depth_images/image495.png\n",
      "nyu_depth_images/image496.png\n",
      "nyu_depth_images/image497.png\n",
      "nyu_depth_images/image498.png\n",
      "nyu_depth_images/image499.png\n",
      "nyu_depth_images/image5.png\n",
      "nyu_depth_images/image50.png\n",
      "nyu_depth_images/image500.png\n",
      "nyu_depth_images/image501.png\n",
      "nyu_depth_images/image502.png\n",
      "nyu_depth_images/image503.png\n",
      "nyu_depth_images/image504.png\n",
      "nyu_depth_images/image505.png\n",
      "nyu_depth_images/image506.png\n",
      "nyu_depth_images/image507.png\n",
      "nyu_depth_images/image508.png\n",
      "nyu_depth_images/image509.png\n",
      "nyu_depth_images/image51.png\n",
      "nyu_depth_images/image510.png\n",
      "nyu_depth_images/image511.png\n",
      "nyu_depth_images/image512.png\n",
      "nyu_depth_images/image513.png\n",
      "nyu_depth_images/image514.png\n",
      "nyu_depth_images/image515.png\n",
      "nyu_depth_images/image516.png\n",
      "nyu_depth_images/image517.png\n",
      "nyu_depth_images/image518.png\n",
      "nyu_depth_images/image519.png\n",
      "nyu_depth_images/image52.png\n",
      "nyu_depth_images/image520.png\n",
      "nyu_depth_images/image521.png\n",
      "nyu_depth_images/image522.png\n",
      "nyu_depth_images/image523.png\n",
      "nyu_depth_images/image524.png\n",
      "nyu_depth_images/image525.png\n",
      "nyu_depth_images/image526.png\n",
      "nyu_depth_images/image527.png\n",
      "nyu_depth_images/image528.png\n",
      "nyu_depth_images/image529.png\n",
      "nyu_depth_images/image53.png\n",
      "nyu_depth_images/image530.png\n",
      "nyu_depth_images/image531.png\n",
      "nyu_depth_images/image532.png\n",
      "nyu_depth_images/image533.png\n",
      "nyu_depth_images/image534.png\n",
      "nyu_depth_images/image535.png\n",
      "nyu_depth_images/image536.png\n",
      "nyu_depth_images/image537.png\n",
      "nyu_depth_images/image538.png\n",
      "nyu_depth_images/image539.png\n",
      "nyu_depth_images/image54.png\n",
      "nyu_depth_images/image540.png\n",
      "nyu_depth_images/image541.png\n",
      "nyu_depth_images/image542.png\n",
      "nyu_depth_images/image543.png\n",
      "nyu_depth_images/image544.png\n",
      "nyu_depth_images/image545.png\n",
      "nyu_depth_images/image546.png\n",
      "nyu_depth_images/image547.png\n",
      "nyu_depth_images/image548.png\n",
      "nyu_depth_images/image549.png\n",
      "nyu_depth_images/image55.png\n",
      "nyu_depth_images/image550.png\n",
      "nyu_depth_images/image551.png\n",
      "nyu_depth_images/image552.png\n",
      "nyu_depth_images/image553.png\n",
      "nyu_depth_images/image554.png\n",
      "nyu_depth_images/image555.png\n",
      "nyu_depth_images/image556.png\n",
      "nyu_depth_images/image557.png\n",
      "nyu_depth_images/image558.png\n",
      "nyu_depth_images/image559.png\n",
      "nyu_depth_images/image56.png\n",
      "nyu_depth_images/image560.png\n",
      "nyu_depth_images/image561.png\n",
      "nyu_depth_images/image562.png\n",
      "nyu_depth_images/image563.png\n",
      "nyu_depth_images/image564.png\n",
      "nyu_depth_images/image565.png\n",
      "nyu_depth_images/image566.png\n",
      "nyu_depth_images/image567.png\n",
      "nyu_depth_images/image568.png\n",
      "nyu_depth_images/image569.png\n",
      "nyu_depth_images/image57.png\n",
      "nyu_depth_images/image570.png\n",
      "nyu_depth_images/image571.png\n",
      "nyu_depth_images/image572.png\n",
      "nyu_depth_images/image573.png\n",
      "nyu_depth_images/image574.png\n",
      "nyu_depth_images/image575.png\n",
      "nyu_depth_images/image576.png\n",
      "nyu_depth_images/image577.png\n",
      "nyu_depth_images/image578.png\n",
      "nyu_depth_images/image579.png\n",
      "nyu_depth_images/image58.png\n",
      "nyu_depth_images/image580.png\n",
      "nyu_depth_images/image581.png\n",
      "nyu_depth_images/image582.png\n",
      "nyu_depth_images/image583.png\n",
      "nyu_depth_images/image584.png\n",
      "nyu_depth_images/image585.png\n",
      "nyu_depth_images/image586.png\n",
      "nyu_depth_images/image587.png\n",
      "nyu_depth_images/image588.png\n",
      "nyu_depth_images/image589.png\n",
      "nyu_depth_images/image59.png\n",
      "nyu_depth_images/image590.png\n",
      "nyu_depth_images/image591.png\n",
      "nyu_depth_images/image592.png\n",
      "nyu_depth_images/image593.png\n",
      "nyu_depth_images/image594.png\n",
      "nyu_depth_images/image595.png\n",
      "nyu_depth_images/image596.png\n",
      "nyu_depth_images/image597.png\n",
      "nyu_depth_images/image598.png\n",
      "nyu_depth_images/image599.png\n",
      "nyu_depth_images/image6.png\n",
      "nyu_depth_images/image60.png\n",
      "nyu_depth_images/image600.png\n",
      "nyu_depth_images/image601.png\n",
      "nyu_depth_images/image602.png\n",
      "nyu_depth_images/image603.png\n",
      "nyu_depth_images/image604.png\n",
      "nyu_depth_images/image605.png\n",
      "nyu_depth_images/image606.png\n",
      "nyu_depth_images/image607.png\n",
      "nyu_depth_images/image608.png\n",
      "nyu_depth_images/image609.png\n",
      "nyu_depth_images/image61.png\n",
      "nyu_depth_images/image610.png\n",
      "nyu_depth_images/image611.png\n",
      "nyu_depth_images/image612.png\n",
      "nyu_depth_images/image613.png\n",
      "nyu_depth_images/image614.png\n",
      "nyu_depth_images/image615.png\n",
      "nyu_depth_images/image616.png\n",
      "nyu_depth_images/image617.png\n",
      "nyu_depth_images/image618.png\n",
      "nyu_depth_images/image619.png\n",
      "nyu_depth_images/image62.png\n",
      "nyu_depth_images/image620.png\n",
      "nyu_depth_images/image621.png\n",
      "nyu_depth_images/image622.png\n",
      "nyu_depth_images/image623.png\n",
      "nyu_depth_images/image624.png\n",
      "nyu_depth_images/image625.png\n",
      "nyu_depth_images/image626.png\n",
      "nyu_depth_images/image627.png\n",
      "nyu_depth_images/image628.png\n",
      "nyu_depth_images/image629.png\n",
      "nyu_depth_images/image63.png\n",
      "nyu_depth_images/image630.png\n",
      "nyu_depth_images/image631.png\n",
      "nyu_depth_images/image632.png\n",
      "nyu_depth_images/image633.png\n",
      "nyu_depth_images/image634.png\n",
      "nyu_depth_images/image635.png\n",
      "nyu_depth_images/image636.png\n",
      "nyu_depth_images/image637.png\n",
      "nyu_depth_images/image638.png\n",
      "nyu_depth_images/image639.png\n",
      "nyu_depth_images/image64.png\n",
      "nyu_depth_images/image640.png\n",
      "nyu_depth_images/image641.png\n",
      "nyu_depth_images/image642.png\n",
      "nyu_depth_images/image643.png\n",
      "nyu_depth_images/image644.png\n",
      "nyu_depth_images/image645.png\n",
      "nyu_depth_images/image646.png\n",
      "nyu_depth_images/image647.png\n",
      "nyu_depth_images/image648.png\n",
      "nyu_depth_images/image649.png\n",
      "nyu_depth_images/image65.png\n",
      "nyu_depth_images/image650.png\n",
      "nyu_depth_images/image651.png\n",
      "nyu_depth_images/image652.png\n",
      "nyu_depth_images/image653.png\n",
      "nyu_depth_images/image654.png\n",
      "nyu_depth_images/image655.png\n",
      "nyu_depth_images/image656.png\n",
      "nyu_depth_images/image657.png\n",
      "nyu_depth_images/image658.png\n",
      "nyu_depth_images/image659.png\n",
      "nyu_depth_images/image66.png\n",
      "nyu_depth_images/image660.png\n",
      "nyu_depth_images/image661.png\n",
      "nyu_depth_images/image662.png\n",
      "nyu_depth_images/image663.png\n",
      "nyu_depth_images/image664.png\n",
      "nyu_depth_images/image665.png\n",
      "nyu_depth_images/image666.png\n",
      "nyu_depth_images/image667.png\n",
      "nyu_depth_images/image668.png\n",
      "nyu_depth_images/image669.png\n",
      "nyu_depth_images/image67.png\n",
      "nyu_depth_images/image670.png\n",
      "nyu_depth_images/image671.png\n",
      "nyu_depth_images/image672.png\n",
      "nyu_depth_images/image673.png\n",
      "nyu_depth_images/image674.png\n",
      "nyu_depth_images/image675.png\n",
      "nyu_depth_images/image676.png\n",
      "nyu_depth_images/image677.png\n",
      "nyu_depth_images/image678.png\n",
      "nyu_depth_images/image679.png\n",
      "nyu_depth_images/image68.png\n",
      "nyu_depth_images/image680.png\n",
      "nyu_depth_images/image681.png\n",
      "nyu_depth_images/image682.png\n",
      "nyu_depth_images/image683.png\n",
      "nyu_depth_images/image684.png\n",
      "nyu_depth_images/image685.png\n",
      "nyu_depth_images/image686.png\n",
      "nyu_depth_images/image687.png\n",
      "nyu_depth_images/image688.png\n",
      "nyu_depth_images/image689.png\n",
      "nyu_depth_images/image69.png\n",
      "nyu_depth_images/image690.png\n",
      "nyu_depth_images/image691.png\n",
      "nyu_depth_images/image692.png\n",
      "nyu_depth_images/image693.png\n",
      "nyu_depth_images/image694.png\n",
      "nyu_depth_images/image695.png\n",
      "nyu_depth_images/image696.png\n",
      "nyu_depth_images/image697.png\n",
      "nyu_depth_images/image698.png\n",
      "nyu_depth_images/image699.png\n",
      "nyu_depth_images/image7.png\n",
      "nyu_depth_images/image70.png\n",
      "nyu_depth_images/image700.png\n",
      "nyu_depth_images/image701.png\n",
      "nyu_depth_images/image702.png\n",
      "nyu_depth_images/image703.png\n",
      "nyu_depth_images/image704.png\n",
      "nyu_depth_images/image705.png\n",
      "nyu_depth_images/image706.png\n",
      "nyu_depth_images/image707.png\n",
      "nyu_depth_images/image708.png\n",
      "nyu_depth_images/image709.png\n",
      "nyu_depth_images/image71.png\n",
      "nyu_depth_images/image710.png\n",
      "nyu_depth_images/image711.png\n",
      "nyu_depth_images/image712.png\n",
      "nyu_depth_images/image713.png\n",
      "nyu_depth_images/image714.png\n",
      "nyu_depth_images/image715.png\n",
      "nyu_depth_images/image716.png\n",
      "nyu_depth_images/image717.png\n",
      "nyu_depth_images/image718.png\n",
      "nyu_depth_images/image719.png\n",
      "nyu_depth_images/image72.png\n",
      "nyu_depth_images/image720.png\n",
      "nyu_depth_images/image721.png\n",
      "nyu_depth_images/image722.png\n",
      "nyu_depth_images/image723.png\n",
      "nyu_depth_images/image724.png\n",
      "nyu_depth_images/image725.png\n",
      "nyu_depth_images/image726.png\n",
      "nyu_depth_images/image727.png\n",
      "nyu_depth_images/image728.png\n",
      "nyu_depth_images/image729.png\n",
      "nyu_depth_images/image73.png\n",
      "nyu_depth_images/image730.png\n",
      "nyu_depth_images/image731.png\n",
      "nyu_depth_images/image732.png\n",
      "nyu_depth_images/image733.png\n",
      "nyu_depth_images/image734.png\n",
      "nyu_depth_images/image735.png\n",
      "nyu_depth_images/image736.png\n",
      "nyu_depth_images/image737.png\n",
      "nyu_depth_images/image738.png\n",
      "nyu_depth_images/image739.png\n",
      "nyu_depth_images/image74.png\n",
      "nyu_depth_images/image740.png\n",
      "nyu_depth_images/image741.png\n",
      "nyu_depth_images/image742.png\n",
      "nyu_depth_images/image743.png\n",
      "nyu_depth_images/image744.png\n",
      "nyu_depth_images/image745.png\n",
      "nyu_depth_images/image746.png\n",
      "nyu_depth_images/image747.png\n",
      "nyu_depth_images/image748.png\n",
      "nyu_depth_images/image749.png\n",
      "nyu_depth_images/image75.png\n",
      "nyu_depth_images/image750.png\n",
      "nyu_depth_images/image751.png\n",
      "nyu_depth_images/image752.png\n",
      "nyu_depth_images/image753.png\n",
      "nyu_depth_images/image754.png\n",
      "nyu_depth_images/image755.png\n",
      "nyu_depth_images/image756.png\n",
      "nyu_depth_images/image757.png\n",
      "nyu_depth_images/image758.png\n",
      "nyu_depth_images/image759.png\n",
      "nyu_depth_images/image76.png\n",
      "nyu_depth_images/image760.png\n",
      "nyu_depth_images/image761.png\n",
      "nyu_depth_images/image762.png\n",
      "nyu_depth_images/image763.png\n",
      "nyu_depth_images/image764.png\n",
      "nyu_depth_images/image765.png\n",
      "nyu_depth_images/image766.png\n",
      "nyu_depth_images/image767.png\n",
      "nyu_depth_images/image768.png\n",
      "nyu_depth_images/image769.png\n",
      "nyu_depth_images/image77.png\n",
      "nyu_depth_images/image770.png\n",
      "nyu_depth_images/image771.png\n",
      "nyu_depth_images/image772.png\n",
      "nyu_depth_images/image773.png\n",
      "nyu_depth_images/image774.png\n",
      "nyu_depth_images/image775.png\n",
      "nyu_depth_images/image776.png\n",
      "nyu_depth_images/image777.png\n",
      "nyu_depth_images/image778.png\n",
      "nyu_depth_images/image779.png\n",
      "nyu_depth_images/image78.png\n",
      "nyu_depth_images/image780.png\n",
      "nyu_depth_images/image781.png\n",
      "nyu_depth_images/image782.png\n",
      "nyu_depth_images/image783.png\n",
      "nyu_depth_images/image784.png\n",
      "nyu_depth_images/image785.png\n",
      "nyu_depth_images/image786.png\n",
      "nyu_depth_images/image787.png\n",
      "nyu_depth_images/image788.png\n",
      "nyu_depth_images/image789.png\n",
      "nyu_depth_images/image79.png\n",
      "nyu_depth_images/image790.png\n",
      "nyu_depth_images/image791.png\n",
      "nyu_depth_images/image792.png\n",
      "nyu_depth_images/image793.png\n",
      "nyu_depth_images/image794.png\n",
      "nyu_depth_images/image795.png\n",
      "nyu_depth_images/image796.png\n",
      "nyu_depth_images/image797.png\n",
      "nyu_depth_images/image798.png\n",
      "nyu_depth_images/image799.png\n",
      "nyu_depth_images/image8.png\n",
      "nyu_depth_images/image80.png\n",
      "nyu_depth_images/image800.png\n",
      "nyu_depth_images/image801.png\n",
      "nyu_depth_images/image802.png\n",
      "nyu_depth_images/image803.png\n",
      "nyu_depth_images/image804.png\n",
      "nyu_depth_images/image805.png\n",
      "nyu_depth_images/image806.png\n",
      "nyu_depth_images/image807.png\n",
      "nyu_depth_images/image808.png\n",
      "nyu_depth_images/image809.png\n",
      "nyu_depth_images/image81.png\n",
      "nyu_depth_images/image810.png\n",
      "nyu_depth_images/image811.png\n",
      "nyu_depth_images/image812.png\n",
      "nyu_depth_images/image813.png\n",
      "nyu_depth_images/image814.png\n",
      "nyu_depth_images/image815.png\n",
      "nyu_depth_images/image816.png\n",
      "nyu_depth_images/image817.png\n",
      "nyu_depth_images/image818.png\n",
      "nyu_depth_images/image819.png\n",
      "nyu_depth_images/image82.png\n",
      "nyu_depth_images/image820.png\n",
      "nyu_depth_images/image821.png\n",
      "nyu_depth_images/image822.png\n",
      "nyu_depth_images/image823.png\n",
      "nyu_depth_images/image824.png\n",
      "nyu_depth_images/image825.png\n",
      "nyu_depth_images/image826.png\n",
      "nyu_depth_images/image827.png\n",
      "nyu_depth_images/image828.png\n",
      "nyu_depth_images/image829.png\n",
      "nyu_depth_images/image83.png\n",
      "nyu_depth_images/image830.png\n",
      "nyu_depth_images/image831.png\n",
      "nyu_depth_images/image832.png\n",
      "nyu_depth_images/image833.png\n",
      "nyu_depth_images/image834.png\n",
      "nyu_depth_images/image835.png\n",
      "nyu_depth_images/image836.png\n",
      "nyu_depth_images/image837.png\n",
      "nyu_depth_images/image838.png\n",
      "nyu_depth_images/image839.png\n",
      "nyu_depth_images/image84.png\n",
      "nyu_depth_images/image840.png\n",
      "nyu_depth_images/image841.png\n",
      "nyu_depth_images/image842.png\n",
      "nyu_depth_images/image843.png\n",
      "nyu_depth_images/image844.png\n",
      "nyu_depth_images/image845.png\n",
      "nyu_depth_images/image846.png\n",
      "nyu_depth_images/image847.png\n",
      "nyu_depth_images/image848.png\n",
      "nyu_depth_images/image849.png\n",
      "nyu_depth_images/image85.png\n",
      "nyu_depth_images/image850.png\n",
      "nyu_depth_images/image851.png\n",
      "nyu_depth_images/image852.png\n",
      "nyu_depth_images/image853.png\n",
      "nyu_depth_images/image854.png\n",
      "nyu_depth_images/image855.png\n",
      "nyu_depth_images/image856.png\n",
      "nyu_depth_images/image857.png\n",
      "nyu_depth_images/image858.png\n",
      "nyu_depth_images/image859.png\n",
      "nyu_depth_images/image86.png\n",
      "nyu_depth_images/image860.png\n",
      "nyu_depth_images/image861.png\n",
      "nyu_depth_images/image862.png\n",
      "nyu_depth_images/image863.png\n",
      "nyu_depth_images/image864.png\n",
      "nyu_depth_images/image865.png\n",
      "nyu_depth_images/image866.png\n",
      "nyu_depth_images/image867.png\n",
      "nyu_depth_images/image868.png\n",
      "nyu_depth_images/image869.png\n",
      "nyu_depth_images/image87.png\n",
      "nyu_depth_images/image870.png\n",
      "nyu_depth_images/image871.png\n",
      "nyu_depth_images/image872.png\n",
      "nyu_depth_images/image873.png\n",
      "nyu_depth_images/image874.png\n",
      "nyu_depth_images/image875.png\n",
      "nyu_depth_images/image876.png\n",
      "nyu_depth_images/image877.png\n",
      "nyu_depth_images/image878.png\n",
      "nyu_depth_images/image879.png\n",
      "nyu_depth_images/image88.png\n",
      "nyu_depth_images/image880.png\n",
      "nyu_depth_images/image881.png\n",
      "nyu_depth_images/image882.png\n",
      "nyu_depth_images/image883.png\n",
      "nyu_depth_images/image884.png\n",
      "nyu_depth_images/image885.png\n",
      "nyu_depth_images/image886.png\n",
      "nyu_depth_images/image887.png\n",
      "nyu_depth_images/image888.png\n",
      "nyu_depth_images/image889.png\n",
      "nyu_depth_images/image89.png\n",
      "nyu_depth_images/image890.png\n",
      "nyu_depth_images/image891.png\n",
      "nyu_depth_images/image892.png\n",
      "nyu_depth_images/image893.png\n",
      "nyu_depth_images/image894.png\n",
      "nyu_depth_images/image895.png\n",
      "nyu_depth_images/image896.png\n",
      "nyu_depth_images/image897.png\n",
      "nyu_depth_images/image898.png\n",
      "nyu_depth_images/image899.png\n",
      "nyu_depth_images/image9.png\n",
      "nyu_depth_images/image90.png\n",
      "nyu_depth_images/image900.png\n",
      "nyu_depth_images/image901.png\n",
      "nyu_depth_images/image902.png\n",
      "nyu_depth_images/image903.png\n",
      "nyu_depth_images/image904.png\n",
      "nyu_depth_images/image905.png\n",
      "nyu_depth_images/image906.png\n",
      "nyu_depth_images/image907.png\n",
      "nyu_depth_images/image908.png\n",
      "nyu_depth_images/image909.png\n",
      "nyu_depth_images/image91.png\n",
      "nyu_depth_images/image910.png\n",
      "nyu_depth_images/image911.png\n",
      "nyu_depth_images/image912.png\n",
      "nyu_depth_images/image913.png\n",
      "nyu_depth_images/image914.png\n",
      "nyu_depth_images/image915.png\n",
      "nyu_depth_images/image916.png\n",
      "nyu_depth_images/image917.png\n",
      "nyu_depth_images/image918.png\n",
      "nyu_depth_images/image919.png\n",
      "nyu_depth_images/image92.png\n",
      "nyu_depth_images/image920.png\n",
      "nyu_depth_images/image921.png\n",
      "nyu_depth_images/image922.png\n",
      "nyu_depth_images/image923.png\n",
      "nyu_depth_images/image924.png\n",
      "nyu_depth_images/image925.png\n",
      "nyu_depth_images/image926.png\n",
      "nyu_depth_images/image927.png\n",
      "nyu_depth_images/image928.png\n",
      "nyu_depth_images/image929.png\n",
      "nyu_depth_images/image93.png\n",
      "nyu_depth_images/image930.png\n",
      "nyu_depth_images/image931.png\n",
      "nyu_depth_images/image932.png\n",
      "nyu_depth_images/image933.png\n",
      "nyu_depth_images/image934.png\n",
      "nyu_depth_images/image935.png\n",
      "nyu_depth_images/image936.png\n",
      "nyu_depth_images/image937.png\n",
      "nyu_depth_images/image938.png\n",
      "nyu_depth_images/image939.png\n",
      "nyu_depth_images/image94.png\n",
      "nyu_depth_images/image940.png\n",
      "nyu_depth_images/image941.png\n",
      "nyu_depth_images/image942.png\n",
      "nyu_depth_images/image943.png\n",
      "nyu_depth_images/image944.png\n",
      "nyu_depth_images/image945.png\n",
      "nyu_depth_images/image946.png\n",
      "nyu_depth_images/image947.png\n",
      "nyu_depth_images/image948.png\n",
      "nyu_depth_images/image949.png\n",
      "nyu_depth_images/image95.png\n",
      "nyu_depth_images/image950.png\n",
      "nyu_depth_images/image951.png\n",
      "nyu_depth_images/image952.png\n",
      "nyu_depth_images/image953.png\n",
      "nyu_depth_images/image954.png\n",
      "nyu_depth_images/image955.png\n",
      "nyu_depth_images/image956.png\n",
      "nyu_depth_images/image957.png\n",
      "nyu_depth_images/image958.png\n",
      "nyu_depth_images/image959.png\n",
      "nyu_depth_images/image96.png\n",
      "nyu_depth_images/image960.png\n",
      "nyu_depth_images/image961.png\n",
      "nyu_depth_images/image962.png\n",
      "nyu_depth_images/image963.png\n",
      "nyu_depth_images/image964.png\n",
      "nyu_depth_images/image965.png\n",
      "nyu_depth_images/image966.png\n",
      "nyu_depth_images/image967.png\n",
      "nyu_depth_images/image968.png\n",
      "nyu_depth_images/image969.png\n",
      "nyu_depth_images/image97.png\n",
      "nyu_depth_images/image970.png\n",
      "nyu_depth_images/image971.png\n",
      "nyu_depth_images/image972.png\n",
      "nyu_depth_images/image973.png\n",
      "nyu_depth_images/image974.png\n",
      "nyu_depth_images/image975.png\n",
      "nyu_depth_images/image976.png\n",
      "nyu_depth_images/image977.png\n",
      "nyu_depth_images/image978.png\n",
      "nyu_depth_images/image979.png\n",
      "nyu_depth_images/image98.png\n",
      "nyu_depth_images/image980.png\n",
      "nyu_depth_images/image981.png\n",
      "nyu_depth_images/image982.png\n",
      "nyu_depth_images/image983.png\n",
      "nyu_depth_images/image984.png\n",
      "nyu_depth_images/image985.png\n",
      "nyu_depth_images/image986.png\n",
      "nyu_depth_images/image987.png\n",
      "nyu_depth_images/image988.png\n",
      "nyu_depth_images/image989.png\n",
      "nyu_depth_images/image99.png\n",
      "nyu_depth_images/image990.png\n",
      "nyu_depth_images/image991.png\n",
      "nyu_depth_images/image992.png\n",
      "nyu_depth_images/image993.png\n",
      "nyu_depth_images/image994.png\n",
      "nyu_depth_images/image995.png\n",
      "nyu_depth_images/image996.png\n",
      "nyu_depth_images/image997.png\n",
      "nyu_depth_images/image998.png\n",
      "nyu_depth_images/image999.png\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf  '/content/drive/MyDrive/Copy of nyu_depth_images.tar' -C './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jv0BwQnKV5Cp",
    "outputId": "3deb2b5a-fc4a-4915-f9c3-3e918fd79f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n",
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
      "\u001b[K     || 2.1MB 7.2MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     || 901kB 35.1MB/s \n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     || 3.3MB 55.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Installing collected packages: sacremoses, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n",
      "Collecting gputil\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
      "Building wheels for collected packages: gputil\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=cbd8cf9a1c51bbf8f89d8a481fa316aee4df341c4317f417db83db42c6e87217\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
      "Successfully built gputil\n",
      "Installing collected packages: gputil\n",
      "Successfully installed gputil-1.4.0\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U keras\n",
    "!pip install transformers\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xx51KqLc0F2z",
    "outputId": "0af8376c-88e7-4681-c95f-2c8411f6ca98"
   },
   "outputs": [],
   "source": [
    "import os, re, random, zipfile, pickle, torch, logging\n",
    "import numpy as np, torch.nn as nn, pandas as pd,\\\n",
    "torch.nn.functional as F, matplotlib.pyplot as plt,\\\n",
    "seaborn as sn\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot, Tokenizer\n",
    "from time import time, sleep\n",
    "from models import SelfVQA\n",
    "from string import punctuation\n",
    "from torch.optim import SGD, Adam, lr_scheduler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import (\n",
    "    TensorDataset,\n",
    "    Dataset,\n",
    "    DataLoader, \n",
    "    Subset, \n",
    "    RandomSampler, SequentialSampler\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, \n",
    "    roc_auc_score, \n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "from PIL import Image, ImageFilter, ImageDraw\n",
    "from torchvision.models import vgg16_bn\n",
    "from torchvision.transforms import ToTensor\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "# from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jrvfA5p09NJO"
   },
   "outputs": [],
   "source": [
    "def download_dirs(dirlist):\n",
    "    from google.colab import files\n",
    "    for dirname in dirlist:\n",
    "        for filename in os.listdir(dirname):\n",
    "            filename = os.path.join(dirname, filename)\n",
    "            files.download(filename)\n",
    "            \n",
    "def get_dataLoader(dataset, splits, batch_sizes, shuffle_indices, **kwargs):\n",
    "    n_samples = len(dataset)\n",
    "    indices = list(range(n_samples))\n",
    "    if shuffle_indices:\n",
    "        np.random.shuffle(indices)\n",
    "    split_index = int(n_samples*splits[0])\n",
    "    train_indices = indices[:split_index]\n",
    "    valid_indices = indices[split_index:]\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    valid_dataset = Subset(dataset, valid_indices)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, shuffle=True, batch_size=batch_sizes[0], **kwargs\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, shuffle=False, batch_size=batch_sizes[1], **kwargs\n",
    "    )\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def fix_seed(seed_value, random_lib=False, numpy_lib=False, torch_lib=False):\n",
    "    if random_lib:\n",
    "        random.seed(seed_value)\n",
    "    if numpy_lib:\n",
    "        np.random.seed(seed_value)\n",
    "    if torch_lib:\n",
    "        torch.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def setup_logger(name, format=None, level=logging.DEBUG, handlers=None, log_file='default.log'):\n",
    "    logging.basicConfig(\n",
    "        level=level, \n",
    "        format=format if format else '%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=handlers if handlers else [\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "\n",
    "def cal_accuracy(pred_labels, true_labels):\n",
    "    _, pred_labels = pred_labels.max(dim=1)\n",
    "    true_labels = true_labels.view(-1)\n",
    "    return torch.sum(pred_labels == true_labels).item() / true_labels.size()[0]\n",
    "\n",
    "def cal_wups(pred_labels, true_labels, label2word):\n",
    "    print(pred_labels)\n",
    "    print(true_labels)\n",
    "    pred_labels = pred_labels.tolist()\n",
    "    true_labels = true_labels.tolist()\n",
    "    wups_scores = []\n",
    "    for i in range(len(pred_labels)):\n",
    "        pred_syn = wordnet.synsets(label2word[pred_labels[i]])\n",
    "        true_syn = wordnet.synsets(label2word[true_labels[i]])\n",
    "        mid_score = []\n",
    "        for psyn in pred_syn:\n",
    "            for tsyn in true_syn:\n",
    "                score = psyn.wup_similarity(tsyn)\n",
    "                if score:\n",
    "                    mid_score.append(score)\n",
    "        mean_score = np.mean(mid_score)\n",
    "        if not np.isnan(mean_score):\n",
    "            wups_scores.append(mean_score)\n",
    "    return np.mean(wups_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Jvz4oivi8vQ1"
   },
   "outputs": [],
   "source": [
    "class SelfDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ant_df, images_dir, tokenizer=None, transform=ToTensor()):\n",
    "        self.ant_df = ant_df\n",
    "        self.encoded_matrix, self.vocab_size, self.tokenizer = encode_txt(\n",
    "            list(ant_df.question.values), tokenizer\n",
    "        )\n",
    "        self.encoded_matrix = torch.as_tensor(self.encoded_matrix)\n",
    "        self.image_names = list(ant_df.image_name.values)\n",
    "        self.images_dir = images_dir\n",
    "        self.labels = torch.as_tensor(ant_df.answer_id.values)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        question = self.encoded_matrix[item]\n",
    "        image_name = os.path.join(self.images_dir, self.image_names[item])\n",
    "        img = Image.open(image_name)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[item]\n",
    "        return question, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "class TrainTest():\n",
    "    def __init__(self, model, optimizer, scheduler, criterion, logger=None):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.criterion = criterion\n",
    "        self.logger = logger\n",
    "        self.tr_metrics = {\n",
    "            'train_loss':[],\n",
    "            'train_accuracy':[],\n",
    "            'valid_loss':[],\n",
    "            'valid_accuracy':[],\n",
    "        }\n",
    "        \n",
    "    def train(\n",
    "        self, train_loader, valid_loader, \n",
    "        num_epochs, device, eval_interval,\n",
    "        clip=None, model_path=None, save_per_epoch=None,\n",
    "        results_path=None, defaults=None, **kwargs\n",
    "    ):\n",
    "        total_itrs = num_epochs*len(train_loader)\n",
    "        num_tr, total_tr_loss, itr = 0, 0, 0\n",
    "        self.model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (questions, imgs, labels) in enumerate(train_loader):\n",
    "                questions = questions.to(device)\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(\n",
    "                    questions,\n",
    "                    imgs\n",
    "                )\n",
    "                tr_loss = self.criterion(output, labels.view(-1))\n",
    "                # nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                if self.logger:\n",
    "                    self.logger.info(f'Training: {itr}/{total_itrs} -- loss: {tr_loss.item()}')\n",
    "                tr_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                num_tr += 1\n",
    "                total_tr_loss += tr_loss\n",
    "                if itr % eval_interval == 0 or itr+1 == total_itrs:\n",
    "                    self.tr_metrics['train_loss'].append(total_tr_loss.cpu().item()/num_tr)\n",
    "                    tr_accuracy = cal_accuracy(output, labels)\n",
    "                    self.tr_metrics['train_accuracy'].append(tr_accuracy)\n",
    "                    num_tr, total_tr_loss = 0, 0\n",
    "                    val_loss = 0\n",
    "                    self.model.eval()\n",
    "                    val_accuracy = []\n",
    "                    with torch.no_grad():\n",
    "                        for i, (val_questions, val_imgs, val_labels) in enumerate(valid_loader):\n",
    "                            val_questions = val_questions.to(device)\n",
    "                            val_imgs = val_imgs.to(device)\n",
    "                            val_labels = val_labels.to(device)\n",
    "                            self.optimizer.zero_grad()\n",
    "                            val_output = self.model(\n",
    "                                val_questions,\n",
    "                                val_imgs\n",
    "                            )\n",
    "                            val_loss += self.criterion(val_output, val_labels.view(-1))\n",
    "                            val_accuracy.append(cal_accuracy(val_output, val_labels))\n",
    "                    self.tr_metrics['valid_accuracy'].append(np.mean(val_accuracy))\n",
    "                    self.tr_metrics['valid_loss'].append(val_loss.cpu().item()/len(valid_loader))\n",
    "                    self.model.train()\n",
    "                    if self.logger:\n",
    "                        self.logger.info(f'Training: iteration: {itr}/{total_itrs} -- epoch: {epoch} -- '\n",
    "                        f' train_loss: {self.tr_metrics[\"train_loss\"][-1]:.3f} -- train_accuracy: {self.tr_metrics[\"train_accuracy\"][-1]:.2f}'\n",
    "                        f' valid_loss: {self.tr_metrics[\"valid_loss\"][-1]:.3f} -- valid_accuracy: {self.tr_metrics[\"valid_accuracy\"][-1]:.2f}')\n",
    "                itr += 1\n",
    "            if model_path and results_path and ((epoch+1) % save_per_epoch == 0) and epoch != 0:\n",
    "                self.save_model(epoch+1, model_path, f'{epoch+1}_epochs_train')\n",
    "                self.save_results(results_path, f'{epoch+1}_epochs_train', self.tr_metrics)\n",
    "        if model_path and results_path:\n",
    "            self.save_model(epoch+1, model_path, f'{epoch+1}_epochs_last_train')\n",
    "            self.save_results(results_path, f'{epoch+1}_epochs_last_train', self.tr_metrics)\n",
    "            \n",
    "    def save_model(self, epoch, model_path, name):\n",
    "        model_dir = '/'.join(model_path.split('/')[:-1])\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "                'loss': self.tr_metrics['valid_loss'][-1],\n",
    "            }, os.path.join(model_dir, f'model_{name}.pt')\n",
    "        )\n",
    "        if self.logger:\n",
    "            self.logger.info(f'Training: model saved to: {model_dir}/model_{name}.pt')\n",
    "    \n",
    "    def save_results(self, results_path, name, results):\n",
    "        results_dir = '/'.join(results_path.split('/')[:-1])\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.makedirs(results_dir)\n",
    "        with open(os.path.join(results_dir, f'results_{name}.pkl'), 'wb') as save_file:\n",
    "            pickle.dump(results, save_file)\n",
    "        if self.logger:\n",
    "            self.logger.info(f'Training: results saved to: {results_dir}/resutls_{name}.pkl')\n",
    "\n",
    "    def test(self, test_loader, device, label2word, results_path=None, defaults=None):\n",
    "        test_accuracy, test_true, test_pred = [], [], []\n",
    "        test_loss = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (test_questions, test_imgs, test_labels) in enumerate(test_loader):\n",
    "                test_questions = test_questions.to(device)\n",
    "                test_imgs = test_imgs.to(device)\n",
    "                test_labels = test_labels.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "                test_output = self.model(\n",
    "                    test_questions,\n",
    "                    test_imgs\n",
    "                )\n",
    "                test_loss += self.criterion(test_output, test_labels.view(-1))\n",
    "                test_accuracy.append(cal_accuracy(test_output, test_labels))\n",
    "                test_true.append(test_labels.cpu())\n",
    "                test_pred.append(test_output.cpu().max(dim=1)[1])\n",
    "        test_true = torch.cat(test_true)\n",
    "        test_pred = torch.cat(test_pred)\n",
    "        test_loss = test_loss.cpu().item()/len(test_loader)\n",
    "        test_accuracy = np.mean(test_accuracy)\n",
    "        test_wups = cal_wups(test_pred, test_true, label2word)\n",
    "        prf = precision_recall_fscore_support(\n",
    "            test_true,\n",
    "            test_pred,\n",
    "            labels=list(label2word.keys()),\n",
    "            average='weighted'\n",
    "        )\n",
    "        confm = confusion_matrix(test_true, test_pred, labels=list(label2word.keys()))\n",
    "        self.ts_metrics = {\n",
    "            'loss':test_loss,\n",
    "            'accuracy':test_accuracy,\n",
    "            'wups':test_wups,\n",
    "            'precision':prf[0],\n",
    "            'recall':prf[1],\n",
    "            'f1_score':prf[2],\n",
    "            'confusion_matrix':confm\n",
    "        }\n",
    "        if self.logger:\n",
    "            print(f'Testing: test_loss: {test_loss:.3f} -- test_accurcy: {test_accuracy:.2f} -- test_wups: {test_wups:.2f}')\n",
    "        if results_path:\n",
    "            self.save_results(results_path, f'test', self.ts_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Z2VLMy3c7C8A"
   },
   "outputs": [],
   "source": [
    "def resize_images(resize_shape, images_path, img_dist_path='rescaled_images'):\n",
    "    if not os.path.exists(img_dist_path):\n",
    "        os.makedirs(img_dist_path)\n",
    "    else: return img_dist_path\n",
    "    image_names = sorted(os.listdir(images_path))\n",
    "    img_counter = 0\n",
    "    for img_file in image_names:\n",
    "        img = Image.open(os.path.join(images_path, img_file))\n",
    "        img.thumbnail(resize_shape, Image.ANTIALIAS)\n",
    "        new_path = os.path.join(img_dist_path, img_file)\n",
    "        img.save(new_path, format='PNG')\n",
    "        img_counter += 1\n",
    "    return img_dist_path\n",
    "\n",
    "def create_df(file_path, answer_mapping=None):\n",
    "    with open(file_path, 'r') as annotation_file:\n",
    "        questions = []\n",
    "        answers = []\n",
    "        image_names = []\n",
    "        chars = set('_,')\n",
    "        lines = annotation_file.readlines()\n",
    "        for i in range(0, len(lines)-1, 2):\n",
    "            question = lines[i].strip().split()\n",
    "            answer = lines[i+1].strip()\n",
    "            if answer_mapping and answer not in answer_mapping.keys():\n",
    "                continue\n",
    "            if not any((c in chars) for c in answer):\n",
    "                image_name = question.pop(-2)\n",
    "                image_names.append(image_name[image_name.index('image'):]+'.png')\n",
    "                answers.append(answer)\n",
    "                questions.append(' '.join(question[:-3])+'?')\n",
    "    df = pd.DataFrame(\n",
    "        list(zip(image_names, questions, answers)), columns=['image_name', 'question', 'answer']\n",
    "    ).sort_values(['image_name']).reset_index(drop=True)\n",
    "    valid_answers = np.sort(df.answer.unique())\n",
    "    if not answer_mapping:\n",
    "        answer_mapping = dict(zip(valid_answers, range(len(valid_answers))))\n",
    "    df['answer_id'] = df.answer.apply(lambda x: answer_mapping[x])\n",
    "    return df, answer_mapping\n",
    "\n",
    "def encode_txt(txt_list, tokenizer=None):\n",
    "    if tokenizer is None:\n",
    "        print('train tokenizer')\n",
    "        tokenizer = Tokenizer(oov_token='OOV')\n",
    "        tokenizer.fit_on_texts(txt_list)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    encoded_txt = tokenizer.texts_to_sequences(txt_list)\n",
    "    encoded_matrix = pad_sequences(\n",
    "        encoded_txt,\n",
    "        padding='pre',\n",
    "        truncating='pre'\n",
    "    )\n",
    "    return encoded_matrix, vocab_size, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "B2g9gu5TA1xl"
   },
   "outputs": [],
   "source": [
    "cuda_flag = True if torch.cuda.is_available() else False\n",
    "lrlast = .001\n",
    "lrmain = .00001\n",
    "n_iters = 10000\n",
    "num_epochs = 12\n",
    "eval_interval = 150\n",
    "save_model = True\n",
    "device = torch.device('cuda' if cuda_flag else 'cpu')\n",
    "params = {'num_workers': 2, 'pin_memory': True} if cuda_flag else {}\n",
    "data_splits = [0.9, 0.1]\n",
    "batch_sizes = [8, 8]\n",
    "seed = 20214\n",
    "fix_seed(seed, random_lib=True, numpy_lib=True, torch_lib=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Path to images directory and annotation files for training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAuiTepM7C8F",
    "outputId": "123cb64d-e4bd-472a-82ce-3a1cc0f95098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train tokenizer\n"
     ]
    }
   ],
   "source": [
    "resize_shape = (200, 200)\n",
    "resized_dir = resize_images(resize_shape, './nyu_depth_images/', './rescaled_images/')\n",
    "tr_ant_path = './qa.894.raw.train.txt'\n",
    "train_df, answer_mapping = create_df(tr_ant_path)\n",
    "label2word = {v: k for k, v in answer_mapping.items()}\n",
    "train_dataset = SelfDataset(train_df, resized_dir)\n",
    "ts_ant_path = './qa.894.raw.test.txt'\n",
    "test_df, _ = create_df(ts_ant_path, answer_mapping)\n",
    "test_dataset = SelfDataset(test_df, resized_dir, train_dataset.tokenizer)\n",
    "\n",
    "train_loader, valid_loader = get_dataLoader(\n",
    "    train_dataset,\n",
    "    data_splits,\n",
    "    batch_sizes,\n",
    "    shuffle_indices=True, **params\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, shuffle=False, batch_size=8, **params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set path to GloVe 300d embedding fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tD2iey147C8F"
   },
   "outputs": [],
   "source": [
    "embedded_words = dict()\n",
    "glove_path = '/content/drive/MyDrive/Copy of glove.42B.300d.txt'\n",
    "glove_file = open(glove_path)\n",
    "for line in glove_file:\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    words_weights = np.array(values[1:], dtype='float32')\n",
    "    embedded_words[word] = words_weights\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kqsWTz0T7C8G"
   },
   "outputs": [],
   "source": [
    "mean_embedding = np.array(list(embedded_words.values())).mean(axis=0)\n",
    "embedding_dim = len(embedded_words[next(iter(embedded_words))])\n",
    "embedding_matrix = np.zeros((train_dataset.vocab_size, embedding_dim))\n",
    "for word, index in train_dataset.tokenizer.word_index.items():\n",
    "    embedding_vector = embedded_words.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "    else:\n",
    "        embedding_matrix[index] = mean_embedding\n",
    "\n",
    "del embedded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HG_U5XhY7C8G",
    "outputId": "b50a2c93-3972-4b89-a214-51195d2a9e69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "output_size = len(answer_mapping)\n",
    "hidden_dim = 150\n",
    "n_layers = 1\n",
    "lstm_drop = 0.5\n",
    "\n",
    "model = SelfVQA(\n",
    "    train_dataset.vocab_size,\n",
    "    output_size,\n",
    "    embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    lstm_drop,\n",
    "    bidirectional=True\n",
    ").to(device)\n",
    "\n",
    "embedding_matrix = torch.as_tensor(embedding_matrix, dtype=torch.float)\n",
    "model.embedding.weight.data.copy_(embedding_matrix)\n",
    "model.embedding.weight.requires_grad=False\n",
    "for param in model.vgg.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "kceZqSSm7C8K"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = SGD(model.parameters(), lr=lrmain)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_epochs*len(train_loader),\n",
    ")\n",
    "open('metrics.log', 'w').close()\n",
    "logger = setup_logger(name='track_logger', level=logging.INFO, log_file='metrics.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIp1i2JfDVzV",
    "outputId": "e17d3189-1198-4903-98d6-f0d4ce87be6c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "2021-04-25 17:51:36,698 [INFO] Training: 1890/6852 -- loss: 2.6486988067626953\n",
      "2021-04-25 17:51:36,747 [INFO] Training: 1891/6852 -- loss: 3.3164992332458496\n",
      "2021-04-25 17:51:36,796 [INFO] Training: 1892/6852 -- loss: 2.936614513397217\n",
      "2021-04-25 17:51:36,848 [INFO] Training: 1893/6852 -- loss: 2.658435344696045\n",
      "2021-04-25 17:51:36,896 [INFO] Training: 1894/6852 -- loss: 2.699702024459839\n",
      "2021-04-25 17:51:36,944 [INFO] Training: 1895/6852 -- loss: 2.7893033027648926\n",
      "2021-04-25 17:51:36,992 [INFO] Training: 1896/6852 -- loss: 2.677666664123535\n",
      "2021-04-25 17:51:37,042 [INFO] Training: 1897/6852 -- loss: 2.81429386138916\n",
      "2021-04-25 17:51:37,091 [INFO] Training: 1898/6852 -- loss: 2.023453712463379\n",
      "2021-04-25 17:51:37,142 [INFO] Training: 1899/6852 -- loss: 4.038838863372803\n",
      "2021-04-25 17:51:37,190 [INFO] Training: 1900/6852 -- loss: 3.213956594467163\n",
      "2021-04-25 17:51:37,239 [INFO] Training: 1901/6852 -- loss: 3.5561327934265137\n",
      "2021-04-25 17:51:37,286 [INFO] Training: 1902/6852 -- loss: 3.845473527908325\n",
      "2021-04-25 17:51:37,338 [INFO] Training: 1903/6852 -- loss: 3.165809392929077\n",
      "2021-04-25 17:51:37,388 [INFO] Training: 1904/6852 -- loss: 2.648715019226074\n",
      "2021-04-25 17:51:37,437 [INFO] Training: 1905/6852 -- loss: 4.129256248474121\n",
      "2021-04-25 17:51:37,484 [INFO] Training: 1906/6852 -- loss: 2.835071086883545\n",
      "2021-04-25 17:51:37,531 [INFO] Training: 1907/6852 -- loss: 3.1097779273986816\n",
      "2021-04-25 17:51:37,582 [INFO] Training: 1908/6852 -- loss: 2.99920654296875\n",
      "2021-04-25 17:51:37,630 [INFO] Training: 1909/6852 -- loss: 2.785383939743042\n",
      "2021-04-25 17:51:37,678 [INFO] Training: 1910/6852 -- loss: 3.9113240242004395\n",
      "2021-04-25 17:51:37,727 [INFO] Training: 1911/6852 -- loss: 3.3259992599487305\n",
      "2021-04-25 17:51:37,774 [INFO] Training: 1912/6852 -- loss: 2.6345489025115967\n",
      "2021-04-25 17:51:37,823 [INFO] Training: 1913/6852 -- loss: 2.485043525695801\n",
      "2021-04-25 17:51:37,870 [INFO] Training: 1914/6852 -- loss: 3.1364903450012207\n",
      "2021-04-25 17:51:37,919 [INFO] Training: 1915/6852 -- loss: 3.561274528503418\n",
      "2021-04-25 17:51:37,971 [INFO] Training: 1916/6852 -- loss: 3.143073081970215\n",
      "2021-04-25 17:51:38,023 [INFO] Training: 1917/6852 -- loss: 2.9029414653778076\n",
      "2021-04-25 17:51:38,071 [INFO] Training: 1918/6852 -- loss: 4.228684902191162\n",
      "2021-04-25 17:51:38,123 [INFO] Training: 1919/6852 -- loss: 3.2241265773773193\n",
      "2021-04-25 17:51:38,174 [INFO] Training: 1920/6852 -- loss: 2.3697943687438965\n",
      "2021-04-25 17:51:38,222 [INFO] Training: 1921/6852 -- loss: 3.0294675827026367\n",
      "2021-04-25 17:51:38,272 [INFO] Training: 1922/6852 -- loss: 1.5458290576934814\n",
      "2021-04-25 17:51:38,321 [INFO] Training: 1923/6852 -- loss: 3.4699106216430664\n",
      "2021-04-25 17:51:38,370 [INFO] Training: 1924/6852 -- loss: 2.395556688308716\n",
      "2021-04-25 17:51:38,422 [INFO] Training: 1925/6852 -- loss: 2.668881416320801\n",
      "2021-04-25 17:51:38,473 [INFO] Training: 1926/6852 -- loss: 2.612302303314209\n",
      "2021-04-25 17:51:38,522 [INFO] Training: 1927/6852 -- loss: 3.0442023277282715\n",
      "2021-04-25 17:51:38,575 [INFO] Training: 1928/6852 -- loss: 2.3437552452087402\n",
      "2021-04-25 17:51:38,624 [INFO] Training: 1929/6852 -- loss: 2.649787425994873\n",
      "2021-04-25 17:51:38,679 [INFO] Training: 1930/6852 -- loss: 2.7258682250976562\n",
      "2021-04-25 17:51:38,725 [INFO] Training: 1931/6852 -- loss: 2.5196352005004883\n",
      "2021-04-25 17:51:38,773 [INFO] Training: 1932/6852 -- loss: 2.7504053115844727\n",
      "2021-04-25 17:51:38,821 [INFO] Training: 1933/6852 -- loss: 2.8968734741210938\n",
      "2021-04-25 17:51:38,869 [INFO] Training: 1934/6852 -- loss: 2.55304217338562\n",
      "2021-04-25 17:51:38,917 [INFO] Training: 1935/6852 -- loss: 2.5856895446777344\n",
      "2021-04-25 17:51:38,965 [INFO] Training: 1936/6852 -- loss: 2.2572877407073975\n",
      "2021-04-25 17:51:39,018 [INFO] Training: 1937/6852 -- loss: 2.3470733165740967\n",
      "2021-04-25 17:51:39,065 [INFO] Training: 1938/6852 -- loss: 3.3384249210357666\n",
      "2021-04-25 17:51:39,115 [INFO] Training: 1939/6852 -- loss: 1.7039183378219604\n",
      "2021-04-25 17:51:39,166 [INFO] Training: 1940/6852 -- loss: 2.0604443550109863\n",
      "2021-04-25 17:51:39,216 [INFO] Training: 1941/6852 -- loss: 2.622241258621216\n",
      "2021-04-25 17:51:39,265 [INFO] Training: 1942/6852 -- loss: 3.0832293033599854\n",
      "2021-04-25 17:51:39,318 [INFO] Training: 1943/6852 -- loss: 3.663248062133789\n",
      "2021-04-25 17:51:39,367 [INFO] Training: 1944/6852 -- loss: 2.9301559925079346\n",
      "2021-04-25 17:51:39,417 [INFO] Training: 1945/6852 -- loss: 2.9770145416259766\n",
      "2021-04-25 17:51:39,466 [INFO] Training: 1946/6852 -- loss: 2.373887538909912\n",
      "2021-04-25 17:51:39,514 [INFO] Training: 1947/6852 -- loss: 3.0170814990997314\n",
      "2021-04-25 17:51:39,566 [INFO] Training: 1948/6852 -- loss: 2.674607276916504\n",
      "2021-04-25 17:51:39,619 [INFO] Training: 1949/6852 -- loss: 2.2179179191589355\n",
      "2021-04-25 17:51:39,669 [INFO] Training: 1950/6852 -- loss: 2.6363940238952637\n",
      "2021-04-25 17:51:42,501 [INFO] Training: iteration: 1950/6852 -- epoch: 3 --  train_loss: 2.869 -- train_accuracy: 0.38 valid_loss: 3.154 -- valid_accuracy: 0.23\n",
      "2021-04-25 17:51:42,541 [INFO] Training: 1951/6852 -- loss: 2.920090675354004\n",
      "2021-04-25 17:51:42,591 [INFO] Training: 1952/6852 -- loss: 2.941899299621582\n",
      "2021-04-25 17:51:42,643 [INFO] Training: 1953/6852 -- loss: 2.926525592803955\n",
      "2021-04-25 17:51:42,691 [INFO] Training: 1954/6852 -- loss: 2.4626686573028564\n",
      "2021-04-25 17:51:42,740 [INFO] Training: 1955/6852 -- loss: 2.378148078918457\n",
      "2021-04-25 17:51:42,788 [INFO] Training: 1956/6852 -- loss: 2.75787091255188\n",
      "2021-04-25 17:51:42,835 [INFO] Training: 1957/6852 -- loss: 2.9778900146484375\n",
      "2021-04-25 17:51:42,884 [INFO] Training: 1958/6852 -- loss: 3.218301773071289\n",
      "2021-04-25 17:51:42,931 [INFO] Training: 1959/6852 -- loss: 2.900564193725586\n",
      "2021-04-25 17:51:42,983 [INFO] Training: 1960/6852 -- loss: 2.112107515335083\n",
      "2021-04-25 17:51:43,030 [INFO] Training: 1961/6852 -- loss: 2.505016326904297\n",
      "2021-04-25 17:51:43,077 [INFO] Training: 1962/6852 -- loss: 2.9179954528808594\n",
      "2021-04-25 17:51:43,127 [INFO] Training: 1963/6852 -- loss: 3.535008430480957\n",
      "2021-04-25 17:51:43,178 [INFO] Training: 1964/6852 -- loss: 2.2335829734802246\n",
      "2021-04-25 17:51:43,228 [INFO] Training: 1965/6852 -- loss: 5.045970439910889\n",
      "2021-04-25 17:51:43,278 [INFO] Training: 1966/6852 -- loss: 2.7317886352539062\n",
      "2021-04-25 17:51:43,328 [INFO] Training: 1967/6852 -- loss: 2.502655506134033\n",
      "2021-04-25 17:51:43,376 [INFO] Training: 1968/6852 -- loss: 1.8637921810150146\n",
      "2021-04-25 17:51:43,427 [INFO] Training: 1969/6852 -- loss: 2.7166433334350586\n",
      "2021-04-25 17:51:43,478 [INFO] Training: 1970/6852 -- loss: 2.8433218002319336\n",
      "2021-04-25 17:51:43,530 [INFO] Training: 1971/6852 -- loss: 3.61315655708313\n",
      "2021-04-25 17:51:43,583 [INFO] Training: 1972/6852 -- loss: 2.725191593170166\n",
      "2021-04-25 17:51:43,632 [INFO] Training: 1973/6852 -- loss: 2.153545618057251\n",
      "2021-04-25 17:51:43,679 [INFO] Training: 1974/6852 -- loss: 3.5528624057769775\n",
      "2021-04-25 17:51:43,730 [INFO] Training: 1975/6852 -- loss: 1.6215918064117432\n",
      "2021-04-25 17:51:43,777 [INFO] Training: 1976/6852 -- loss: 4.57321834564209\n",
      "2021-04-25 17:51:43,825 [INFO] Training: 1977/6852 -- loss: 2.5651416778564453\n",
      "2021-04-25 17:51:43,875 [INFO] Training: 1978/6852 -- loss: 2.8189609050750732\n",
      "2021-04-25 17:51:43,924 [INFO] Training: 1979/6852 -- loss: 2.701432704925537\n",
      "2021-04-25 17:51:43,972 [INFO] Training: 1980/6852 -- loss: 2.4120025634765625\n",
      "2021-04-25 17:51:44,021 [INFO] Training: 1981/6852 -- loss: 2.6112310886383057\n",
      "2021-04-25 17:51:44,068 [INFO] Training: 1982/6852 -- loss: 2.77449369430542\n",
      "2021-04-25 17:51:44,118 [INFO] Training: 1983/6852 -- loss: 2.8550641536712646\n",
      "2021-04-25 17:51:44,169 [INFO] Training: 1984/6852 -- loss: 3.4918980598449707\n",
      "2021-04-25 17:51:44,219 [INFO] Training: 1985/6852 -- loss: 2.9941980838775635\n",
      "2021-04-25 17:51:44,271 [INFO] Training: 1986/6852 -- loss: 3.641862392425537\n",
      "2021-04-25 17:51:44,321 [INFO] Training: 1987/6852 -- loss: 2.332101821899414\n",
      "2021-04-25 17:51:44,372 [INFO] Training: 1988/6852 -- loss: 1.9977428913116455\n",
      "2021-04-25 17:51:44,422 [INFO] Training: 1989/6852 -- loss: 2.619889497756958\n",
      "2021-04-25 17:51:44,472 [INFO] Training: 1990/6852 -- loss: 2.8536782264709473\n",
      "2021-04-25 17:51:44,521 [INFO] Training: 1991/6852 -- loss: 2.217454671859741\n",
      "2021-04-25 17:51:44,571 [INFO] Training: 1992/6852 -- loss: 3.624974012374878\n",
      "2021-04-25 17:51:44,617 [INFO] Training: 1993/6852 -- loss: 1.9370851516723633\n",
      "2021-04-25 17:51:44,668 [INFO] Training: 1994/6852 -- loss: 2.3746936321258545\n",
      "2021-04-25 17:51:44,717 [INFO] Training: 1995/6852 -- loss: 2.9460511207580566\n",
      "2021-04-25 17:51:44,769 [INFO] Training: 1996/6852 -- loss: 3.4535062313079834\n",
      "2021-04-25 17:51:44,816 [INFO] Training: 1997/6852 -- loss: 2.6707561016082764\n",
      "2021-04-25 17:51:44,865 [INFO] Training: 1998/6852 -- loss: 2.7245657444000244\n",
      "2021-04-25 17:51:44,913 [INFO] Training: 1999/6852 -- loss: 4.687309265136719\n",
      "2021-04-25 17:51:44,960 [INFO] Training: 2000/6852 -- loss: 2.622093677520752\n",
      "2021-04-25 17:51:45,009 [INFO] Training: 2001/6852 -- loss: 3.002213478088379\n",
      "2021-04-25 17:51:45,056 [INFO] Training: 2002/6852 -- loss: 3.9033045768737793\n",
      "2021-04-25 17:51:45,104 [INFO] Training: 2003/6852 -- loss: 3.9520349502563477\n",
      "2021-04-25 17:51:45,158 [INFO] Training: 2004/6852 -- loss: 1.9678890705108643\n",
      "2021-04-25 17:51:45,207 [INFO] Training: 2005/6852 -- loss: 2.4620702266693115\n",
      "2021-04-25 17:51:45,258 [INFO] Training: 2006/6852 -- loss: 2.407949209213257\n",
      "2021-04-25 17:51:45,306 [INFO] Training: 2007/6852 -- loss: 2.9515109062194824\n",
      "2021-04-25 17:51:45,356 [INFO] Training: 2008/6852 -- loss: 3.5983340740203857\n",
      "2021-04-25 17:51:45,411 [INFO] Training: 2009/6852 -- loss: 2.577680826187134\n",
      "2021-04-25 17:51:45,460 [INFO] Training: 2010/6852 -- loss: 2.5487701892852783\n",
      "2021-04-25 17:51:45,509 [INFO] Training: 2011/6852 -- loss: 1.9867515563964844\n",
      "2021-04-25 17:51:45,559 [INFO] Training: 2012/6852 -- loss: 2.6583075523376465\n",
      "2021-04-25 17:51:45,607 [INFO] Training: 2013/6852 -- loss: 2.010500192642212\n",
      "2021-04-25 17:51:45,657 [INFO] Training: 2014/6852 -- loss: 3.419910192489624\n",
      "2021-04-25 17:51:45,705 [INFO] Training: 2015/6852 -- loss: 2.430274724960327\n",
      "2021-04-25 17:51:45,751 [INFO] Training: 2016/6852 -- loss: 2.982013702392578\n",
      "2021-04-25 17:51:45,801 [INFO] Training: 2017/6852 -- loss: 1.8281919956207275\n",
      "2021-04-25 17:51:45,850 [INFO] Training: 2018/6852 -- loss: 1.4467010498046875\n",
      "2021-04-25 17:51:45,900 [INFO] Training: 2019/6852 -- loss: 2.088421106338501\n",
      "2021-04-25 17:51:45,952 [INFO] Training: 2020/6852 -- loss: 2.965094566345215\n",
      "2021-04-25 17:51:45,998 [INFO] Training: 2021/6852 -- loss: 2.158928632736206\n",
      "2021-04-25 17:51:46,047 [INFO] Training: 2022/6852 -- loss: 3.1253533363342285\n",
      "2021-04-25 17:51:46,094 [INFO] Training: 2023/6852 -- loss: 2.903247117996216\n",
      "2021-04-25 17:51:46,141 [INFO] Training: 2024/6852 -- loss: 2.0899949073791504\n",
      "2021-04-25 17:51:46,192 [INFO] Training: 2025/6852 -- loss: 2.5042812824249268\n",
      "2021-04-25 17:51:46,241 [INFO] Training: 2026/6852 -- loss: 3.8931703567504883\n",
      "2021-04-25 17:51:46,292 [INFO] Training: 2027/6852 -- loss: 3.2469191551208496\n",
      "2021-04-25 17:51:46,346 [INFO] Training: 2028/6852 -- loss: 3.7833354473114014\n",
      "2021-04-25 17:51:46,398 [INFO] Training: 2029/6852 -- loss: 3.0214085578918457\n",
      "2021-04-25 17:51:46,449 [INFO] Training: 2030/6852 -- loss: 3.588684558868408\n",
      "2021-04-25 17:51:46,502 [INFO] Training: 2031/6852 -- loss: 2.368656635284424\n",
      "2021-04-25 17:51:46,552 [INFO] Training: 2032/6852 -- loss: 3.0130808353424072\n",
      "2021-04-25 17:51:46,603 [INFO] Training: 2033/6852 -- loss: 3.9126734733581543\n",
      "2021-04-25 17:51:46,652 [INFO] Training: 2034/6852 -- loss: 2.289330244064331\n",
      "2021-04-25 17:51:46,705 [INFO] Training: 2035/6852 -- loss: 3.008849620819092\n",
      "2021-04-25 17:51:46,753 [INFO] Training: 2036/6852 -- loss: 2.302215337753296\n",
      "2021-04-25 17:51:46,807 [INFO] Training: 2037/6852 -- loss: 2.4627013206481934\n",
      "2021-04-25 17:51:46,857 [INFO] Training: 2038/6852 -- loss: 2.763974189758301\n",
      "2021-04-25 17:51:46,906 [INFO] Training: 2039/6852 -- loss: 2.5970377922058105\n",
      "2021-04-25 17:51:46,955 [INFO] Training: 2040/6852 -- loss: 2.7475905418395996\n",
      "2021-04-25 17:51:47,006 [INFO] Training: 2041/6852 -- loss: 1.9191817045211792\n",
      "2021-04-25 17:51:47,055 [INFO] Training: 2042/6852 -- loss: 2.9299330711364746\n",
      "2021-04-25 17:51:47,103 [INFO] Training: 2043/6852 -- loss: 2.2298920154571533\n",
      "2021-04-25 17:51:47,152 [INFO] Training: 2044/6852 -- loss: 3.6566076278686523\n",
      "2021-04-25 17:51:47,202 [INFO] Training: 2045/6852 -- loss: 3.8390207290649414\n",
      "2021-04-25 17:51:47,251 [INFO] Training: 2046/6852 -- loss: 4.3283820152282715\n",
      "2021-04-25 17:51:47,300 [INFO] Training: 2047/6852 -- loss: 1.7477622032165527\n",
      "2021-04-25 17:51:47,351 [INFO] Training: 2048/6852 -- loss: 2.072777271270752\n",
      "2021-04-25 17:51:47,401 [INFO] Training: 2049/6852 -- loss: 1.9521435499191284\n",
      "2021-04-25 17:51:47,452 [INFO] Training: 2050/6852 -- loss: 2.3854684829711914\n",
      "2021-04-25 17:51:47,500 [INFO] Training: 2051/6852 -- loss: 2.6699764728546143\n",
      "2021-04-25 17:51:47,551 [INFO] Training: 2052/6852 -- loss: 3.4856693744659424\n",
      "2021-04-25 17:51:47,599 [INFO] Training: 2053/6852 -- loss: 1.88716721534729\n",
      "2021-04-25 17:51:47,647 [INFO] Training: 2054/6852 -- loss: 1.5351186990737915\n",
      "2021-04-25 17:51:47,699 [INFO] Training: 2055/6852 -- loss: 3.613844156265259\n",
      "2021-04-25 17:51:47,746 [INFO] Training: 2056/6852 -- loss: 1.2663543224334717\n",
      "2021-04-25 17:51:47,795 [INFO] Training: 2057/6852 -- loss: 2.2942750453948975\n",
      "2021-04-25 17:51:47,846 [INFO] Training: 2058/6852 -- loss: 2.7089929580688477\n",
      "2021-04-25 17:51:47,897 [INFO] Training: 2059/6852 -- loss: 3.3335957527160645\n",
      "2021-04-25 17:51:47,946 [INFO] Training: 2060/6852 -- loss: 3.237755060195923\n",
      "2021-04-25 17:51:47,994 [INFO] Training: 2061/6852 -- loss: 2.52158260345459\n",
      "2021-04-25 17:51:48,044 [INFO] Training: 2062/6852 -- loss: 3.5793564319610596\n",
      "2021-04-25 17:51:48,097 [INFO] Training: 2063/6852 -- loss: 2.850407838821411\n",
      "2021-04-25 17:51:48,146 [INFO] Training: 2064/6852 -- loss: 2.6300604343414307\n",
      "2021-04-25 17:51:48,197 [INFO] Training: 2065/6852 -- loss: 3.104905128479004\n",
      "2021-04-25 17:51:48,244 [INFO] Training: 2066/6852 -- loss: 2.3073506355285645\n",
      "2021-04-25 17:51:48,296 [INFO] Training: 2067/6852 -- loss: 3.318779706954956\n",
      "2021-04-25 17:51:48,344 [INFO] Training: 2068/6852 -- loss: 3.079807996749878\n",
      "2021-04-25 17:51:48,392 [INFO] Training: 2069/6852 -- loss: 2.420875310897827\n",
      "2021-04-25 17:51:48,443 [INFO] Training: 2070/6852 -- loss: 3.008756160736084\n",
      "2021-04-25 17:51:48,491 [INFO] Training: 2071/6852 -- loss: 2.6322317123413086\n",
      "2021-04-25 17:51:48,547 [INFO] Training: 2072/6852 -- loss: 2.796112537384033\n",
      "2021-04-25 17:51:48,593 [INFO] Training: 2073/6852 -- loss: 3.3460330963134766\n",
      "2021-04-25 17:51:48,642 [INFO] Training: 2074/6852 -- loss: 2.5851500034332275\n",
      "2021-04-25 17:51:48,691 [INFO] Training: 2075/6852 -- loss: 2.8993418216705322\n",
      "2021-04-25 17:51:48,739 [INFO] Training: 2076/6852 -- loss: 2.396949529647827\n",
      "2021-04-25 17:51:48,789 [INFO] Training: 2077/6852 -- loss: 2.815483331680298\n",
      "2021-04-25 17:51:48,838 [INFO] Training: 2078/6852 -- loss: 2.578988552093506\n",
      "2021-04-25 17:51:48,889 [INFO] Training: 2079/6852 -- loss: 2.2832069396972656\n",
      "2021-04-25 17:51:48,936 [INFO] Training: 2080/6852 -- loss: 2.4275522232055664\n",
      "2021-04-25 17:51:48,983 [INFO] Training: 2081/6852 -- loss: 2.7384631633758545\n",
      "2021-04-25 17:51:49,033 [INFO] Training: 2082/6852 -- loss: 2.331113576889038\n",
      "2021-04-25 17:51:49,081 [INFO] Training: 2083/6852 -- loss: 2.6200361251831055\n",
      "2021-04-25 17:51:49,132 [INFO] Training: 2084/6852 -- loss: 1.6629034280776978\n",
      "2021-04-25 17:51:49,180 [INFO] Training: 2085/6852 -- loss: 3.3623337745666504\n",
      "2021-04-25 17:51:49,231 [INFO] Training: 2086/6852 -- loss: 2.473947048187256\n",
      "2021-04-25 17:51:49,279 [INFO] Training: 2087/6852 -- loss: 3.120574951171875\n",
      "2021-04-25 17:51:49,328 [INFO] Training: 2088/6852 -- loss: 2.5770130157470703\n",
      "2021-04-25 17:51:49,376 [INFO] Training: 2089/6852 -- loss: 3.3168933391571045\n",
      "2021-04-25 17:51:49,424 [INFO] Training: 2090/6852 -- loss: 2.668243885040283\n",
      "2021-04-25 17:51:49,473 [INFO] Training: 2091/6852 -- loss: 2.3090085983276367\n",
      "2021-04-25 17:51:49,523 [INFO] Training: 2092/6852 -- loss: 3.2848896980285645\n",
      "2021-04-25 17:51:49,574 [INFO] Training: 2093/6852 -- loss: 2.4012186527252197\n",
      "2021-04-25 17:51:49,627 [INFO] Training: 2094/6852 -- loss: 2.5565457344055176\n",
      "2021-04-25 17:51:49,678 [INFO] Training: 2095/6852 -- loss: 3.1654512882232666\n",
      "2021-04-25 17:51:49,728 [INFO] Training: 2096/6852 -- loss: 2.485366106033325\n",
      "2021-04-25 17:51:49,775 [INFO] Training: 2097/6852 -- loss: 2.7239530086517334\n",
      "2021-04-25 17:51:49,825 [INFO] Training: 2098/6852 -- loss: 4.57516622543335\n",
      "2021-04-25 17:51:49,872 [INFO] Training: 2099/6852 -- loss: 4.001519680023193\n",
      "2021-04-25 17:51:49,920 [INFO] Training: 2100/6852 -- loss: 2.6552894115448\n",
      "2021-04-25 17:51:52,800 [INFO] Training: iteration: 2100/6852 -- epoch: 3 --  train_loss: 2.796 -- train_accuracy: 0.25 valid_loss: 3.079 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:51:52,842 [INFO] Training: 2101/6852 -- loss: 2.0023343563079834\n",
      "2021-04-25 17:51:52,894 [INFO] Training: 2102/6852 -- loss: 3.0539116859436035\n",
      "2021-04-25 17:51:52,941 [INFO] Training: 2103/6852 -- loss: 2.5341145992279053\n",
      "2021-04-25 17:51:52,990 [INFO] Training: 2104/6852 -- loss: 4.040159702301025\n",
      "2021-04-25 17:51:53,040 [INFO] Training: 2105/6852 -- loss: 2.187026023864746\n",
      "2021-04-25 17:51:53,089 [INFO] Training: 2106/6852 -- loss: 3.2669241428375244\n",
      "2021-04-25 17:51:53,138 [INFO] Training: 2107/6852 -- loss: 2.701815605163574\n",
      "2021-04-25 17:51:53,189 [INFO] Training: 2108/6852 -- loss: 2.8235907554626465\n",
      "2021-04-25 17:51:53,237 [INFO] Training: 2109/6852 -- loss: 2.2206993103027344\n",
      "2021-04-25 17:51:53,286 [INFO] Training: 2110/6852 -- loss: 3.608891010284424\n",
      "2021-04-25 17:51:53,337 [INFO] Training: 2111/6852 -- loss: 2.0625832080841064\n",
      "2021-04-25 17:51:53,385 [INFO] Training: 2112/6852 -- loss: 3.5157811641693115\n",
      "2021-04-25 17:51:53,433 [INFO] Training: 2113/6852 -- loss: 2.3107235431671143\n",
      "2021-04-25 17:51:53,482 [INFO] Training: 2114/6852 -- loss: 3.193636178970337\n",
      "2021-04-25 17:51:53,533 [INFO] Training: 2115/6852 -- loss: 3.19450044631958\n",
      "2021-04-25 17:51:53,583 [INFO] Training: 2116/6852 -- loss: 3.497734785079956\n",
      "2021-04-25 17:51:53,631 [INFO] Training: 2117/6852 -- loss: 2.383322238922119\n",
      "2021-04-25 17:51:53,682 [INFO] Training: 2118/6852 -- loss: 4.37217903137207\n",
      "2021-04-25 17:51:53,732 [INFO] Training: 2119/6852 -- loss: 2.816115617752075\n",
      "2021-04-25 17:51:53,783 [INFO] Training: 2120/6852 -- loss: 2.6148078441619873\n",
      "2021-04-25 17:51:53,834 [INFO] Training: 2121/6852 -- loss: 3.1621932983398438\n",
      "2021-04-25 17:51:53,884 [INFO] Training: 2122/6852 -- loss: 2.8758955001831055\n",
      "2021-04-25 17:51:53,931 [INFO] Training: 2123/6852 -- loss: 2.6609179973602295\n",
      "2021-04-25 17:51:53,982 [INFO] Training: 2124/6852 -- loss: 2.7386631965637207\n",
      "2021-04-25 17:51:54,034 [INFO] Training: 2125/6852 -- loss: 3.6166133880615234\n",
      "2021-04-25 17:51:54,083 [INFO] Training: 2126/6852 -- loss: 1.9710018634796143\n",
      "2021-04-25 17:51:54,132 [INFO] Training: 2127/6852 -- loss: 2.8286354541778564\n",
      "2021-04-25 17:51:54,180 [INFO] Training: 2128/6852 -- loss: 3.344428062438965\n",
      "2021-04-25 17:51:54,230 [INFO] Training: 2129/6852 -- loss: 2.6529030799865723\n",
      "2021-04-25 17:51:54,278 [INFO] Training: 2130/6852 -- loss: 3.2697136402130127\n",
      "2021-04-25 17:51:54,329 [INFO] Training: 2131/6852 -- loss: 2.4249603748321533\n",
      "2021-04-25 17:51:54,377 [INFO] Training: 2132/6852 -- loss: 2.6982715129852295\n",
      "2021-04-25 17:51:54,426 [INFO] Training: 2133/6852 -- loss: 3.2125165462493896\n",
      "2021-04-25 17:51:54,475 [INFO] Training: 2134/6852 -- loss: 2.914020538330078\n",
      "2021-04-25 17:51:54,523 [INFO] Training: 2135/6852 -- loss: 2.131234645843506\n",
      "2021-04-25 17:51:54,571 [INFO] Training: 2136/6852 -- loss: 3.5759804248809814\n",
      "2021-04-25 17:51:54,620 [INFO] Training: 2137/6852 -- loss: 3.1777260303497314\n",
      "2021-04-25 17:51:54,668 [INFO] Training: 2138/6852 -- loss: 2.7535560131073\n",
      "2021-04-25 17:51:54,720 [INFO] Training: 2139/6852 -- loss: 2.2182493209838867\n",
      "2021-04-25 17:51:54,767 [INFO] Training: 2140/6852 -- loss: 3.269731044769287\n",
      "2021-04-25 17:51:54,818 [INFO] Training: 2141/6852 -- loss: 3.613007068634033\n",
      "2021-04-25 17:51:54,865 [INFO] Training: 2142/6852 -- loss: 3.489525556564331\n",
      "2021-04-25 17:51:54,914 [INFO] Training: 2143/6852 -- loss: 2.6959903240203857\n",
      "2021-04-25 17:51:54,962 [INFO] Training: 2144/6852 -- loss: 2.7817654609680176\n",
      "2021-04-25 17:51:55,012 [INFO] Training: 2145/6852 -- loss: 2.4783835411071777\n",
      "2021-04-25 17:51:55,062 [INFO] Training: 2146/6852 -- loss: 2.897141456604004\n",
      "2021-04-25 17:51:55,110 [INFO] Training: 2147/6852 -- loss: 2.4284796714782715\n",
      "2021-04-25 17:51:55,161 [INFO] Training: 2148/6852 -- loss: 2.365156888961792\n",
      "2021-04-25 17:51:55,211 [INFO] Training: 2149/6852 -- loss: 3.018094062805176\n",
      "2021-04-25 17:51:55,263 [INFO] Training: 2150/6852 -- loss: 2.8190298080444336\n",
      "2021-04-25 17:51:55,313 [INFO] Training: 2151/6852 -- loss: 2.915797710418701\n",
      "2021-04-25 17:51:55,365 [INFO] Training: 2152/6852 -- loss: 3.629199266433716\n",
      "2021-04-25 17:51:55,416 [INFO] Training: 2153/6852 -- loss: 3.0557870864868164\n",
      "2021-04-25 17:51:55,466 [INFO] Training: 2154/6852 -- loss: 2.2800214290618896\n",
      "2021-04-25 17:51:55,515 [INFO] Training: 2155/6852 -- loss: 1.705065131187439\n",
      "2021-04-25 17:51:55,562 [INFO] Training: 2156/6852 -- loss: 3.7745537757873535\n",
      "2021-04-25 17:51:55,612 [INFO] Training: 2157/6852 -- loss: 3.211700201034546\n",
      "2021-04-25 17:51:55,659 [INFO] Training: 2158/6852 -- loss: 2.757296085357666\n",
      "2021-04-25 17:51:55,709 [INFO] Training: 2159/6852 -- loss: 2.554405927658081\n",
      "2021-04-25 17:51:55,759 [INFO] Training: 2160/6852 -- loss: 3.181826591491699\n",
      "2021-04-25 17:51:55,811 [INFO] Training: 2161/6852 -- loss: 3.6576623916625977\n",
      "2021-04-25 17:51:55,861 [INFO] Training: 2162/6852 -- loss: 2.0048646926879883\n",
      "2021-04-25 17:51:55,912 [INFO] Training: 2163/6852 -- loss: 3.078733444213867\n",
      "2021-04-25 17:51:55,962 [INFO] Training: 2164/6852 -- loss: 2.6461334228515625\n",
      "2021-04-25 17:51:56,012 [INFO] Training: 2165/6852 -- loss: 2.089508056640625\n",
      "2021-04-25 17:51:56,061 [INFO] Training: 2166/6852 -- loss: 2.018596649169922\n",
      "2021-04-25 17:51:56,111 [INFO] Training: 2167/6852 -- loss: 2.761552333831787\n",
      "2021-04-25 17:51:56,161 [INFO] Training: 2168/6852 -- loss: 2.598259687423706\n",
      "2021-04-25 17:51:56,211 [INFO] Training: 2169/6852 -- loss: 3.5820021629333496\n",
      "2021-04-25 17:51:56,260 [INFO] Training: 2170/6852 -- loss: 2.342926263809204\n",
      "2021-04-25 17:51:56,308 [INFO] Training: 2171/6852 -- loss: 2.646460771560669\n",
      "2021-04-25 17:51:56,360 [INFO] Training: 2172/6852 -- loss: 2.522554397583008\n",
      "2021-04-25 17:51:56,408 [INFO] Training: 2173/6852 -- loss: 1.975418210029602\n",
      "2021-04-25 17:51:56,456 [INFO] Training: 2174/6852 -- loss: 2.4162802696228027\n",
      "2021-04-25 17:51:56,508 [INFO] Training: 2175/6852 -- loss: 2.830930709838867\n",
      "2021-04-25 17:51:56,555 [INFO] Training: 2176/6852 -- loss: 3.207075357437134\n",
      "2021-04-25 17:51:56,608 [INFO] Training: 2177/6852 -- loss: 1.5242254734039307\n",
      "2021-04-25 17:51:56,658 [INFO] Training: 2178/6852 -- loss: 3.3190343379974365\n",
      "2021-04-25 17:51:56,706 [INFO] Training: 2179/6852 -- loss: 3.5779833793640137\n",
      "2021-04-25 17:51:56,753 [INFO] Training: 2180/6852 -- loss: 3.2538249492645264\n",
      "2021-04-25 17:51:56,801 [INFO] Training: 2181/6852 -- loss: 2.767158031463623\n",
      "2021-04-25 17:51:56,852 [INFO] Training: 2182/6852 -- loss: 4.121408462524414\n",
      "2021-04-25 17:51:56,901 [INFO] Training: 2183/6852 -- loss: 2.7264370918273926\n",
      "2021-04-25 17:51:56,950 [INFO] Training: 2184/6852 -- loss: 3.5399203300476074\n",
      "2021-04-25 17:51:56,998 [INFO] Training: 2185/6852 -- loss: 2.3403918743133545\n",
      "2021-04-25 17:51:57,049 [INFO] Training: 2186/6852 -- loss: 2.62442946434021\n",
      "2021-04-25 17:51:57,097 [INFO] Training: 2187/6852 -- loss: 2.209336757659912\n",
      "2021-04-25 17:51:57,150 [INFO] Training: 2188/6852 -- loss: 2.6670045852661133\n",
      "2021-04-25 17:51:57,201 [INFO] Training: 2189/6852 -- loss: 3.1402556896209717\n",
      "2021-04-25 17:51:57,249 [INFO] Training: 2190/6852 -- loss: 2.535374641418457\n",
      "2021-04-25 17:51:57,303 [INFO] Training: 2191/6852 -- loss: 2.1620116233825684\n",
      "2021-04-25 17:51:57,353 [INFO] Training: 2192/6852 -- loss: 2.654649257659912\n",
      "2021-04-25 17:51:57,402 [INFO] Training: 2193/6852 -- loss: 1.830948829650879\n",
      "2021-04-25 17:51:57,449 [INFO] Training: 2194/6852 -- loss: 3.745986223220825\n",
      "2021-04-25 17:51:57,501 [INFO] Training: 2195/6852 -- loss: 2.1492908000946045\n",
      "2021-04-25 17:51:57,551 [INFO] Training: 2196/6852 -- loss: 3.376461982727051\n",
      "2021-04-25 17:51:57,601 [INFO] Training: 2197/6852 -- loss: 3.3644092082977295\n",
      "2021-04-25 17:51:57,650 [INFO] Training: 2198/6852 -- loss: 2.6990976333618164\n",
      "2021-04-25 17:51:57,700 [INFO] Training: 2199/6852 -- loss: 3.0316481590270996\n",
      "2021-04-25 17:51:57,747 [INFO] Training: 2200/6852 -- loss: 3.4374632835388184\n",
      "2021-04-25 17:51:57,795 [INFO] Training: 2201/6852 -- loss: 4.216238021850586\n",
      "2021-04-25 17:51:57,843 [INFO] Training: 2202/6852 -- loss: 2.312053680419922\n",
      "2021-04-25 17:51:57,892 [INFO] Training: 2203/6852 -- loss: 3.0945777893066406\n",
      "2021-04-25 17:51:57,940 [INFO] Training: 2204/6852 -- loss: 3.2705821990966797\n",
      "2021-04-25 17:51:57,990 [INFO] Training: 2205/6852 -- loss: 1.4012136459350586\n",
      "2021-04-25 17:51:58,041 [INFO] Training: 2206/6852 -- loss: 3.7097697257995605\n",
      "2021-04-25 17:51:58,089 [INFO] Training: 2207/6852 -- loss: 2.673027515411377\n",
      "2021-04-25 17:51:58,136 [INFO] Training: 2208/6852 -- loss: 2.7485198974609375\n",
      "2021-04-25 17:51:58,185 [INFO] Training: 2209/6852 -- loss: 3.005950689315796\n",
      "2021-04-25 17:51:58,234 [INFO] Training: 2210/6852 -- loss: 2.370051383972168\n",
      "2021-04-25 17:51:58,283 [INFO] Training: 2211/6852 -- loss: 2.958242416381836\n",
      "2021-04-25 17:51:58,334 [INFO] Training: 2212/6852 -- loss: 3.101933479309082\n",
      "2021-04-25 17:51:58,380 [INFO] Training: 2213/6852 -- loss: 2.754749298095703\n",
      "2021-04-25 17:51:58,428 [INFO] Training: 2214/6852 -- loss: 2.50498366355896\n",
      "2021-04-25 17:51:58,476 [INFO] Training: 2215/6852 -- loss: 2.6096768379211426\n",
      "2021-04-25 17:51:58,524 [INFO] Training: 2216/6852 -- loss: 3.064514636993408\n",
      "2021-04-25 17:51:58,573 [INFO] Training: 2217/6852 -- loss: 3.33760666847229\n",
      "2021-04-25 17:51:58,620 [INFO] Training: 2218/6852 -- loss: 3.81038498878479\n",
      "2021-04-25 17:51:58,667 [INFO] Training: 2219/6852 -- loss: 3.1712164878845215\n",
      "2021-04-25 17:51:58,718 [INFO] Training: 2220/6852 -- loss: 2.9154858589172363\n",
      "2021-04-25 17:51:58,770 [INFO] Training: 2221/6852 -- loss: 1.6323521137237549\n",
      "2021-04-25 17:51:58,821 [INFO] Training: 2222/6852 -- loss: 2.746258020401001\n",
      "2021-04-25 17:51:58,868 [INFO] Training: 2223/6852 -- loss: 2.4104747772216797\n",
      "2021-04-25 17:51:58,920 [INFO] Training: 2224/6852 -- loss: 2.6409358978271484\n",
      "2021-04-25 17:51:58,967 [INFO] Training: 2225/6852 -- loss: 3.2068943977355957\n",
      "2021-04-25 17:51:59,015 [INFO] Training: 2226/6852 -- loss: 1.5414166450500488\n",
      "2021-04-25 17:51:59,068 [INFO] Training: 2227/6852 -- loss: 3.112215757369995\n",
      "2021-04-25 17:51:59,118 [INFO] Training: 2228/6852 -- loss: 3.425846815109253\n",
      "2021-04-25 17:51:59,166 [INFO] Training: 2229/6852 -- loss: 3.030571937561035\n",
      "2021-04-25 17:51:59,216 [INFO] Training: 2230/6852 -- loss: 2.6277732849121094\n",
      "2021-04-25 17:51:59,266 [INFO] Training: 2231/6852 -- loss: 2.119685649871826\n",
      "2021-04-25 17:51:59,315 [INFO] Training: 2232/6852 -- loss: 3.373497247695923\n",
      "2021-04-25 17:51:59,366 [INFO] Training: 2233/6852 -- loss: 4.210259914398193\n",
      "2021-04-25 17:51:59,414 [INFO] Training: 2234/6852 -- loss: 1.593648910522461\n",
      "2021-04-25 17:51:59,464 [INFO] Training: 2235/6852 -- loss: 2.2387630939483643\n",
      "2021-04-25 17:51:59,514 [INFO] Training: 2236/6852 -- loss: 2.1343352794647217\n",
      "2021-04-25 17:51:59,565 [INFO] Training: 2237/6852 -- loss: 1.9646987915039062\n",
      "2021-04-25 17:51:59,614 [INFO] Training: 2238/6852 -- loss: 3.426382303237915\n",
      "2021-04-25 17:51:59,662 [INFO] Training: 2239/6852 -- loss: 4.5128889083862305\n",
      "2021-04-25 17:51:59,716 [INFO] Training: 2240/6852 -- loss: 2.634103298187256\n",
      "2021-04-25 17:51:59,764 [INFO] Training: 2241/6852 -- loss: 1.9077880382537842\n",
      "2021-04-25 17:51:59,814 [INFO] Training: 2242/6852 -- loss: 3.0245447158813477\n",
      "2021-04-25 17:51:59,869 [INFO] Training: 2243/6852 -- loss: 3.1692614555358887\n",
      "2021-04-25 17:51:59,918 [INFO] Training: 2244/6852 -- loss: 3.7104766368865967\n",
      "2021-04-25 17:51:59,966 [INFO] Training: 2245/6852 -- loss: 3.149580955505371\n",
      "2021-04-25 17:52:00,017 [INFO] Training: 2246/6852 -- loss: 3.0726637840270996\n",
      "2021-04-25 17:52:00,068 [INFO] Training: 2247/6852 -- loss: 3.4179887771606445\n",
      "2021-04-25 17:52:00,118 [INFO] Training: 2248/6852 -- loss: 3.93278169631958\n",
      "2021-04-25 17:52:00,171 [INFO] Training: 2249/6852 -- loss: 2.094341278076172\n",
      "2021-04-25 17:52:00,222 [INFO] Training: 2250/6852 -- loss: 3.892911672592163\n",
      "2021-04-25 17:52:03,104 [INFO] Training: iteration: 2250/6852 -- epoch: 3 --  train_loss: 2.865 -- train_accuracy: 0.12 valid_loss: 3.075 -- valid_accuracy: 0.26\n",
      "2021-04-25 17:52:03,162 [INFO] Training: 2251/6852 -- loss: 2.6014041900634766\n",
      "2021-04-25 17:52:03,209 [INFO] Training: 2252/6852 -- loss: 3.0366854667663574\n",
      "2021-04-25 17:52:03,257 [INFO] Training: 2253/6852 -- loss: 2.9490280151367188\n",
      "2021-04-25 17:52:03,310 [INFO] Training: 2254/6852 -- loss: 3.516288995742798\n",
      "2021-04-25 17:52:03,360 [INFO] Training: 2255/6852 -- loss: 2.1839568614959717\n",
      "2021-04-25 17:52:03,412 [INFO] Training: 2256/6852 -- loss: 3.5707180500030518\n",
      "2021-04-25 17:52:03,462 [INFO] Training: 2257/6852 -- loss: 3.82318115234375\n",
      "2021-04-25 17:52:03,513 [INFO] Training: 2258/6852 -- loss: 2.1480979919433594\n",
      "2021-04-25 17:52:03,560 [INFO] Training: 2259/6852 -- loss: 2.2630081176757812\n",
      "2021-04-25 17:52:03,613 [INFO] Training: 2260/6852 -- loss: 2.612828493118286\n",
      "2021-04-25 17:52:03,661 [INFO] Training: 2261/6852 -- loss: 3.243837356567383\n",
      "2021-04-25 17:52:03,711 [INFO] Training: 2262/6852 -- loss: 2.39530873298645\n",
      "2021-04-25 17:52:03,767 [INFO] Training: 2263/6852 -- loss: 2.9920828342437744\n",
      "2021-04-25 17:52:03,818 [INFO] Training: 2264/6852 -- loss: 1.8426587581634521\n",
      "2021-04-25 17:52:03,872 [INFO] Training: 2265/6852 -- loss: 2.058614730834961\n",
      "2021-04-25 17:52:03,921 [INFO] Training: 2266/6852 -- loss: 3.0716419219970703\n",
      "2021-04-25 17:52:03,973 [INFO] Training: 2267/6852 -- loss: 2.1422765254974365\n",
      "2021-04-25 17:52:04,025 [INFO] Training: 2268/6852 -- loss: 2.6563024520874023\n",
      "2021-04-25 17:52:04,080 [INFO] Training: 2269/6852 -- loss: 2.9241747856140137\n",
      "2021-04-25 17:52:04,130 [INFO] Training: 2270/6852 -- loss: 2.6920347213745117\n",
      "2021-04-25 17:52:04,184 [INFO] Training: 2271/6852 -- loss: 3.1180248260498047\n",
      "2021-04-25 17:52:04,232 [INFO] Training: 2272/6852 -- loss: 4.788487911224365\n",
      "2021-04-25 17:52:04,283 [INFO] Training: 2273/6852 -- loss: 3.93208909034729\n",
      "2021-04-25 17:52:04,337 [INFO] Training: 2274/6852 -- loss: 3.171119213104248\n",
      "2021-04-25 17:52:04,387 [INFO] Training: 2275/6852 -- loss: 2.472761631011963\n",
      "2021-04-25 17:52:04,438 [INFO] Training: 2276/6852 -- loss: 2.932673692703247\n",
      "2021-04-25 17:52:04,487 [INFO] Training: 2277/6852 -- loss: 4.249087333679199\n",
      "2021-04-25 17:52:04,537 [INFO] Training: 2278/6852 -- loss: 2.6797170639038086\n",
      "2021-04-25 17:52:04,588 [INFO] Training: 2279/6852 -- loss: 3.0504655838012695\n",
      "2021-04-25 17:52:04,637 [INFO] Training: 2280/6852 -- loss: 3.43446946144104\n",
      "2021-04-25 17:52:04,689 [INFO] Training: 2281/6852 -- loss: 3.47880482673645\n",
      "2021-04-25 17:52:04,737 [INFO] Training: 2282/6852 -- loss: 2.9978084564208984\n",
      "2021-04-25 17:52:04,787 [INFO] Training: 2283/6852 -- loss: 3.8100967407226562\n",
      "2021-04-25 17:52:05,066 [INFO] Training: 2284/6852 -- loss: 2.4740118980407715\n",
      "2021-04-25 17:52:05,116 [INFO] Training: 2285/6852 -- loss: 2.6217944622039795\n",
      "2021-04-25 17:52:05,164 [INFO] Training: 2286/6852 -- loss: 2.382169723510742\n",
      "2021-04-25 17:52:05,217 [INFO] Training: 2287/6852 -- loss: 2.54886531829834\n",
      "2021-04-25 17:52:05,264 [INFO] Training: 2288/6852 -- loss: 2.5859925746917725\n",
      "2021-04-25 17:52:05,314 [INFO] Training: 2289/6852 -- loss: 2.568880081176758\n",
      "2021-04-25 17:52:05,363 [INFO] Training: 2290/6852 -- loss: 3.5255541801452637\n",
      "2021-04-25 17:52:05,412 [INFO] Training: 2291/6852 -- loss: 2.714232921600342\n",
      "2021-04-25 17:52:05,461 [INFO] Training: 2292/6852 -- loss: 3.9986214637756348\n",
      "2021-04-25 17:52:05,512 [INFO] Training: 2293/6852 -- loss: 2.071377992630005\n",
      "2021-04-25 17:52:05,564 [INFO] Training: 2294/6852 -- loss: 3.415227174758911\n",
      "2021-04-25 17:52:05,610 [INFO] Training: 2295/6852 -- loss: 2.5310311317443848\n",
      "2021-04-25 17:52:05,660 [INFO] Training: 2296/6852 -- loss: 3.867072820663452\n",
      "2021-04-25 17:52:05,710 [INFO] Training: 2297/6852 -- loss: 3.267030715942383\n",
      "2021-04-25 17:52:05,762 [INFO] Training: 2298/6852 -- loss: 2.7285044193267822\n",
      "2021-04-25 17:52:05,810 [INFO] Training: 2299/6852 -- loss: 2.5048134326934814\n",
      "2021-04-25 17:52:05,859 [INFO] Training: 2300/6852 -- loss: 3.7927379608154297\n",
      "2021-04-25 17:52:05,910 [INFO] Training: 2301/6852 -- loss: 3.3250973224639893\n",
      "2021-04-25 17:52:05,963 [INFO] Training: 2302/6852 -- loss: 2.1191818714141846\n",
      "2021-04-25 17:52:06,012 [INFO] Training: 2303/6852 -- loss: 2.837498664855957\n",
      "2021-04-25 17:52:06,061 [INFO] Training: 2304/6852 -- loss: 3.1093335151672363\n",
      "2021-04-25 17:52:06,111 [INFO] Training: 2305/6852 -- loss: 2.059103488922119\n",
      "2021-04-25 17:52:06,159 [INFO] Training: 2306/6852 -- loss: 2.5669543743133545\n",
      "2021-04-25 17:52:06,209 [INFO] Training: 2307/6852 -- loss: 1.6908406019210815\n",
      "2021-04-25 17:52:06,259 [INFO] Training: 2308/6852 -- loss: 2.6542370319366455\n",
      "2021-04-25 17:52:06,310 [INFO] Training: 2309/6852 -- loss: 2.1936097145080566\n",
      "2021-04-25 17:52:06,359 [INFO] Training: 2310/6852 -- loss: 2.7104837894439697\n",
      "2021-04-25 17:52:06,408 [INFO] Training: 2311/6852 -- loss: 2.6859829425811768\n",
      "2021-04-25 17:52:06,458 [INFO] Training: 2312/6852 -- loss: 2.938215732574463\n",
      "2021-04-25 17:52:06,508 [INFO] Training: 2313/6852 -- loss: 2.657935380935669\n",
      "2021-04-25 17:52:06,558 [INFO] Training: 2314/6852 -- loss: 2.8956193923950195\n",
      "2021-04-25 17:52:06,609 [INFO] Training: 2315/6852 -- loss: 3.1650161743164062\n",
      "2021-04-25 17:52:06,660 [INFO] Training: 2316/6852 -- loss: 3.2622275352478027\n",
      "2021-04-25 17:52:06,712 [INFO] Training: 2317/6852 -- loss: 1.8025712966918945\n",
      "2021-04-25 17:52:06,764 [INFO] Training: 2318/6852 -- loss: 1.7792880535125732\n",
      "2021-04-25 17:52:06,816 [INFO] Training: 2319/6852 -- loss: 2.730173110961914\n",
      "2021-04-25 17:52:06,865 [INFO] Training: 2320/6852 -- loss: 3.3664755821228027\n",
      "2021-04-25 17:52:06,917 [INFO] Training: 2321/6852 -- loss: 1.8703688383102417\n",
      "2021-04-25 17:52:06,964 [INFO] Training: 2322/6852 -- loss: 2.5096001625061035\n",
      "2021-04-25 17:52:07,011 [INFO] Training: 2323/6852 -- loss: 2.8608384132385254\n",
      "2021-04-25 17:52:07,061 [INFO] Training: 2324/6852 -- loss: 3.555701494216919\n",
      "2021-04-25 17:52:07,111 [INFO] Training: 2325/6852 -- loss: 2.075331926345825\n",
      "2021-04-25 17:52:07,164 [INFO] Training: 2326/6852 -- loss: 2.5096652507781982\n",
      "2021-04-25 17:52:07,213 [INFO] Training: 2327/6852 -- loss: 2.4911468029022217\n",
      "2021-04-25 17:52:07,261 [INFO] Training: 2328/6852 -- loss: 2.6409223079681396\n",
      "2021-04-25 17:52:07,309 [INFO] Training: 2329/6852 -- loss: 2.568661689758301\n",
      "2021-04-25 17:52:07,359 [INFO] Training: 2330/6852 -- loss: 3.0810375213623047\n",
      "2021-04-25 17:52:07,410 [INFO] Training: 2331/6852 -- loss: 2.503286123275757\n",
      "2021-04-25 17:52:07,459 [INFO] Training: 2332/6852 -- loss: 1.8575139045715332\n",
      "2021-04-25 17:52:07,511 [INFO] Training: 2333/6852 -- loss: 2.1894123554229736\n",
      "2021-04-25 17:52:07,559 [INFO] Training: 2334/6852 -- loss: 3.23399019241333\n",
      "2021-04-25 17:52:07,609 [INFO] Training: 2335/6852 -- loss: 3.3949642181396484\n",
      "2021-04-25 17:52:07,658 [INFO] Training: 2336/6852 -- loss: 2.321650743484497\n",
      "2021-04-25 17:52:07,705 [INFO] Training: 2337/6852 -- loss: 2.2096238136291504\n",
      "2021-04-25 17:52:07,755 [INFO] Training: 2338/6852 -- loss: 2.1929454803466797\n",
      "2021-04-25 17:52:07,802 [INFO] Training: 2339/6852 -- loss: 3.017906665802002\n",
      "2021-04-25 17:52:07,852 [INFO] Training: 2340/6852 -- loss: 3.2227325439453125\n",
      "2021-04-25 17:52:07,901 [INFO] Training: 2341/6852 -- loss: 1.9198243618011475\n",
      "2021-04-25 17:52:07,953 [INFO] Training: 2342/6852 -- loss: 2.908235549926758\n",
      "2021-04-25 17:52:08,000 [INFO] Training: 2343/6852 -- loss: 2.0976932048797607\n",
      "2021-04-25 17:52:08,050 [INFO] Training: 2344/6852 -- loss: 2.100846290588379\n",
      "2021-04-25 17:52:08,106 [INFO] Training: 2345/6852 -- loss: 2.013601541519165\n",
      "2021-04-25 17:52:08,156 [INFO] Training: 2346/6852 -- loss: 2.8685266971588135\n",
      "2021-04-25 17:52:08,206 [INFO] Training: 2347/6852 -- loss: 2.1825263500213623\n",
      "2021-04-25 17:52:08,257 [INFO] Training: 2348/6852 -- loss: 1.2216709852218628\n",
      "2021-04-25 17:52:08,310 [INFO] Training: 2349/6852 -- loss: 3.308206081390381\n",
      "2021-04-25 17:52:08,361 [INFO] Training: 2350/6852 -- loss: 3.258803367614746\n",
      "2021-04-25 17:52:08,408 [INFO] Training: 2351/6852 -- loss: 2.202650785446167\n",
      "2021-04-25 17:52:08,457 [INFO] Training: 2352/6852 -- loss: 2.5040998458862305\n",
      "2021-04-25 17:52:08,507 [INFO] Training: 2353/6852 -- loss: 3.865294933319092\n",
      "2021-04-25 17:52:08,555 [INFO] Training: 2354/6852 -- loss: 2.2680587768554688\n",
      "2021-04-25 17:52:08,607 [INFO] Training: 2355/6852 -- loss: 3.1284656524658203\n",
      "2021-04-25 17:52:08,661 [INFO] Training: 2356/6852 -- loss: 2.7485861778259277\n",
      "2021-04-25 17:52:08,711 [INFO] Training: 2357/6852 -- loss: 2.6736984252929688\n",
      "2021-04-25 17:52:08,760 [INFO] Training: 2358/6852 -- loss: 3.2402074337005615\n",
      "2021-04-25 17:52:08,811 [INFO] Training: 2359/6852 -- loss: 2.9398109912872314\n",
      "2021-04-25 17:52:08,859 [INFO] Training: 2360/6852 -- loss: 2.4629082679748535\n",
      "2021-04-25 17:52:08,911 [INFO] Training: 2361/6852 -- loss: 2.538494110107422\n",
      "2021-04-25 17:52:08,963 [INFO] Training: 2362/6852 -- loss: 3.5988266468048096\n",
      "2021-04-25 17:52:09,012 [INFO] Training: 2363/6852 -- loss: 2.5378756523132324\n",
      "2021-04-25 17:52:09,061 [INFO] Training: 2364/6852 -- loss: 1.9758632183074951\n",
      "2021-04-25 17:52:09,110 [INFO] Training: 2365/6852 -- loss: 1.827948808670044\n",
      "2021-04-25 17:52:09,160 [INFO] Training: 2366/6852 -- loss: 2.4360568523406982\n",
      "2021-04-25 17:52:09,208 [INFO] Training: 2367/6852 -- loss: 2.1465463638305664\n",
      "2021-04-25 17:52:09,262 [INFO] Training: 2368/6852 -- loss: 2.092958450317383\n",
      "2021-04-25 17:52:09,310 [INFO] Training: 2369/6852 -- loss: 3.255289077758789\n",
      "2021-04-25 17:52:09,360 [INFO] Training: 2370/6852 -- loss: 3.014594554901123\n",
      "2021-04-25 17:52:09,407 [INFO] Training: 2371/6852 -- loss: 1.71420419216156\n",
      "2021-04-25 17:52:09,458 [INFO] Training: 2372/6852 -- loss: 3.0302252769470215\n",
      "2021-04-25 17:52:09,508 [INFO] Training: 2373/6852 -- loss: 1.6722900867462158\n",
      "2021-04-25 17:52:09,557 [INFO] Training: 2374/6852 -- loss: 2.8042874336242676\n",
      "2021-04-25 17:52:09,606 [INFO] Training: 2375/6852 -- loss: 2.07271409034729\n",
      "2021-04-25 17:52:09,655 [INFO] Training: 2376/6852 -- loss: 3.1764976978302\n",
      "2021-04-25 17:52:09,706 [INFO] Training: 2377/6852 -- loss: 3.268558979034424\n",
      "2021-04-25 17:52:09,753 [INFO] Training: 2378/6852 -- loss: 2.576723098754883\n",
      "2021-04-25 17:52:09,804 [INFO] Training: 2379/6852 -- loss: 3.0177977085113525\n",
      "2021-04-25 17:52:09,851 [INFO] Training: 2380/6852 -- loss: 2.255915403366089\n",
      "2021-04-25 17:52:09,900 [INFO] Training: 2381/6852 -- loss: 2.9907352924346924\n",
      "2021-04-25 17:52:09,949 [INFO] Training: 2382/6852 -- loss: 1.8505033254623413\n",
      "2021-04-25 17:52:09,998 [INFO] Training: 2383/6852 -- loss: 1.9122980833053589\n",
      "2021-04-25 17:52:10,050 [INFO] Training: 2384/6852 -- loss: 3.488125801086426\n",
      "2021-04-25 17:52:10,103 [INFO] Training: 2385/6852 -- loss: 3.9804165363311768\n",
      "2021-04-25 17:52:10,153 [INFO] Training: 2386/6852 -- loss: 2.3002209663391113\n",
      "2021-04-25 17:52:10,203 [INFO] Training: 2387/6852 -- loss: 2.5731148719787598\n",
      "2021-04-25 17:52:10,253 [INFO] Training: 2388/6852 -- loss: 4.594426155090332\n",
      "2021-04-25 17:52:10,304 [INFO] Training: 2389/6852 -- loss: 3.222011089324951\n",
      "2021-04-25 17:52:10,354 [INFO] Training: 2390/6852 -- loss: 2.14631724357605\n",
      "2021-04-25 17:52:10,405 [INFO] Training: 2391/6852 -- loss: 3.2119126319885254\n",
      "2021-04-25 17:52:10,454 [INFO] Training: 2392/6852 -- loss: 3.336385726928711\n",
      "2021-04-25 17:52:10,502 [INFO] Training: 2393/6852 -- loss: 2.5873818397521973\n",
      "2021-04-25 17:52:10,550 [INFO] Training: 2394/6852 -- loss: 2.040635108947754\n",
      "2021-04-25 17:52:10,601 [INFO] Training: 2395/6852 -- loss: 2.154278516769409\n",
      "2021-04-25 17:52:10,649 [INFO] Training: 2396/6852 -- loss: 1.4626325368881226\n",
      "2021-04-25 17:52:10,697 [INFO] Training: 2397/6852 -- loss: 1.8046890497207642\n",
      "2021-04-25 17:52:10,746 [INFO] Training: 2398/6852 -- loss: 2.457786798477173\n",
      "2021-04-25 17:52:10,793 [INFO] Training: 2399/6852 -- loss: 2.998640537261963\n",
      "2021-04-25 17:52:10,843 [INFO] Training: 2400/6852 -- loss: 1.5877183675765991\n",
      "2021-04-25 17:52:13,737 [INFO] Training: iteration: 2400/6852 -- epoch: 4 --  train_loss: 2.726 -- train_accuracy: 0.62 valid_loss: 3.088 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:52:13,780 [INFO] Training: 2401/6852 -- loss: 1.6870627403259277\n",
      "2021-04-25 17:52:13,831 [INFO] Training: 2402/6852 -- loss: 3.088890552520752\n",
      "2021-04-25 17:52:13,882 [INFO] Training: 2403/6852 -- loss: 2.7579360008239746\n",
      "2021-04-25 17:52:13,930 [INFO] Training: 2404/6852 -- loss: 2.497053861618042\n",
      "2021-04-25 17:52:13,981 [INFO] Training: 2405/6852 -- loss: 1.6038434505462646\n",
      "2021-04-25 17:52:14,031 [INFO] Training: 2406/6852 -- loss: 1.5064740180969238\n",
      "2021-04-25 17:52:14,080 [INFO] Training: 2407/6852 -- loss: 2.381061315536499\n",
      "2021-04-25 17:52:14,129 [INFO] Training: 2408/6852 -- loss: 3.122281789779663\n",
      "2021-04-25 17:52:14,181 [INFO] Training: 2409/6852 -- loss: 2.3014354705810547\n",
      "2021-04-25 17:52:14,229 [INFO] Training: 2410/6852 -- loss: 2.6815905570983887\n",
      "2021-04-25 17:52:14,279 [INFO] Training: 2411/6852 -- loss: 3.0925774574279785\n",
      "2021-04-25 17:52:14,327 [INFO] Training: 2412/6852 -- loss: 2.653444290161133\n",
      "2021-04-25 17:52:14,377 [INFO] Training: 2413/6852 -- loss: 2.420206308364868\n",
      "2021-04-25 17:52:14,427 [INFO] Training: 2414/6852 -- loss: 2.445587158203125\n",
      "2021-04-25 17:52:14,477 [INFO] Training: 2415/6852 -- loss: 2.870706796646118\n",
      "2021-04-25 17:52:14,527 [INFO] Training: 2416/6852 -- loss: 1.1705498695373535\n",
      "2021-04-25 17:52:14,577 [INFO] Training: 2417/6852 -- loss: 2.049197196960449\n",
      "2021-04-25 17:52:14,628 [INFO] Training: 2418/6852 -- loss: 2.543623208999634\n",
      "2021-04-25 17:52:14,683 [INFO] Training: 2419/6852 -- loss: 2.4134433269500732\n",
      "2021-04-25 17:52:14,733 [INFO] Training: 2420/6852 -- loss: 2.637911558151245\n",
      "2021-04-25 17:52:14,781 [INFO] Training: 2421/6852 -- loss: 1.9873055219650269\n",
      "2021-04-25 17:52:14,831 [INFO] Training: 2422/6852 -- loss: 2.8189241886138916\n",
      "2021-04-25 17:52:14,879 [INFO] Training: 2423/6852 -- loss: 2.9232232570648193\n",
      "2021-04-25 17:52:14,933 [INFO] Training: 2424/6852 -- loss: 3.4892120361328125\n",
      "2021-04-25 17:52:14,981 [INFO] Training: 2425/6852 -- loss: 2.73767352104187\n",
      "2021-04-25 17:52:15,033 [INFO] Training: 2426/6852 -- loss: 2.4579036235809326\n",
      "2021-04-25 17:52:15,083 [INFO] Training: 2427/6852 -- loss: 2.2621240615844727\n",
      "2021-04-25 17:52:15,134 [INFO] Training: 2428/6852 -- loss: 3.4060208797454834\n",
      "2021-04-25 17:52:15,184 [INFO] Training: 2429/6852 -- loss: 2.198862314224243\n",
      "2021-04-25 17:52:15,237 [INFO] Training: 2430/6852 -- loss: 2.9358456134796143\n",
      "2021-04-25 17:52:15,285 [INFO] Training: 2431/6852 -- loss: 2.8033084869384766\n",
      "2021-04-25 17:52:15,333 [INFO] Training: 2432/6852 -- loss: 2.846916437149048\n",
      "2021-04-25 17:52:15,383 [INFO] Training: 2433/6852 -- loss: 2.982593536376953\n",
      "2021-04-25 17:52:15,432 [INFO] Training: 2434/6852 -- loss: 3.428039312362671\n",
      "2021-04-25 17:52:15,484 [INFO] Training: 2435/6852 -- loss: 3.2021119594573975\n",
      "2021-04-25 17:52:15,535 [INFO] Training: 2436/6852 -- loss: 3.0291647911071777\n",
      "2021-04-25 17:52:15,585 [INFO] Training: 2437/6852 -- loss: 2.56135892868042\n",
      "2021-04-25 17:52:15,632 [INFO] Training: 2438/6852 -- loss: 2.8606338500976562\n",
      "2021-04-25 17:52:15,687 [INFO] Training: 2439/6852 -- loss: 2.2063345909118652\n",
      "2021-04-25 17:52:15,739 [INFO] Training: 2440/6852 -- loss: 2.5637876987457275\n",
      "2021-04-25 17:52:15,790 [INFO] Training: 2441/6852 -- loss: 3.0566110610961914\n",
      "2021-04-25 17:52:15,839 [INFO] Training: 2442/6852 -- loss: 1.6556360721588135\n",
      "2021-04-25 17:52:15,891 [INFO] Training: 2443/6852 -- loss: 2.037304401397705\n",
      "2021-04-25 17:52:15,940 [INFO] Training: 2444/6852 -- loss: 1.6919801235198975\n",
      "2021-04-25 17:52:15,989 [INFO] Training: 2445/6852 -- loss: 2.865170478820801\n",
      "2021-04-25 17:52:16,037 [INFO] Training: 2446/6852 -- loss: 3.0533082485198975\n",
      "2021-04-25 17:52:16,085 [INFO] Training: 2447/6852 -- loss: 3.0913174152374268\n",
      "2021-04-25 17:52:16,136 [INFO] Training: 2448/6852 -- loss: 2.7350339889526367\n",
      "2021-04-25 17:52:16,185 [INFO] Training: 2449/6852 -- loss: 3.3659753799438477\n",
      "2021-04-25 17:52:16,240 [INFO] Training: 2450/6852 -- loss: 3.404881000518799\n",
      "2021-04-25 17:52:16,292 [INFO] Training: 2451/6852 -- loss: 2.8379974365234375\n",
      "2021-04-25 17:52:16,340 [INFO] Training: 2452/6852 -- loss: 2.8136203289031982\n",
      "2021-04-25 17:52:16,392 [INFO] Training: 2453/6852 -- loss: 2.566725730895996\n",
      "2021-04-25 17:52:16,441 [INFO] Training: 2454/6852 -- loss: 2.757953405380249\n",
      "2021-04-25 17:52:16,489 [INFO] Training: 2455/6852 -- loss: 3.2407312393188477\n",
      "2021-04-25 17:52:16,540 [INFO] Training: 2456/6852 -- loss: 2.3254201412200928\n",
      "2021-04-25 17:52:16,587 [INFO] Training: 2457/6852 -- loss: 1.73671293258667\n",
      "2021-04-25 17:52:16,635 [INFO] Training: 2458/6852 -- loss: 3.494847059249878\n",
      "2021-04-25 17:52:16,684 [INFO] Training: 2459/6852 -- loss: 3.2098374366760254\n",
      "2021-04-25 17:52:16,734 [INFO] Training: 2460/6852 -- loss: 2.433586835861206\n",
      "2021-04-25 17:52:16,785 [INFO] Training: 2461/6852 -- loss: 2.256455898284912\n",
      "2021-04-25 17:52:16,837 [INFO] Training: 2462/6852 -- loss: 4.120715141296387\n",
      "2021-04-25 17:52:16,888 [INFO] Training: 2463/6852 -- loss: 3.276989459991455\n",
      "2021-04-25 17:52:16,936 [INFO] Training: 2464/6852 -- loss: 1.8261284828186035\n",
      "2021-04-25 17:52:16,983 [INFO] Training: 2465/6852 -- loss: 2.1086647510528564\n",
      "2021-04-25 17:52:17,031 [INFO] Training: 2466/6852 -- loss: 1.9707080125808716\n",
      "2021-04-25 17:52:17,081 [INFO] Training: 2467/6852 -- loss: 1.2697880268096924\n",
      "2021-04-25 17:52:17,131 [INFO] Training: 2468/6852 -- loss: 2.6277248859405518\n",
      "2021-04-25 17:52:17,179 [INFO] Training: 2469/6852 -- loss: 1.9409149885177612\n",
      "2021-04-25 17:52:17,229 [INFO] Training: 2470/6852 -- loss: 1.6324578523635864\n",
      "2021-04-25 17:52:17,278 [INFO] Training: 2471/6852 -- loss: 3.2044692039489746\n",
      "2021-04-25 17:52:17,327 [INFO] Training: 2472/6852 -- loss: 1.7579902410507202\n",
      "2021-04-25 17:52:17,379 [INFO] Training: 2473/6852 -- loss: 2.625115156173706\n",
      "2021-04-25 17:52:17,427 [INFO] Training: 2474/6852 -- loss: 2.2082924842834473\n",
      "2021-04-25 17:52:17,478 [INFO] Training: 2475/6852 -- loss: 2.4286868572235107\n",
      "2021-04-25 17:52:17,526 [INFO] Training: 2476/6852 -- loss: 3.2958803176879883\n",
      "2021-04-25 17:52:17,578 [INFO] Training: 2477/6852 -- loss: 3.6287636756896973\n",
      "2021-04-25 17:52:17,628 [INFO] Training: 2478/6852 -- loss: 1.6733734607696533\n",
      "2021-04-25 17:52:17,678 [INFO] Training: 2479/6852 -- loss: 1.4337193965911865\n",
      "2021-04-25 17:52:17,728 [INFO] Training: 2480/6852 -- loss: 2.936055898666382\n",
      "2021-04-25 17:52:17,775 [INFO] Training: 2481/6852 -- loss: 2.1718461513519287\n",
      "2021-04-25 17:52:17,825 [INFO] Training: 2482/6852 -- loss: 4.1580963134765625\n",
      "2021-04-25 17:52:17,872 [INFO] Training: 2483/6852 -- loss: 1.9822207689285278\n",
      "2021-04-25 17:52:17,922 [INFO] Training: 2484/6852 -- loss: 2.9605607986450195\n",
      "2021-04-25 17:52:17,979 [INFO] Training: 2485/6852 -- loss: 2.334759473800659\n",
      "2021-04-25 17:52:18,028 [INFO] Training: 2486/6852 -- loss: 3.058722496032715\n",
      "2021-04-25 17:52:18,078 [INFO] Training: 2487/6852 -- loss: 3.1093759536743164\n",
      "2021-04-25 17:52:18,129 [INFO] Training: 2488/6852 -- loss: 1.7459464073181152\n",
      "2021-04-25 17:52:18,179 [INFO] Training: 2489/6852 -- loss: 2.6791977882385254\n",
      "2021-04-25 17:52:18,230 [INFO] Training: 2490/6852 -- loss: 2.180054187774658\n",
      "2021-04-25 17:52:18,277 [INFO] Training: 2491/6852 -- loss: 2.1599972248077393\n",
      "2021-04-25 17:52:18,328 [INFO] Training: 2492/6852 -- loss: 1.6903526782989502\n",
      "2021-04-25 17:52:18,380 [INFO] Training: 2493/6852 -- loss: 2.6923437118530273\n",
      "2021-04-25 17:52:18,428 [INFO] Training: 2494/6852 -- loss: 2.1774814128875732\n",
      "2021-04-25 17:52:18,477 [INFO] Training: 2495/6852 -- loss: 1.9566712379455566\n",
      "2021-04-25 17:52:18,528 [INFO] Training: 2496/6852 -- loss: 3.1263620853424072\n",
      "2021-04-25 17:52:18,578 [INFO] Training: 2497/6852 -- loss: 1.9538979530334473\n",
      "2021-04-25 17:52:18,627 [INFO] Training: 2498/6852 -- loss: 3.246809720993042\n",
      "2021-04-25 17:52:18,677 [INFO] Training: 2499/6852 -- loss: 2.0847792625427246\n",
      "2021-04-25 17:52:18,726 [INFO] Training: 2500/6852 -- loss: 2.801582098007202\n",
      "2021-04-25 17:52:18,778 [INFO] Training: 2501/6852 -- loss: 2.7740318775177\n",
      "2021-04-25 17:52:18,827 [INFO] Training: 2502/6852 -- loss: 2.87424898147583\n",
      "2021-04-25 17:52:18,876 [INFO] Training: 2503/6852 -- loss: 2.8107974529266357\n",
      "2021-04-25 17:52:18,924 [INFO] Training: 2504/6852 -- loss: 2.079975128173828\n",
      "2021-04-25 17:52:18,972 [INFO] Training: 2505/6852 -- loss: 2.820878028869629\n",
      "2021-04-25 17:52:19,024 [INFO] Training: 2506/6852 -- loss: 2.6128180027008057\n",
      "2021-04-25 17:52:19,076 [INFO] Training: 2507/6852 -- loss: 2.4157052040100098\n",
      "2021-04-25 17:52:19,126 [INFO] Training: 2508/6852 -- loss: 2.1749565601348877\n",
      "2021-04-25 17:52:19,175 [INFO] Training: 2509/6852 -- loss: 2.9054787158966064\n",
      "2021-04-25 17:52:19,227 [INFO] Training: 2510/6852 -- loss: 2.574493169784546\n",
      "2021-04-25 17:52:19,275 [INFO] Training: 2511/6852 -- loss: 2.2103707790374756\n",
      "2021-04-25 17:52:19,326 [INFO] Training: 2512/6852 -- loss: 2.3523526191711426\n",
      "2021-04-25 17:52:19,377 [INFO] Training: 2513/6852 -- loss: 1.8169376850128174\n",
      "2021-04-25 17:52:19,428 [INFO] Training: 2514/6852 -- loss: 2.6870148181915283\n",
      "2021-04-25 17:52:19,479 [INFO] Training: 2515/6852 -- loss: 3.625612258911133\n",
      "2021-04-25 17:52:19,530 [INFO] Training: 2516/6852 -- loss: 2.627006769180298\n",
      "2021-04-25 17:52:19,580 [INFO] Training: 2517/6852 -- loss: 2.0154876708984375\n",
      "2021-04-25 17:52:19,634 [INFO] Training: 2518/6852 -- loss: 1.512821912765503\n",
      "2021-04-25 17:52:19,684 [INFO] Training: 2519/6852 -- loss: 1.9566679000854492\n",
      "2021-04-25 17:52:19,735 [INFO] Training: 2520/6852 -- loss: 2.8217101097106934\n",
      "2021-04-25 17:52:19,784 [INFO] Training: 2521/6852 -- loss: 3.1922428607940674\n",
      "2021-04-25 17:52:19,834 [INFO] Training: 2522/6852 -- loss: 4.87125825881958\n",
      "2021-04-25 17:52:19,887 [INFO] Training: 2523/6852 -- loss: 2.744568347930908\n",
      "2021-04-25 17:52:19,940 [INFO] Training: 2524/6852 -- loss: 2.4564945697784424\n",
      "2021-04-25 17:52:19,989 [INFO] Training: 2525/6852 -- loss: 2.4716086387634277\n",
      "2021-04-25 17:52:20,041 [INFO] Training: 2526/6852 -- loss: 1.499169111251831\n",
      "2021-04-25 17:52:20,090 [INFO] Training: 2527/6852 -- loss: 2.788374900817871\n",
      "2021-04-25 17:52:20,141 [INFO] Training: 2528/6852 -- loss: 2.1489598751068115\n",
      "2021-04-25 17:52:20,188 [INFO] Training: 2529/6852 -- loss: 2.8992714881896973\n",
      "2021-04-25 17:52:20,238 [INFO] Training: 2530/6852 -- loss: 2.111719846725464\n",
      "2021-04-25 17:52:20,290 [INFO] Training: 2531/6852 -- loss: 2.500540256500244\n",
      "2021-04-25 17:52:20,339 [INFO] Training: 2532/6852 -- loss: 3.6288399696350098\n",
      "2021-04-25 17:52:20,390 [INFO] Training: 2533/6852 -- loss: 2.416029453277588\n",
      "2021-04-25 17:52:20,437 [INFO] Training: 2534/6852 -- loss: 2.8841989040374756\n",
      "2021-04-25 17:52:20,487 [INFO] Training: 2535/6852 -- loss: 3.6255412101745605\n",
      "2021-04-25 17:52:20,537 [INFO] Training: 2536/6852 -- loss: 2.6301136016845703\n",
      "2021-04-25 17:52:20,586 [INFO] Training: 2537/6852 -- loss: 2.54654860496521\n",
      "2021-04-25 17:52:20,636 [INFO] Training: 2538/6852 -- loss: 1.8283982276916504\n",
      "2021-04-25 17:52:20,685 [INFO] Training: 2539/6852 -- loss: 2.068772315979004\n",
      "2021-04-25 17:52:20,737 [INFO] Training: 2540/6852 -- loss: 2.9965314865112305\n",
      "2021-04-25 17:52:20,789 [INFO] Training: 2541/6852 -- loss: 3.685129165649414\n",
      "2021-04-25 17:52:20,841 [INFO] Training: 2542/6852 -- loss: 2.774977922439575\n",
      "2021-04-25 17:52:20,892 [INFO] Training: 2543/6852 -- loss: 1.8706493377685547\n",
      "2021-04-25 17:52:20,942 [INFO] Training: 2544/6852 -- loss: 2.002479076385498\n",
      "2021-04-25 17:52:20,994 [INFO] Training: 2545/6852 -- loss: 2.405649185180664\n",
      "2021-04-25 17:52:21,044 [INFO] Training: 2546/6852 -- loss: 2.1448569297790527\n",
      "2021-04-25 17:52:21,094 [INFO] Training: 2547/6852 -- loss: 2.9946041107177734\n",
      "2021-04-25 17:52:21,145 [INFO] Training: 2548/6852 -- loss: 3.528733730316162\n",
      "2021-04-25 17:52:21,198 [INFO] Training: 2549/6852 -- loss: 1.9994319677352905\n",
      "2021-04-25 17:52:21,247 [INFO] Training: 2550/6852 -- loss: 3.0748331546783447\n",
      "2021-04-25 17:52:24,135 [INFO] Training: iteration: 2550/6852 -- epoch: 4 --  train_loss: 2.580 -- train_accuracy: 0.25 valid_loss: 3.057 -- valid_accuracy: 0.30\n",
      "2021-04-25 17:52:24,175 [INFO] Training: 2551/6852 -- loss: 1.9973499774932861\n",
      "2021-04-25 17:52:24,225 [INFO] Training: 2552/6852 -- loss: 3.8174619674682617\n",
      "2021-04-25 17:52:24,276 [INFO] Training: 2553/6852 -- loss: 2.6534385681152344\n",
      "2021-04-25 17:52:24,323 [INFO] Training: 2554/6852 -- loss: 2.5440733432769775\n",
      "2021-04-25 17:52:24,377 [INFO] Training: 2555/6852 -- loss: 2.2716474533081055\n",
      "2021-04-25 17:52:24,425 [INFO] Training: 2556/6852 -- loss: 2.659243583679199\n",
      "2021-04-25 17:52:24,473 [INFO] Training: 2557/6852 -- loss: 3.150216817855835\n",
      "2021-04-25 17:52:24,525 [INFO] Training: 2558/6852 -- loss: 3.151688814163208\n",
      "2021-04-25 17:52:24,572 [INFO] Training: 2559/6852 -- loss: 3.0908398628234863\n",
      "2021-04-25 17:52:24,621 [INFO] Training: 2560/6852 -- loss: 2.7487633228302\n",
      "2021-04-25 17:52:24,669 [INFO] Training: 2561/6852 -- loss: 2.6586246490478516\n",
      "2021-04-25 17:52:24,716 [INFO] Training: 2562/6852 -- loss: 3.1739819049835205\n",
      "2021-04-25 17:52:24,765 [INFO] Training: 2563/6852 -- loss: 2.885312795639038\n",
      "2021-04-25 17:52:24,814 [INFO] Training: 2564/6852 -- loss: 1.5601575374603271\n",
      "2021-04-25 17:52:24,867 [INFO] Training: 2565/6852 -- loss: 2.5862019062042236\n",
      "2021-04-25 17:52:24,914 [INFO] Training: 2566/6852 -- loss: 2.7607221603393555\n",
      "2021-04-25 17:52:24,964 [INFO] Training: 2567/6852 -- loss: 1.5503230094909668\n",
      "2021-04-25 17:52:25,015 [INFO] Training: 2568/6852 -- loss: 3.18180513381958\n",
      "2021-04-25 17:52:25,070 [INFO] Training: 2569/6852 -- loss: 2.527601718902588\n",
      "2021-04-25 17:52:25,119 [INFO] Training: 2570/6852 -- loss: 2.2180140018463135\n",
      "2021-04-25 17:52:25,171 [INFO] Training: 2571/6852 -- loss: 2.292449712753296\n",
      "2021-04-25 17:52:25,219 [INFO] Training: 2572/6852 -- loss: 2.5630791187286377\n",
      "2021-04-25 17:52:25,270 [INFO] Training: 2573/6852 -- loss: 2.8607938289642334\n",
      "2021-04-25 17:52:25,320 [INFO] Training: 2574/6852 -- loss: 2.9536373615264893\n",
      "2021-04-25 17:52:25,371 [INFO] Training: 2575/6852 -- loss: 2.1277518272399902\n",
      "2021-04-25 17:52:25,420 [INFO] Training: 2576/6852 -- loss: 1.7636228799819946\n",
      "2021-04-25 17:52:25,469 [INFO] Training: 2577/6852 -- loss: 2.0111594200134277\n",
      "2021-04-25 17:52:25,521 [INFO] Training: 2578/6852 -- loss: 3.7286806106567383\n",
      "2021-04-25 17:52:25,570 [INFO] Training: 2579/6852 -- loss: 2.4036409854888916\n",
      "2021-04-25 17:52:25,622 [INFO] Training: 2580/6852 -- loss: 1.9850196838378906\n",
      "2021-04-25 17:52:25,672 [INFO] Training: 2581/6852 -- loss: 2.5317695140838623\n",
      "2021-04-25 17:52:25,722 [INFO] Training: 2582/6852 -- loss: 2.63897442817688\n",
      "2021-04-25 17:52:25,770 [INFO] Training: 2583/6852 -- loss: 2.484096050262451\n",
      "2021-04-25 17:52:25,820 [INFO] Training: 2584/6852 -- loss: 2.523423194885254\n",
      "2021-04-25 17:52:25,872 [INFO] Training: 2585/6852 -- loss: 3.204864740371704\n",
      "2021-04-25 17:52:25,919 [INFO] Training: 2586/6852 -- loss: 2.3722105026245117\n",
      "2021-04-25 17:52:25,969 [INFO] Training: 2587/6852 -- loss: 1.5305999517440796\n",
      "2021-04-25 17:52:26,020 [INFO] Training: 2588/6852 -- loss: 2.929178237915039\n",
      "2021-04-25 17:52:26,069 [INFO] Training: 2589/6852 -- loss: 2.7174901962280273\n",
      "2021-04-25 17:52:26,118 [INFO] Training: 2590/6852 -- loss: 2.2835960388183594\n",
      "2021-04-25 17:52:26,170 [INFO] Training: 2591/6852 -- loss: 2.1625778675079346\n",
      "2021-04-25 17:52:26,218 [INFO] Training: 2592/6852 -- loss: 2.958005905151367\n",
      "2021-04-25 17:52:26,271 [INFO] Training: 2593/6852 -- loss: 3.094078779220581\n",
      "2021-04-25 17:52:26,320 [INFO] Training: 2594/6852 -- loss: 3.109649658203125\n",
      "2021-04-25 17:52:26,370 [INFO] Training: 2595/6852 -- loss: 2.4551379680633545\n",
      "2021-04-25 17:52:26,420 [INFO] Training: 2596/6852 -- loss: 3.223592758178711\n",
      "2021-04-25 17:52:26,468 [INFO] Training: 2597/6852 -- loss: 2.908175468444824\n",
      "2021-04-25 17:52:26,519 [INFO] Training: 2598/6852 -- loss: 2.0938618183135986\n",
      "2021-04-25 17:52:26,566 [INFO] Training: 2599/6852 -- loss: 2.2531275749206543\n",
      "2021-04-25 17:52:26,614 [INFO] Training: 2600/6852 -- loss: 1.755008578300476\n",
      "2021-04-25 17:52:26,664 [INFO] Training: 2601/6852 -- loss: 2.365936279296875\n",
      "2021-04-25 17:52:26,713 [INFO] Training: 2602/6852 -- loss: 2.4955954551696777\n",
      "2021-04-25 17:52:26,764 [INFO] Training: 2603/6852 -- loss: 2.846919059753418\n",
      "2021-04-25 17:52:26,812 [INFO] Training: 2604/6852 -- loss: 2.089529514312744\n",
      "2021-04-25 17:52:26,864 [INFO] Training: 2605/6852 -- loss: 2.7964558601379395\n",
      "2021-04-25 17:52:26,911 [INFO] Training: 2606/6852 -- loss: 3.088564395904541\n",
      "2021-04-25 17:52:26,963 [INFO] Training: 2607/6852 -- loss: 2.459949016571045\n",
      "2021-04-25 17:52:27,012 [INFO] Training: 2608/6852 -- loss: 1.454386830329895\n",
      "2021-04-25 17:52:27,061 [INFO] Training: 2609/6852 -- loss: 1.8283778429031372\n",
      "2021-04-25 17:52:27,114 [INFO] Training: 2610/6852 -- loss: 2.673086166381836\n",
      "2021-04-25 17:52:27,166 [INFO] Training: 2611/6852 -- loss: 1.9683096408843994\n",
      "2021-04-25 17:52:27,215 [INFO] Training: 2612/6852 -- loss: 2.749868154525757\n",
      "2021-04-25 17:52:27,262 [INFO] Training: 2613/6852 -- loss: 1.963936686515808\n",
      "2021-04-25 17:52:27,315 [INFO] Training: 2614/6852 -- loss: 3.6030166149139404\n",
      "2021-04-25 17:52:27,365 [INFO] Training: 2615/6852 -- loss: 2.1647045612335205\n",
      "2021-04-25 17:52:27,415 [INFO] Training: 2616/6852 -- loss: 2.6886985301971436\n",
      "2021-04-25 17:52:27,462 [INFO] Training: 2617/6852 -- loss: 2.2957208156585693\n",
      "2021-04-25 17:52:27,512 [INFO] Training: 2618/6852 -- loss: 2.6071722507476807\n",
      "2021-04-25 17:52:27,559 [INFO] Training: 2619/6852 -- loss: 2.631030559539795\n",
      "2021-04-25 17:52:27,606 [INFO] Training: 2620/6852 -- loss: 2.798917770385742\n",
      "2021-04-25 17:52:27,654 [INFO] Training: 2621/6852 -- loss: 2.9410388469696045\n",
      "2021-04-25 17:52:27,702 [INFO] Training: 2622/6852 -- loss: 2.4357998371124268\n",
      "2021-04-25 17:52:27,750 [INFO] Training: 2623/6852 -- loss: 2.597790241241455\n",
      "2021-04-25 17:52:27,799 [INFO] Training: 2624/6852 -- loss: 2.604510545730591\n",
      "2021-04-25 17:52:27,847 [INFO] Training: 2625/6852 -- loss: 1.8610420227050781\n",
      "2021-04-25 17:52:27,898 [INFO] Training: 2626/6852 -- loss: 1.9665088653564453\n",
      "2021-04-25 17:52:27,946 [INFO] Training: 2627/6852 -- loss: 3.0705604553222656\n",
      "2021-04-25 17:52:27,996 [INFO] Training: 2628/6852 -- loss: 2.816450834274292\n",
      "2021-04-25 17:52:28,045 [INFO] Training: 2629/6852 -- loss: 2.775573968887329\n",
      "2021-04-25 17:52:28,097 [INFO] Training: 2630/6852 -- loss: 1.7944468259811401\n",
      "2021-04-25 17:52:28,147 [INFO] Training: 2631/6852 -- loss: 2.452333927154541\n",
      "2021-04-25 17:52:28,196 [INFO] Training: 2632/6852 -- loss: 2.3928301334381104\n",
      "2021-04-25 17:52:28,248 [INFO] Training: 2633/6852 -- loss: 3.03438663482666\n",
      "2021-04-25 17:52:28,294 [INFO] Training: 2634/6852 -- loss: 3.767517566680908\n",
      "2021-04-25 17:52:28,347 [INFO] Training: 2635/6852 -- loss: 2.898364543914795\n",
      "2021-04-25 17:52:28,397 [INFO] Training: 2636/6852 -- loss: 2.9111580848693848\n",
      "2021-04-25 17:52:28,450 [INFO] Training: 2637/6852 -- loss: 3.3998372554779053\n",
      "2021-04-25 17:52:28,497 [INFO] Training: 2638/6852 -- loss: 2.6623268127441406\n",
      "2021-04-25 17:52:28,545 [INFO] Training: 2639/6852 -- loss: 2.1994643211364746\n",
      "2021-04-25 17:52:28,593 [INFO] Training: 2640/6852 -- loss: 2.773900032043457\n",
      "2021-04-25 17:52:28,642 [INFO] Training: 2641/6852 -- loss: 2.225442409515381\n",
      "2021-04-25 17:52:28,690 [INFO] Training: 2642/6852 -- loss: 1.948270320892334\n",
      "2021-04-25 17:52:28,738 [INFO] Training: 2643/6852 -- loss: 2.408348798751831\n",
      "2021-04-25 17:52:28,789 [INFO] Training: 2644/6852 -- loss: 2.502154588699341\n",
      "2021-04-25 17:52:28,836 [INFO] Training: 2645/6852 -- loss: 2.3343045711517334\n",
      "2021-04-25 17:52:28,885 [INFO] Training: 2646/6852 -- loss: 2.279785394668579\n",
      "2021-04-25 17:52:28,933 [INFO] Training: 2647/6852 -- loss: 2.492417573928833\n",
      "2021-04-25 17:52:28,981 [INFO] Training: 2648/6852 -- loss: 2.482823133468628\n",
      "2021-04-25 17:52:29,030 [INFO] Training: 2649/6852 -- loss: 2.4430713653564453\n",
      "2021-04-25 17:52:29,079 [INFO] Training: 2650/6852 -- loss: 2.3557634353637695\n",
      "2021-04-25 17:52:29,128 [INFO] Training: 2651/6852 -- loss: 2.74951171875\n",
      "2021-04-25 17:52:29,179 [INFO] Training: 2652/6852 -- loss: 2.492765426635742\n",
      "2021-04-25 17:52:29,228 [INFO] Training: 2653/6852 -- loss: 3.247586488723755\n",
      "2021-04-25 17:52:29,275 [INFO] Training: 2654/6852 -- loss: 2.010899066925049\n",
      "2021-04-25 17:52:29,325 [INFO] Training: 2655/6852 -- loss: 1.9809176921844482\n",
      "2021-04-25 17:52:29,372 [INFO] Training: 2656/6852 -- loss: 3.683586597442627\n",
      "2021-04-25 17:52:29,421 [INFO] Training: 2657/6852 -- loss: 2.491668224334717\n",
      "2021-04-25 17:52:29,469 [INFO] Training: 2658/6852 -- loss: 3.809854030609131\n",
      "2021-04-25 17:52:29,522 [INFO] Training: 2659/6852 -- loss: 2.638570547103882\n",
      "2021-04-25 17:52:29,572 [INFO] Training: 2660/6852 -- loss: 2.438398838043213\n",
      "2021-04-25 17:52:29,622 [INFO] Training: 2661/6852 -- loss: 2.7462525367736816\n",
      "2021-04-25 17:52:29,672 [INFO] Training: 2662/6852 -- loss: 3.339038610458374\n",
      "2021-04-25 17:52:29,722 [INFO] Training: 2663/6852 -- loss: 2.114030122756958\n",
      "2021-04-25 17:52:29,772 [INFO] Training: 2664/6852 -- loss: 3.185762882232666\n",
      "2021-04-25 17:52:29,818 [INFO] Training: 2665/6852 -- loss: 1.5215027332305908\n",
      "2021-04-25 17:52:29,869 [INFO] Training: 2666/6852 -- loss: 2.2978107929229736\n",
      "2021-04-25 17:52:29,918 [INFO] Training: 2667/6852 -- loss: 4.4062886238098145\n",
      "2021-04-25 17:52:29,969 [INFO] Training: 2668/6852 -- loss: 2.2193844318389893\n",
      "2021-04-25 17:52:30,020 [INFO] Training: 2669/6852 -- loss: 1.538769006729126\n",
      "2021-04-25 17:52:30,071 [INFO] Training: 2670/6852 -- loss: 3.352170467376709\n",
      "2021-04-25 17:52:30,121 [INFO] Training: 2671/6852 -- loss: 2.5045690536499023\n",
      "2021-04-25 17:52:30,171 [INFO] Training: 2672/6852 -- loss: 3.096251964569092\n",
      "2021-04-25 17:52:30,220 [INFO] Training: 2673/6852 -- loss: 3.2397053241729736\n",
      "2021-04-25 17:52:30,268 [INFO] Training: 2674/6852 -- loss: 3.151960849761963\n",
      "2021-04-25 17:52:30,319 [INFO] Training: 2675/6852 -- loss: 1.8718317747116089\n",
      "2021-04-25 17:52:30,367 [INFO] Training: 2676/6852 -- loss: 2.0119829177856445\n",
      "2021-04-25 17:52:30,417 [INFO] Training: 2677/6852 -- loss: 2.0150864124298096\n",
      "2021-04-25 17:52:30,472 [INFO] Training: 2678/6852 -- loss: 3.693918228149414\n",
      "2021-04-25 17:52:30,522 [INFO] Training: 2679/6852 -- loss: 3.5948104858398438\n",
      "2021-04-25 17:52:30,571 [INFO] Training: 2680/6852 -- loss: 4.010750770568848\n",
      "2021-04-25 17:52:30,620 [INFO] Training: 2681/6852 -- loss: 4.32216739654541\n",
      "2021-04-25 17:52:30,670 [INFO] Training: 2682/6852 -- loss: 2.5191688537597656\n",
      "2021-04-25 17:52:30,720 [INFO] Training: 2683/6852 -- loss: 2.281338930130005\n",
      "2021-04-25 17:52:30,770 [INFO] Training: 2684/6852 -- loss: 1.554889440536499\n",
      "2021-04-25 17:52:30,817 [INFO] Training: 2685/6852 -- loss: 2.876194953918457\n",
      "2021-04-25 17:52:30,869 [INFO] Training: 2686/6852 -- loss: 2.650897264480591\n",
      "2021-04-25 17:52:30,917 [INFO] Training: 2687/6852 -- loss: 2.4216296672821045\n",
      "2021-04-25 17:52:30,966 [INFO] Training: 2688/6852 -- loss: 3.243738889694214\n",
      "2021-04-25 17:52:31,014 [INFO] Training: 2689/6852 -- loss: 3.19888973236084\n",
      "2021-04-25 17:52:31,064 [INFO] Training: 2690/6852 -- loss: 2.7262675762176514\n",
      "2021-04-25 17:52:31,121 [INFO] Training: 2691/6852 -- loss: 2.405452013015747\n",
      "2021-04-25 17:52:31,175 [INFO] Training: 2692/6852 -- loss: 1.871408224105835\n",
      "2021-04-25 17:52:31,225 [INFO] Training: 2693/6852 -- loss: 2.199978828430176\n",
      "2021-04-25 17:52:31,273 [INFO] Training: 2694/6852 -- loss: 2.4145090579986572\n",
      "2021-04-25 17:52:31,320 [INFO] Training: 2695/6852 -- loss: 2.4303524494171143\n",
      "2021-04-25 17:52:31,370 [INFO] Training: 2696/6852 -- loss: 2.3372929096221924\n",
      "2021-04-25 17:52:31,421 [INFO] Training: 2697/6852 -- loss: 2.185004711151123\n",
      "2021-04-25 17:52:31,475 [INFO] Training: 2698/6852 -- loss: 3.457296371459961\n",
      "2021-04-25 17:52:31,527 [INFO] Training: 2699/6852 -- loss: 1.892810583114624\n",
      "2021-04-25 17:52:31,576 [INFO] Training: 2700/6852 -- loss: 1.8377736806869507\n",
      "2021-04-25 17:52:34,440 [INFO] Training: iteration: 2700/6852 -- epoch: 4 --  train_loss: 2.599 -- train_accuracy: 0.50 valid_loss: 3.013 -- valid_accuracy: 0.28\n",
      "2021-04-25 17:52:34,479 [INFO] Training: 2701/6852 -- loss: 1.8228338956832886\n",
      "2021-04-25 17:52:34,527 [INFO] Training: 2702/6852 -- loss: 3.8573484420776367\n",
      "2021-04-25 17:52:34,578 [INFO] Training: 2703/6852 -- loss: 1.705658197402954\n",
      "2021-04-25 17:52:34,626 [INFO] Training: 2704/6852 -- loss: 2.91892147064209\n",
      "2021-04-25 17:52:34,677 [INFO] Training: 2705/6852 -- loss: 3.5735809803009033\n",
      "2021-04-25 17:52:34,730 [INFO] Training: 2706/6852 -- loss: 2.577432870864868\n",
      "2021-04-25 17:52:34,779 [INFO] Training: 2707/6852 -- loss: 4.393950939178467\n",
      "2021-04-25 17:52:34,832 [INFO] Training: 2708/6852 -- loss: 1.8254164457321167\n",
      "2021-04-25 17:52:34,882 [INFO] Training: 2709/6852 -- loss: 2.0058786869049072\n",
      "2021-04-25 17:52:34,935 [INFO] Training: 2710/6852 -- loss: 3.6095099449157715\n",
      "2021-04-25 17:52:34,986 [INFO] Training: 2711/6852 -- loss: 1.882513403892517\n",
      "2021-04-25 17:52:35,039 [INFO] Training: 2712/6852 -- loss: 2.8039281368255615\n",
      "2021-04-25 17:52:35,090 [INFO] Training: 2713/6852 -- loss: 3.085143566131592\n",
      "2021-04-25 17:52:35,137 [INFO] Training: 2714/6852 -- loss: 1.712228775024414\n",
      "2021-04-25 17:52:35,189 [INFO] Training: 2715/6852 -- loss: 2.666904926300049\n",
      "2021-04-25 17:52:35,237 [INFO] Training: 2716/6852 -- loss: 2.2924513816833496\n",
      "2021-04-25 17:52:35,285 [INFO] Training: 2717/6852 -- loss: 3.1827187538146973\n",
      "2021-04-25 17:52:35,336 [INFO] Training: 2718/6852 -- loss: 1.7876904010772705\n",
      "2021-04-25 17:52:35,387 [INFO] Training: 2719/6852 -- loss: 3.3059065341949463\n",
      "2021-04-25 17:52:35,437 [INFO] Training: 2720/6852 -- loss: 2.704432964324951\n",
      "2021-04-25 17:52:35,487 [INFO] Training: 2721/6852 -- loss: 3.3343355655670166\n",
      "2021-04-25 17:52:35,538 [INFO] Training: 2722/6852 -- loss: 3.52028489112854\n",
      "2021-04-25 17:52:35,591 [INFO] Training: 2723/6852 -- loss: 2.2972419261932373\n",
      "2021-04-25 17:52:35,638 [INFO] Training: 2724/6852 -- loss: 2.3028650283813477\n",
      "2021-04-25 17:52:35,689 [INFO] Training: 2725/6852 -- loss: 2.490110397338867\n",
      "2021-04-25 17:52:35,741 [INFO] Training: 2726/6852 -- loss: 2.0117461681365967\n",
      "2021-04-25 17:52:35,788 [INFO] Training: 2727/6852 -- loss: 2.768047571182251\n",
      "2021-04-25 17:52:35,839 [INFO] Training: 2728/6852 -- loss: 2.806847333908081\n",
      "2021-04-25 17:52:35,890 [INFO] Training: 2729/6852 -- loss: 2.727504014968872\n",
      "2021-04-25 17:52:35,940 [INFO] Training: 2730/6852 -- loss: 2.6076297760009766\n",
      "2021-04-25 17:52:35,989 [INFO] Training: 2731/6852 -- loss: 3.1510181427001953\n",
      "2021-04-25 17:52:36,041 [INFO] Training: 2732/6852 -- loss: 2.5590734481811523\n",
      "2021-04-25 17:52:36,088 [INFO] Training: 2733/6852 -- loss: 2.4341328144073486\n",
      "2021-04-25 17:52:36,136 [INFO] Training: 2734/6852 -- loss: 2.2160329818725586\n",
      "2021-04-25 17:52:36,187 [INFO] Training: 2735/6852 -- loss: 1.861476182937622\n",
      "2021-04-25 17:52:36,241 [INFO] Training: 2736/6852 -- loss: 2.473923921585083\n",
      "2021-04-25 17:52:36,289 [INFO] Training: 2737/6852 -- loss: 3.507293701171875\n",
      "2021-04-25 17:52:36,343 [INFO] Training: 2738/6852 -- loss: 3.1111791133880615\n",
      "2021-04-25 17:52:36,394 [INFO] Training: 2739/6852 -- loss: 2.9515461921691895\n",
      "2021-04-25 17:52:36,445 [INFO] Training: 2740/6852 -- loss: 1.9037578105926514\n",
      "2021-04-25 17:52:36,494 [INFO] Training: 2741/6852 -- loss: 3.4906206130981445\n",
      "2021-04-25 17:52:36,546 [INFO] Training: 2742/6852 -- loss: 3.370044708251953\n",
      "2021-04-25 17:52:36,595 [INFO] Training: 2743/6852 -- loss: 3.4124951362609863\n",
      "2021-04-25 17:52:36,642 [INFO] Training: 2744/6852 -- loss: 2.1603708267211914\n",
      "2021-04-25 17:52:36,693 [INFO] Training: 2745/6852 -- loss: 3.5780680179595947\n",
      "2021-04-25 17:52:36,740 [INFO] Training: 2746/6852 -- loss: 2.979964256286621\n",
      "2021-04-25 17:52:36,788 [INFO] Training: 2747/6852 -- loss: 3.3424525260925293\n",
      "2021-04-25 17:52:36,835 [INFO] Training: 2748/6852 -- loss: 2.6702072620391846\n",
      "2021-04-25 17:52:36,883 [INFO] Training: 2749/6852 -- loss: 3.3694729804992676\n",
      "2021-04-25 17:52:36,934 [INFO] Training: 2750/6852 -- loss: 3.0907440185546875\n",
      "2021-04-25 17:52:36,987 [INFO] Training: 2751/6852 -- loss: 2.102325677871704\n",
      "2021-04-25 17:52:37,037 [INFO] Training: 2752/6852 -- loss: 2.668302059173584\n",
      "2021-04-25 17:52:37,084 [INFO] Training: 2753/6852 -- loss: 2.8685176372528076\n",
      "2021-04-25 17:52:37,136 [INFO] Training: 2754/6852 -- loss: 3.198060989379883\n",
      "2021-04-25 17:52:37,184 [INFO] Training: 2755/6852 -- loss: 2.2594871520996094\n",
      "2021-04-25 17:52:37,235 [INFO] Training: 2756/6852 -- loss: 1.9987027645111084\n",
      "2021-04-25 17:52:37,285 [INFO] Training: 2757/6852 -- loss: 3.945855140686035\n",
      "2021-04-25 17:52:37,336 [INFO] Training: 2758/6852 -- loss: 2.4662179946899414\n",
      "2021-04-25 17:52:37,386 [INFO] Training: 2759/6852 -- loss: 2.696790933609009\n",
      "2021-04-25 17:52:37,433 [INFO] Training: 2760/6852 -- loss: 2.541804790496826\n",
      "2021-04-25 17:52:37,487 [INFO] Training: 2761/6852 -- loss: 2.6129863262176514\n",
      "2021-04-25 17:52:37,535 [INFO] Training: 2762/6852 -- loss: 2.627448558807373\n",
      "2021-04-25 17:52:37,587 [INFO] Training: 2763/6852 -- loss: 2.8030834197998047\n",
      "2021-04-25 17:52:37,633 [INFO] Training: 2764/6852 -- loss: 2.7471985816955566\n",
      "2021-04-25 17:52:37,683 [INFO] Training: 2765/6852 -- loss: 4.820474147796631\n",
      "2021-04-25 17:52:37,732 [INFO] Training: 2766/6852 -- loss: 2.50334095954895\n",
      "2021-04-25 17:52:37,780 [INFO] Training: 2767/6852 -- loss: 2.301920175552368\n",
      "2021-04-25 17:52:37,831 [INFO] Training: 2768/6852 -- loss: 2.930168867111206\n",
      "2021-04-25 17:52:37,878 [INFO] Training: 2769/6852 -- loss: 1.7559617757797241\n",
      "2021-04-25 17:52:37,927 [INFO] Training: 2770/6852 -- loss: 2.3009748458862305\n",
      "2021-04-25 17:52:37,978 [INFO] Training: 2771/6852 -- loss: 2.6907341480255127\n",
      "2021-04-25 17:52:38,027 [INFO] Training: 2772/6852 -- loss: 3.5230541229248047\n",
      "2021-04-25 17:52:38,077 [INFO] Training: 2773/6852 -- loss: 2.1381607055664062\n",
      "2021-04-25 17:52:38,127 [INFO] Training: 2774/6852 -- loss: 3.0189895629882812\n",
      "2021-04-25 17:52:38,176 [INFO] Training: 2775/6852 -- loss: 1.34686279296875\n",
      "2021-04-25 17:52:38,224 [INFO] Training: 2776/6852 -- loss: 2.986469268798828\n",
      "2021-04-25 17:52:38,274 [INFO] Training: 2777/6852 -- loss: 2.403744697570801\n",
      "2021-04-25 17:52:38,323 [INFO] Training: 2778/6852 -- loss: 4.082313537597656\n",
      "2021-04-25 17:52:38,370 [INFO] Training: 2779/6852 -- loss: 2.2427024841308594\n",
      "2021-04-25 17:52:38,420 [INFO] Training: 2780/6852 -- loss: 2.9784586429595947\n",
      "2021-04-25 17:52:38,467 [INFO] Training: 2781/6852 -- loss: 2.892683506011963\n",
      "2021-04-25 17:52:38,519 [INFO] Training: 2782/6852 -- loss: 2.883057117462158\n",
      "2021-04-25 17:52:38,568 [INFO] Training: 2783/6852 -- loss: 2.8716022968292236\n",
      "2021-04-25 17:52:38,620 [INFO] Training: 2784/6852 -- loss: 2.2760019302368164\n",
      "2021-04-25 17:52:38,667 [INFO] Training: 2785/6852 -- loss: 2.9542431831359863\n",
      "2021-04-25 17:52:38,716 [INFO] Training: 2786/6852 -- loss: 4.431282043457031\n",
      "2021-04-25 17:52:38,765 [INFO] Training: 2787/6852 -- loss: 3.2497167587280273\n",
      "2021-04-25 17:52:38,816 [INFO] Training: 2788/6852 -- loss: 2.3119375705718994\n",
      "2021-04-25 17:52:38,864 [INFO] Training: 2789/6852 -- loss: 3.1251237392425537\n",
      "2021-04-25 17:52:38,914 [INFO] Training: 2790/6852 -- loss: 2.9830775260925293\n",
      "2021-04-25 17:52:38,966 [INFO] Training: 2791/6852 -- loss: 1.9879858493804932\n",
      "2021-04-25 17:52:39,015 [INFO] Training: 2792/6852 -- loss: 3.1873152256011963\n",
      "2021-04-25 17:52:39,067 [INFO] Training: 2793/6852 -- loss: 3.0973596572875977\n",
      "2021-04-25 17:52:39,116 [INFO] Training: 2794/6852 -- loss: 1.6111150979995728\n",
      "2021-04-25 17:52:39,164 [INFO] Training: 2795/6852 -- loss: 2.550368309020996\n",
      "2021-04-25 17:52:39,214 [INFO] Training: 2796/6852 -- loss: 2.2339284420013428\n",
      "2021-04-25 17:52:39,266 [INFO] Training: 2797/6852 -- loss: 2.550359010696411\n",
      "2021-04-25 17:52:39,312 [INFO] Training: 2798/6852 -- loss: 2.2294256687164307\n",
      "2021-04-25 17:52:39,358 [INFO] Training: 2799/6852 -- loss: 1.9532835483551025\n",
      "2021-04-25 17:52:39,408 [INFO] Training: 2800/6852 -- loss: 1.8420075178146362\n",
      "2021-04-25 17:52:39,458 [INFO] Training: 2801/6852 -- loss: 1.9744006395339966\n",
      "2021-04-25 17:52:39,505 [INFO] Training: 2802/6852 -- loss: 2.665163516998291\n",
      "2021-04-25 17:52:39,555 [INFO] Training: 2803/6852 -- loss: 2.6391971111297607\n",
      "2021-04-25 17:52:39,603 [INFO] Training: 2804/6852 -- loss: 2.9472172260284424\n",
      "2021-04-25 17:52:39,655 [INFO] Training: 2805/6852 -- loss: 2.6412248611450195\n",
      "2021-04-25 17:52:39,703 [INFO] Training: 2806/6852 -- loss: 2.762566328048706\n",
      "2021-04-25 17:52:39,754 [INFO] Training: 2807/6852 -- loss: 3.4899847507476807\n",
      "2021-04-25 17:52:39,801 [INFO] Training: 2808/6852 -- loss: 3.3189828395843506\n",
      "2021-04-25 17:52:39,849 [INFO] Training: 2809/6852 -- loss: 2.645023822784424\n",
      "2021-04-25 17:52:39,900 [INFO] Training: 2810/6852 -- loss: 2.1613779067993164\n",
      "2021-04-25 17:52:39,947 [INFO] Training: 2811/6852 -- loss: 2.1984610557556152\n",
      "2021-04-25 17:52:39,995 [INFO] Training: 2812/6852 -- loss: 2.2209341526031494\n",
      "2021-04-25 17:52:40,045 [INFO] Training: 2813/6852 -- loss: 2.6379411220550537\n",
      "2021-04-25 17:52:40,095 [INFO] Training: 2814/6852 -- loss: 2.9024198055267334\n",
      "2021-04-25 17:52:40,145 [INFO] Training: 2815/6852 -- loss: 2.9168620109558105\n",
      "2021-04-25 17:52:40,195 [INFO] Training: 2816/6852 -- loss: 3.763718605041504\n",
      "2021-04-25 17:52:40,245 [INFO] Training: 2817/6852 -- loss: 3.2882468700408936\n",
      "2021-04-25 17:52:40,293 [INFO] Training: 2818/6852 -- loss: 2.920422077178955\n",
      "2021-04-25 17:52:40,348 [INFO] Training: 2819/6852 -- loss: 2.0364935398101807\n",
      "2021-04-25 17:52:40,399 [INFO] Training: 2820/6852 -- loss: 3.2122180461883545\n",
      "2021-04-25 17:52:40,448 [INFO] Training: 2821/6852 -- loss: 2.398407220840454\n",
      "2021-04-25 17:52:40,499 [INFO] Training: 2822/6852 -- loss: 3.554473400115967\n",
      "2021-04-25 17:52:40,547 [INFO] Training: 2823/6852 -- loss: 2.3438451290130615\n",
      "2021-04-25 17:52:40,598 [INFO] Training: 2824/6852 -- loss: 3.322808265686035\n",
      "2021-04-25 17:52:40,647 [INFO] Training: 2825/6852 -- loss: 3.5770926475524902\n",
      "2021-04-25 17:52:40,696 [INFO] Training: 2826/6852 -- loss: 2.4616873264312744\n",
      "2021-04-25 17:52:40,747 [INFO] Training: 2827/6852 -- loss: 2.5657291412353516\n",
      "2021-04-25 17:52:40,794 [INFO] Training: 2828/6852 -- loss: 2.515350103378296\n",
      "2021-04-25 17:52:40,844 [INFO] Training: 2829/6852 -- loss: 3.930877685546875\n",
      "2021-04-25 17:52:40,896 [INFO] Training: 2830/6852 -- loss: 1.8514878749847412\n",
      "2021-04-25 17:52:40,944 [INFO] Training: 2831/6852 -- loss: 1.956833004951477\n",
      "2021-04-25 17:52:40,993 [INFO] Training: 2832/6852 -- loss: 2.680244207382202\n",
      "2021-04-25 17:52:41,040 [INFO] Training: 2833/6852 -- loss: 2.480086326599121\n",
      "2021-04-25 17:52:41,094 [INFO] Training: 2834/6852 -- loss: 1.873647689819336\n",
      "2021-04-25 17:52:41,146 [INFO] Training: 2835/6852 -- loss: 4.235256671905518\n",
      "2021-04-25 17:52:41,195 [INFO] Training: 2836/6852 -- loss: 4.457769870758057\n",
      "2021-04-25 17:52:41,243 [INFO] Training: 2837/6852 -- loss: 3.102602005004883\n",
      "2021-04-25 17:52:41,293 [INFO] Training: 2838/6852 -- loss: 2.7831530570983887\n",
      "2021-04-25 17:52:41,346 [INFO] Training: 2839/6852 -- loss: 3.5554721355438232\n",
      "2021-04-25 17:52:41,393 [INFO] Training: 2840/6852 -- loss: 2.5192956924438477\n",
      "2021-04-25 17:52:41,444 [INFO] Training: 2841/6852 -- loss: 3.2958736419677734\n",
      "2021-04-25 17:52:41,493 [INFO] Training: 2842/6852 -- loss: 2.666055202484131\n",
      "2021-04-25 17:52:41,544 [INFO] Training: 2843/6852 -- loss: 2.103419303894043\n",
      "2021-04-25 17:52:41,591 [INFO] Training: 2844/6852 -- loss: 2.1467878818511963\n",
      "2021-04-25 17:52:41,641 [INFO] Training: 2845/6852 -- loss: 2.7867496013641357\n",
      "2021-04-25 17:52:41,691 [INFO] Training: 2846/6852 -- loss: 2.0797271728515625\n",
      "2021-04-25 17:52:41,744 [INFO] Training: 2847/6852 -- loss: 1.70751953125\n",
      "2021-04-25 17:52:41,793 [INFO] Training: 2848/6852 -- loss: 3.362366199493408\n",
      "2021-04-25 17:52:41,841 [INFO] Training: 2849/6852 -- loss: 3.2399179935455322\n",
      "2021-04-25 17:52:41,889 [INFO] Training: 2850/6852 -- loss: 2.394259214401245\n",
      "2021-04-25 17:52:44,752 [INFO] Training: iteration: 2850/6852 -- epoch: 4 --  train_loss: 2.749 -- train_accuracy: 0.38 valid_loss: 2.976 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:52:44,788 [INFO] Training: 2851/6852 -- loss: 2.2008659839630127\n",
      "2021-04-25 17:52:44,836 [INFO] Training: 2852/6852 -- loss: 1.6546119451522827\n",
      "2021-04-25 17:52:44,883 [INFO] Training: 2853/6852 -- loss: 1.7777113914489746\n",
      "2021-04-25 17:52:44,930 [INFO] Training: 2854/6852 -- loss: 2.8534789085388184\n",
      "2021-04-25 17:52:45,194 [INFO] Training: 2855/6852 -- loss: 1.7994599342346191\n",
      "2021-04-25 17:52:45,252 [INFO] Training: 2856/6852 -- loss: 2.8036978244781494\n",
      "2021-04-25 17:52:45,304 [INFO] Training: 2857/6852 -- loss: 2.324965000152588\n",
      "2021-04-25 17:52:45,352 [INFO] Training: 2858/6852 -- loss: 2.6102936267852783\n",
      "2021-04-25 17:52:45,409 [INFO] Training: 2859/6852 -- loss: 3.7927656173706055\n",
      "2021-04-25 17:52:45,458 [INFO] Training: 2860/6852 -- loss: 2.51373291015625\n",
      "2021-04-25 17:52:45,507 [INFO] Training: 2861/6852 -- loss: 2.2919442653656006\n",
      "2021-04-25 17:52:45,555 [INFO] Training: 2862/6852 -- loss: 2.113351821899414\n",
      "2021-04-25 17:52:45,603 [INFO] Training: 2863/6852 -- loss: 1.635399341583252\n",
      "2021-04-25 17:52:45,655 [INFO] Training: 2864/6852 -- loss: 1.9964503049850464\n",
      "2021-04-25 17:52:45,704 [INFO] Training: 2865/6852 -- loss: 1.9544557332992554\n",
      "2021-04-25 17:52:45,753 [INFO] Training: 2866/6852 -- loss: 2.3061368465423584\n",
      "2021-04-25 17:52:45,803 [INFO] Training: 2867/6852 -- loss: 1.9500218629837036\n",
      "2021-04-25 17:52:45,851 [INFO] Training: 2868/6852 -- loss: 2.4347240924835205\n",
      "2021-04-25 17:52:45,903 [INFO] Training: 2869/6852 -- loss: 2.8604164123535156\n",
      "2021-04-25 17:52:45,954 [INFO] Training: 2870/6852 -- loss: 2.9582135677337646\n",
      "2021-04-25 17:52:46,003 [INFO] Training: 2871/6852 -- loss: 1.9864044189453125\n",
      "2021-04-25 17:52:46,054 [INFO] Training: 2872/6852 -- loss: 2.333101511001587\n",
      "2021-04-25 17:52:46,102 [INFO] Training: 2873/6852 -- loss: 1.8610409498214722\n",
      "2021-04-25 17:52:46,152 [INFO] Training: 2874/6852 -- loss: 2.6062614917755127\n",
      "2021-04-25 17:52:46,202 [INFO] Training: 2875/6852 -- loss: 2.0907719135284424\n",
      "2021-04-25 17:52:46,254 [INFO] Training: 2876/6852 -- loss: 2.1389074325561523\n",
      "2021-04-25 17:52:46,304 [INFO] Training: 2877/6852 -- loss: 1.592113971710205\n",
      "2021-04-25 17:52:46,355 [INFO] Training: 2878/6852 -- loss: 2.365063428878784\n",
      "2021-04-25 17:52:46,405 [INFO] Training: 2879/6852 -- loss: 2.2044785022735596\n",
      "2021-04-25 17:52:46,456 [INFO] Training: 2880/6852 -- loss: 1.791706919670105\n",
      "2021-04-25 17:52:46,506 [INFO] Training: 2881/6852 -- loss: 1.0236287117004395\n",
      "2021-04-25 17:52:46,554 [INFO] Training: 2882/6852 -- loss: 2.120811700820923\n",
      "2021-04-25 17:52:46,606 [INFO] Training: 2883/6852 -- loss: 2.3608691692352295\n",
      "2021-04-25 17:52:46,655 [INFO] Training: 2884/6852 -- loss: 2.234177589416504\n",
      "2021-04-25 17:52:46,704 [INFO] Training: 2885/6852 -- loss: 3.3826937675476074\n",
      "2021-04-25 17:52:46,758 [INFO] Training: 2886/6852 -- loss: 2.823051929473877\n",
      "2021-04-25 17:52:46,809 [INFO] Training: 2887/6852 -- loss: 1.6444653272628784\n",
      "2021-04-25 17:52:46,855 [INFO] Training: 2888/6852 -- loss: 2.713984727859497\n",
      "2021-04-25 17:52:46,905 [INFO] Training: 2889/6852 -- loss: 1.6852848529815674\n",
      "2021-04-25 17:52:46,953 [INFO] Training: 2890/6852 -- loss: 3.135631561279297\n",
      "2021-04-25 17:52:47,004 [INFO] Training: 2891/6852 -- loss: 1.928924798965454\n",
      "2021-04-25 17:52:47,053 [INFO] Training: 2892/6852 -- loss: 1.947738766670227\n",
      "2021-04-25 17:52:47,099 [INFO] Training: 2893/6852 -- loss: 2.1984620094299316\n",
      "2021-04-25 17:52:47,153 [INFO] Training: 2894/6852 -- loss: 2.619471311569214\n",
      "2021-04-25 17:52:47,201 [INFO] Training: 2895/6852 -- loss: 2.1265854835510254\n",
      "2021-04-25 17:52:47,251 [INFO] Training: 2896/6852 -- loss: 2.0392134189605713\n",
      "2021-04-25 17:52:47,302 [INFO] Training: 2897/6852 -- loss: 3.1107611656188965\n",
      "2021-04-25 17:52:47,353 [INFO] Training: 2898/6852 -- loss: 3.3913872241973877\n",
      "2021-04-25 17:52:47,404 [INFO] Training: 2899/6852 -- loss: 1.547484040260315\n",
      "2021-04-25 17:52:47,456 [INFO] Training: 2900/6852 -- loss: 1.795127272605896\n",
      "2021-04-25 17:52:47,502 [INFO] Training: 2901/6852 -- loss: 1.7460285425186157\n",
      "2021-04-25 17:52:47,554 [INFO] Training: 2902/6852 -- loss: 1.9901169538497925\n",
      "2021-04-25 17:52:47,602 [INFO] Training: 2903/6852 -- loss: 1.969678282737732\n",
      "2021-04-25 17:52:47,651 [INFO] Training: 2904/6852 -- loss: 1.8989911079406738\n",
      "2021-04-25 17:52:47,700 [INFO] Training: 2905/6852 -- loss: 2.518843173980713\n",
      "2021-04-25 17:52:47,748 [INFO] Training: 2906/6852 -- loss: 2.7946197986602783\n",
      "2021-04-25 17:52:47,799 [INFO] Training: 2907/6852 -- loss: 2.354093313217163\n",
      "2021-04-25 17:52:47,847 [INFO] Training: 2908/6852 -- loss: 2.3472914695739746\n",
      "2021-04-25 17:52:47,895 [INFO] Training: 2909/6852 -- loss: 2.3234825134277344\n",
      "2021-04-25 17:52:47,947 [INFO] Training: 2910/6852 -- loss: 2.509078025817871\n",
      "2021-04-25 17:52:47,997 [INFO] Training: 2911/6852 -- loss: 2.120251417160034\n",
      "2021-04-25 17:52:48,044 [INFO] Training: 2912/6852 -- loss: 2.474918842315674\n",
      "2021-04-25 17:52:48,094 [INFO] Training: 2913/6852 -- loss: 2.145008087158203\n",
      "2021-04-25 17:52:48,144 [INFO] Training: 2914/6852 -- loss: 3.0188705921173096\n",
      "2021-04-25 17:52:48,192 [INFO] Training: 2915/6852 -- loss: 1.7601227760314941\n",
      "2021-04-25 17:52:48,242 [INFO] Training: 2916/6852 -- loss: 2.2007126808166504\n",
      "2021-04-25 17:52:48,290 [INFO] Training: 2917/6852 -- loss: 3.7337398529052734\n",
      "2021-04-25 17:52:48,338 [INFO] Training: 2918/6852 -- loss: 2.740245819091797\n",
      "2021-04-25 17:52:48,387 [INFO] Training: 2919/6852 -- loss: 1.7076654434204102\n",
      "2021-04-25 17:52:48,434 [INFO] Training: 2920/6852 -- loss: 1.6613352298736572\n",
      "2021-04-25 17:52:48,483 [INFO] Training: 2921/6852 -- loss: 3.491337299346924\n",
      "2021-04-25 17:52:48,530 [INFO] Training: 2922/6852 -- loss: 2.0720627307891846\n",
      "2021-04-25 17:52:48,577 [INFO] Training: 2923/6852 -- loss: 1.853672981262207\n",
      "2021-04-25 17:52:48,627 [INFO] Training: 2924/6852 -- loss: 2.386162757873535\n",
      "2021-04-25 17:52:48,678 [INFO] Training: 2925/6852 -- loss: 2.369358539581299\n",
      "2021-04-25 17:52:48,725 [INFO] Training: 2926/6852 -- loss: 2.085768222808838\n",
      "2021-04-25 17:52:48,777 [INFO] Training: 2927/6852 -- loss: 2.2741661071777344\n",
      "2021-04-25 17:52:48,824 [INFO] Training: 2928/6852 -- loss: 3.8026177883148193\n",
      "2021-04-25 17:52:48,875 [INFO] Training: 2929/6852 -- loss: 3.044860601425171\n",
      "2021-04-25 17:52:48,921 [INFO] Training: 2930/6852 -- loss: 2.8652076721191406\n",
      "2021-04-25 17:52:48,969 [INFO] Training: 2931/6852 -- loss: 1.9990322589874268\n",
      "2021-04-25 17:52:49,019 [INFO] Training: 2932/6852 -- loss: 1.8800315856933594\n",
      "2021-04-25 17:52:49,070 [INFO] Training: 2933/6852 -- loss: 2.1773929595947266\n",
      "2021-04-25 17:52:49,123 [INFO] Training: 2934/6852 -- loss: 2.0556135177612305\n",
      "2021-04-25 17:52:49,171 [INFO] Training: 2935/6852 -- loss: 2.1045045852661133\n",
      "2021-04-25 17:52:49,221 [INFO] Training: 2936/6852 -- loss: 1.512861967086792\n",
      "2021-04-25 17:52:49,268 [INFO] Training: 2937/6852 -- loss: 1.8743821382522583\n",
      "2021-04-25 17:52:49,318 [INFO] Training: 2938/6852 -- loss: 2.9462103843688965\n",
      "2021-04-25 17:52:49,367 [INFO] Training: 2939/6852 -- loss: 2.5266363620758057\n",
      "2021-04-25 17:52:49,415 [INFO] Training: 2940/6852 -- loss: 2.3709073066711426\n",
      "2021-04-25 17:52:49,463 [INFO] Training: 2941/6852 -- loss: 2.236931324005127\n",
      "2021-04-25 17:52:49,513 [INFO] Training: 2942/6852 -- loss: 1.9827271699905396\n",
      "2021-04-25 17:52:49,563 [INFO] Training: 2943/6852 -- loss: 4.039949893951416\n",
      "2021-04-25 17:52:49,611 [INFO] Training: 2944/6852 -- loss: 2.8445093631744385\n",
      "2021-04-25 17:52:49,665 [INFO] Training: 2945/6852 -- loss: 2.9789063930511475\n",
      "2021-04-25 17:52:49,713 [INFO] Training: 2946/6852 -- loss: 2.3721911907196045\n",
      "2021-04-25 17:52:49,762 [INFO] Training: 2947/6852 -- loss: 3.281564712524414\n",
      "2021-04-25 17:52:49,809 [INFO] Training: 2948/6852 -- loss: 2.2364635467529297\n",
      "2021-04-25 17:52:49,858 [INFO] Training: 2949/6852 -- loss: 1.8260085582733154\n",
      "2021-04-25 17:52:49,907 [INFO] Training: 2950/6852 -- loss: 3.197146415710449\n",
      "2021-04-25 17:52:49,955 [INFO] Training: 2951/6852 -- loss: 2.6058263778686523\n",
      "2021-04-25 17:52:50,003 [INFO] Training: 2952/6852 -- loss: 2.649649143218994\n",
      "2021-04-25 17:52:50,055 [INFO] Training: 2953/6852 -- loss: 2.644178628921509\n",
      "2021-04-25 17:52:50,107 [INFO] Training: 2954/6852 -- loss: 2.429354190826416\n",
      "2021-04-25 17:52:50,156 [INFO] Training: 2955/6852 -- loss: 2.076219320297241\n",
      "2021-04-25 17:52:50,207 [INFO] Training: 2956/6852 -- loss: 2.550088405609131\n",
      "2021-04-25 17:52:50,257 [INFO] Training: 2957/6852 -- loss: 2.7684130668640137\n",
      "2021-04-25 17:52:50,304 [INFO] Training: 2958/6852 -- loss: 2.653451919555664\n",
      "2021-04-25 17:52:50,354 [INFO] Training: 2959/6852 -- loss: 2.805267810821533\n",
      "2021-04-25 17:52:50,402 [INFO] Training: 2960/6852 -- loss: 2.9476211071014404\n",
      "2021-04-25 17:52:50,456 [INFO] Training: 2961/6852 -- loss: 2.348304033279419\n",
      "2021-04-25 17:52:50,502 [INFO] Training: 2962/6852 -- loss: 1.70447838306427\n",
      "2021-04-25 17:52:50,550 [INFO] Training: 2963/6852 -- loss: 1.9131451845169067\n",
      "2021-04-25 17:52:50,598 [INFO] Training: 2964/6852 -- loss: 1.2676126956939697\n",
      "2021-04-25 17:52:50,645 [INFO] Training: 2965/6852 -- loss: 2.985502243041992\n",
      "2021-04-25 17:52:50,693 [INFO] Training: 2966/6852 -- loss: 2.6962482929229736\n",
      "2021-04-25 17:52:50,745 [INFO] Training: 2967/6852 -- loss: 3.6349093914031982\n",
      "2021-04-25 17:52:50,791 [INFO] Training: 2968/6852 -- loss: 2.60302734375\n",
      "2021-04-25 17:52:50,838 [INFO] Training: 2969/6852 -- loss: 2.5533437728881836\n",
      "2021-04-25 17:52:50,888 [INFO] Training: 2970/6852 -- loss: 2.712186813354492\n",
      "2021-04-25 17:52:50,936 [INFO] Training: 2971/6852 -- loss: 2.09293532371521\n",
      "2021-04-25 17:52:50,988 [INFO] Training: 2972/6852 -- loss: 2.817502737045288\n",
      "2021-04-25 17:52:51,034 [INFO] Training: 2973/6852 -- loss: 1.924647331237793\n",
      "2021-04-25 17:52:51,082 [INFO] Training: 2974/6852 -- loss: 2.9600510597229004\n",
      "2021-04-25 17:52:51,130 [INFO] Training: 2975/6852 -- loss: 2.7096364498138428\n",
      "2021-04-25 17:52:51,178 [INFO] Training: 2976/6852 -- loss: 2.434222459793091\n",
      "2021-04-25 17:52:51,230 [INFO] Training: 2977/6852 -- loss: 1.5720386505126953\n",
      "2021-04-25 17:52:51,279 [INFO] Training: 2978/6852 -- loss: 2.8452515602111816\n",
      "2021-04-25 17:52:51,328 [INFO] Training: 2979/6852 -- loss: 1.6243927478790283\n",
      "2021-04-25 17:52:51,379 [INFO] Training: 2980/6852 -- loss: 1.8322776556015015\n",
      "2021-04-25 17:52:51,429 [INFO] Training: 2981/6852 -- loss: 2.0874948501586914\n",
      "2021-04-25 17:52:51,479 [INFO] Training: 2982/6852 -- loss: 2.5541532039642334\n",
      "2021-04-25 17:52:51,527 [INFO] Training: 2983/6852 -- loss: 2.783761739730835\n",
      "2021-04-25 17:52:51,577 [INFO] Training: 2984/6852 -- loss: 2.7254812717437744\n",
      "2021-04-25 17:52:51,626 [INFO] Training: 2985/6852 -- loss: 2.7931642532348633\n",
      "2021-04-25 17:52:51,675 [INFO] Training: 2986/6852 -- loss: 1.9457498788833618\n",
      "2021-04-25 17:52:51,723 [INFO] Training: 2987/6852 -- loss: 3.015392303466797\n",
      "2021-04-25 17:52:51,772 [INFO] Training: 2988/6852 -- loss: 1.60636305809021\n",
      "2021-04-25 17:52:51,820 [INFO] Training: 2989/6852 -- loss: 3.495098829269409\n",
      "2021-04-25 17:52:51,869 [INFO] Training: 2990/6852 -- loss: 2.449040412902832\n",
      "2021-04-25 17:52:51,923 [INFO] Training: 2991/6852 -- loss: 1.962492823600769\n",
      "2021-04-25 17:52:51,970 [INFO] Training: 2992/6852 -- loss: 1.4582470655441284\n",
      "2021-04-25 17:52:52,019 [INFO] Training: 2993/6852 -- loss: 2.8222036361694336\n",
      "2021-04-25 17:52:52,068 [INFO] Training: 2994/6852 -- loss: 2.442058563232422\n",
      "2021-04-25 17:52:52,117 [INFO] Training: 2995/6852 -- loss: 2.45512318611145\n",
      "2021-04-25 17:52:52,165 [INFO] Training: 2996/6852 -- loss: 1.9540687799453735\n",
      "2021-04-25 17:52:52,213 [INFO] Training: 2997/6852 -- loss: 2.345336437225342\n",
      "2021-04-25 17:52:52,264 [INFO] Training: 2998/6852 -- loss: 1.3543891906738281\n",
      "2021-04-25 17:52:52,312 [INFO] Training: 2999/6852 -- loss: 2.707484483718872\n",
      "2021-04-25 17:52:52,363 [INFO] Training: 3000/6852 -- loss: 2.3050551414489746\n",
      "2021-04-25 17:52:55,224 [INFO] Training: iteration: 3000/6852 -- epoch: 5 --  train_loss: 2.366 -- train_accuracy: 0.25 valid_loss: 3.016 -- valid_accuracy: 0.30\n",
      "2021-04-25 17:52:55,266 [INFO] Training: 3001/6852 -- loss: 2.17570161819458\n",
      "2021-04-25 17:52:55,317 [INFO] Training: 3002/6852 -- loss: 3.09065842628479\n",
      "2021-04-25 17:52:55,369 [INFO] Training: 3003/6852 -- loss: 3.665119171142578\n",
      "2021-04-25 17:52:55,417 [INFO] Training: 3004/6852 -- loss: 2.158745288848877\n",
      "2021-04-25 17:52:55,468 [INFO] Training: 3005/6852 -- loss: 2.068286895751953\n",
      "2021-04-25 17:52:55,517 [INFO] Training: 3006/6852 -- loss: 2.3748838901519775\n",
      "2021-04-25 17:52:55,571 [INFO] Training: 3007/6852 -- loss: 1.7178717851638794\n",
      "2021-04-25 17:52:55,618 [INFO] Training: 3008/6852 -- loss: 1.9311659336090088\n",
      "2021-04-25 17:52:55,665 [INFO] Training: 3009/6852 -- loss: 1.852829098701477\n",
      "2021-04-25 17:52:55,713 [INFO] Training: 3010/6852 -- loss: 2.087224006652832\n",
      "2021-04-25 17:52:55,761 [INFO] Training: 3011/6852 -- loss: 2.4900472164154053\n",
      "2021-04-25 17:52:55,812 [INFO] Training: 3012/6852 -- loss: 2.5358974933624268\n",
      "2021-04-25 17:52:55,860 [INFO] Training: 3013/6852 -- loss: 3.1210005283355713\n",
      "2021-04-25 17:52:55,913 [INFO] Training: 3014/6852 -- loss: 2.1152491569519043\n",
      "2021-04-25 17:52:55,961 [INFO] Training: 3015/6852 -- loss: 1.8789583444595337\n",
      "2021-04-25 17:52:56,008 [INFO] Training: 3016/6852 -- loss: 2.264923095703125\n",
      "2021-04-25 17:52:56,057 [INFO] Training: 3017/6852 -- loss: 3.5231950283050537\n",
      "2021-04-25 17:52:56,105 [INFO] Training: 3018/6852 -- loss: 3.9758880138397217\n",
      "2021-04-25 17:52:56,153 [INFO] Training: 3019/6852 -- loss: 3.0435009002685547\n",
      "2021-04-25 17:52:56,204 [INFO] Training: 3020/6852 -- loss: 1.7768241167068481\n",
      "2021-04-25 17:52:56,252 [INFO] Training: 3021/6852 -- loss: 2.7941808700561523\n",
      "2021-04-25 17:52:56,301 [INFO] Training: 3022/6852 -- loss: 2.8003852367401123\n",
      "2021-04-25 17:52:56,348 [INFO] Training: 3023/6852 -- loss: 3.907526731491089\n",
      "2021-04-25 17:52:56,399 [INFO] Training: 3024/6852 -- loss: 2.901841163635254\n",
      "2021-04-25 17:52:56,449 [INFO] Training: 3025/6852 -- loss: 2.4125590324401855\n",
      "2021-04-25 17:52:56,497 [INFO] Training: 3026/6852 -- loss: 3.082603931427002\n",
      "2021-04-25 17:52:56,545 [INFO] Training: 3027/6852 -- loss: 2.3759241104125977\n",
      "2021-04-25 17:52:56,592 [INFO] Training: 3028/6852 -- loss: 1.6242715120315552\n",
      "2021-04-25 17:52:56,639 [INFO] Training: 3029/6852 -- loss: 3.4892492294311523\n",
      "2021-04-25 17:52:56,687 [INFO] Training: 3030/6852 -- loss: 1.7495043277740479\n",
      "2021-04-25 17:52:56,739 [INFO] Training: 3031/6852 -- loss: 2.405503511428833\n",
      "2021-04-25 17:52:56,790 [INFO] Training: 3032/6852 -- loss: 1.9260375499725342\n",
      "2021-04-25 17:52:56,841 [INFO] Training: 3033/6852 -- loss: 1.5304608345031738\n",
      "2021-04-25 17:52:56,892 [INFO] Training: 3034/6852 -- loss: 1.6652573347091675\n",
      "2021-04-25 17:52:56,943 [INFO] Training: 3035/6852 -- loss: 2.571376085281372\n",
      "2021-04-25 17:52:56,993 [INFO] Training: 3036/6852 -- loss: 2.209620952606201\n",
      "2021-04-25 17:52:57,043 [INFO] Training: 3037/6852 -- loss: 3.5163259506225586\n",
      "2021-04-25 17:52:57,093 [INFO] Training: 3038/6852 -- loss: 2.6965277194976807\n",
      "2021-04-25 17:52:57,146 [INFO] Training: 3039/6852 -- loss: 2.1942501068115234\n",
      "2021-04-25 17:52:57,196 [INFO] Training: 3040/6852 -- loss: 2.1685917377471924\n",
      "2021-04-25 17:52:57,250 [INFO] Training: 3041/6852 -- loss: 2.2256269454956055\n",
      "2021-04-25 17:52:57,300 [INFO] Training: 3042/6852 -- loss: 1.7041269540786743\n",
      "2021-04-25 17:52:57,347 [INFO] Training: 3043/6852 -- loss: 2.418640613555908\n",
      "2021-04-25 17:52:57,395 [INFO] Training: 3044/6852 -- loss: 3.1317508220672607\n",
      "2021-04-25 17:52:57,444 [INFO] Training: 3045/6852 -- loss: 3.3784313201904297\n",
      "2021-04-25 17:52:57,493 [INFO] Training: 3046/6852 -- loss: 2.1476399898529053\n",
      "2021-04-25 17:52:57,544 [INFO] Training: 3047/6852 -- loss: 1.5467146635055542\n",
      "2021-04-25 17:52:57,593 [INFO] Training: 3048/6852 -- loss: 2.3398020267486572\n",
      "2021-04-25 17:52:57,644 [INFO] Training: 3049/6852 -- loss: 2.7928779125213623\n",
      "2021-04-25 17:52:57,696 [INFO] Training: 3050/6852 -- loss: 3.0777971744537354\n",
      "2021-04-25 17:52:57,747 [INFO] Training: 3051/6852 -- loss: 2.7412259578704834\n",
      "2021-04-25 17:52:57,797 [INFO] Training: 3052/6852 -- loss: 2.823521614074707\n",
      "2021-04-25 17:52:57,846 [INFO] Training: 3053/6852 -- loss: 1.5591992139816284\n",
      "2021-04-25 17:52:57,895 [INFO] Training: 3054/6852 -- loss: 1.9072202444076538\n",
      "2021-04-25 17:52:57,942 [INFO] Training: 3055/6852 -- loss: 1.9565736055374146\n",
      "2021-04-25 17:52:57,992 [INFO] Training: 3056/6852 -- loss: 3.2813539505004883\n",
      "2021-04-25 17:52:58,043 [INFO] Training: 3057/6852 -- loss: 2.6849026679992676\n",
      "2021-04-25 17:52:58,093 [INFO] Training: 3058/6852 -- loss: 3.2372024059295654\n",
      "2021-04-25 17:52:58,142 [INFO] Training: 3059/6852 -- loss: 3.5371994972229004\n",
      "2021-04-25 17:52:58,192 [INFO] Training: 3060/6852 -- loss: 2.951585292816162\n",
      "2021-04-25 17:52:58,242 [INFO] Training: 3061/6852 -- loss: 2.7178103923797607\n",
      "2021-04-25 17:52:58,293 [INFO] Training: 3062/6852 -- loss: 3.2456462383270264\n",
      "2021-04-25 17:52:58,349 [INFO] Training: 3063/6852 -- loss: 1.9548338651657104\n",
      "2021-04-25 17:52:58,397 [INFO] Training: 3064/6852 -- loss: 1.8158899545669556\n",
      "2021-04-25 17:52:58,444 [INFO] Training: 3065/6852 -- loss: 2.3748512268066406\n",
      "2021-04-25 17:52:58,493 [INFO] Training: 3066/6852 -- loss: 2.7525041103363037\n",
      "2021-04-25 17:52:58,541 [INFO] Training: 3067/6852 -- loss: 3.127992630004883\n",
      "2021-04-25 17:52:58,592 [INFO] Training: 3068/6852 -- loss: 2.8035826683044434\n",
      "2021-04-25 17:52:58,641 [INFO] Training: 3069/6852 -- loss: 2.6687889099121094\n",
      "2021-04-25 17:52:58,692 [INFO] Training: 3070/6852 -- loss: 2.7323830127716064\n",
      "2021-04-25 17:52:58,742 [INFO] Training: 3071/6852 -- loss: 2.1511294841766357\n",
      "2021-04-25 17:52:58,789 [INFO] Training: 3072/6852 -- loss: 2.4233033657073975\n",
      "2021-04-25 17:52:58,837 [INFO] Training: 3073/6852 -- loss: 3.0576953887939453\n",
      "2021-04-25 17:52:58,887 [INFO] Training: 3074/6852 -- loss: 2.259671926498413\n",
      "2021-04-25 17:52:58,935 [INFO] Training: 3075/6852 -- loss: 2.1491243839263916\n",
      "2021-04-25 17:52:58,985 [INFO] Training: 3076/6852 -- loss: 1.7364366054534912\n",
      "2021-04-25 17:52:59,037 [INFO] Training: 3077/6852 -- loss: 2.054506778717041\n",
      "2021-04-25 17:52:59,090 [INFO] Training: 3078/6852 -- loss: 1.5390217304229736\n",
      "2021-04-25 17:52:59,139 [INFO] Training: 3079/6852 -- loss: 2.848137617111206\n",
      "2021-04-25 17:52:59,189 [INFO] Training: 3080/6852 -- loss: 2.8672778606414795\n",
      "2021-04-25 17:52:59,239 [INFO] Training: 3081/6852 -- loss: 1.5437068939208984\n",
      "2021-04-25 17:52:59,287 [INFO] Training: 3082/6852 -- loss: 2.589967727661133\n",
      "2021-04-25 17:52:59,335 [INFO] Training: 3083/6852 -- loss: 3.2837862968444824\n",
      "2021-04-25 17:52:59,382 [INFO] Training: 3084/6852 -- loss: 3.1149773597717285\n",
      "2021-04-25 17:52:59,431 [INFO] Training: 3085/6852 -- loss: 2.216752767562866\n",
      "2021-04-25 17:52:59,482 [INFO] Training: 3086/6852 -- loss: 2.771524667739868\n",
      "2021-04-25 17:52:59,529 [INFO] Training: 3087/6852 -- loss: 2.6857423782348633\n",
      "2021-04-25 17:52:59,581 [INFO] Training: 3088/6852 -- loss: 2.8129780292510986\n",
      "2021-04-25 17:52:59,634 [INFO] Training: 3089/6852 -- loss: 3.1044273376464844\n",
      "2021-04-25 17:52:59,681 [INFO] Training: 3090/6852 -- loss: 2.0613861083984375\n",
      "2021-04-25 17:52:59,727 [INFO] Training: 3091/6852 -- loss: 2.544787645339966\n",
      "2021-04-25 17:52:59,776 [INFO] Training: 3092/6852 -- loss: 2.5157275199890137\n",
      "2021-04-25 17:52:59,826 [INFO] Training: 3093/6852 -- loss: 3.5249075889587402\n",
      "2021-04-25 17:52:59,879 [INFO] Training: 3094/6852 -- loss: 2.7782299518585205\n",
      "2021-04-25 17:52:59,927 [INFO] Training: 3095/6852 -- loss: 3.627762794494629\n",
      "2021-04-25 17:52:59,975 [INFO] Training: 3096/6852 -- loss: 1.819074034690857\n",
      "2021-04-25 17:53:00,024 [INFO] Training: 3097/6852 -- loss: 1.1176011562347412\n",
      "2021-04-25 17:53:00,071 [INFO] Training: 3098/6852 -- loss: 2.407780408859253\n",
      "2021-04-25 17:53:00,120 [INFO] Training: 3099/6852 -- loss: 1.7850383520126343\n",
      "2021-04-25 17:53:00,169 [INFO] Training: 3100/6852 -- loss: 2.813920497894287\n",
      "2021-04-25 17:53:00,219 [INFO] Training: 3101/6852 -- loss: 2.009589672088623\n",
      "2021-04-25 17:53:00,268 [INFO] Training: 3102/6852 -- loss: 2.3632545471191406\n",
      "2021-04-25 17:53:00,316 [INFO] Training: 3103/6852 -- loss: 1.8292534351348877\n",
      "2021-04-25 17:53:00,365 [INFO] Training: 3104/6852 -- loss: 2.3930633068084717\n",
      "2021-04-25 17:53:00,414 [INFO] Training: 3105/6852 -- loss: 2.2354156970977783\n",
      "2021-04-25 17:53:00,461 [INFO] Training: 3106/6852 -- loss: 1.6512274742126465\n",
      "2021-04-25 17:53:00,510 [INFO] Training: 3107/6852 -- loss: 2.8189759254455566\n",
      "2021-04-25 17:53:00,560 [INFO] Training: 3108/6852 -- loss: 2.7097463607788086\n",
      "2021-04-25 17:53:00,611 [INFO] Training: 3109/6852 -- loss: 2.7687246799468994\n",
      "2021-04-25 17:53:00,659 [INFO] Training: 3110/6852 -- loss: 3.330737829208374\n",
      "2021-04-25 17:53:00,710 [INFO] Training: 3111/6852 -- loss: 2.348832607269287\n",
      "2021-04-25 17:53:00,762 [INFO] Training: 3112/6852 -- loss: 1.8194923400878906\n",
      "2021-04-25 17:53:00,808 [INFO] Training: 3113/6852 -- loss: 2.3511931896209717\n",
      "2021-04-25 17:53:00,858 [INFO] Training: 3114/6852 -- loss: 3.003710985183716\n",
      "2021-04-25 17:53:00,911 [INFO] Training: 3115/6852 -- loss: 2.2715749740600586\n",
      "2021-04-25 17:53:00,961 [INFO] Training: 3116/6852 -- loss: 2.3186168670654297\n",
      "2021-04-25 17:53:01,008 [INFO] Training: 3117/6852 -- loss: 3.251613140106201\n",
      "2021-04-25 17:53:01,059 [INFO] Training: 3118/6852 -- loss: 3.2353010177612305\n",
      "2021-04-25 17:53:01,108 [INFO] Training: 3119/6852 -- loss: 2.064591884613037\n",
      "2021-04-25 17:53:01,157 [INFO] Training: 3120/6852 -- loss: 3.421776294708252\n",
      "2021-04-25 17:53:01,206 [INFO] Training: 3121/6852 -- loss: 1.3154146671295166\n",
      "2021-04-25 17:53:01,255 [INFO] Training: 3122/6852 -- loss: 1.9407483339309692\n",
      "2021-04-25 17:53:01,305 [INFO] Training: 3123/6852 -- loss: 3.104175329208374\n",
      "2021-04-25 17:53:01,353 [INFO] Training: 3124/6852 -- loss: 2.455958127975464\n",
      "2021-04-25 17:53:01,403 [INFO] Training: 3125/6852 -- loss: 2.6284656524658203\n",
      "2021-04-25 17:53:01,452 [INFO] Training: 3126/6852 -- loss: 1.7449480295181274\n",
      "2021-04-25 17:53:01,499 [INFO] Training: 3127/6852 -- loss: 1.9329643249511719\n",
      "2021-04-25 17:53:01,548 [INFO] Training: 3128/6852 -- loss: 2.2624711990356445\n",
      "2021-04-25 17:53:01,598 [INFO] Training: 3129/6852 -- loss: 2.4457788467407227\n",
      "2021-04-25 17:53:01,654 [INFO] Training: 3130/6852 -- loss: 2.487410068511963\n",
      "2021-04-25 17:53:01,702 [INFO] Training: 3131/6852 -- loss: 2.6337521076202393\n",
      "2021-04-25 17:53:01,756 [INFO] Training: 3132/6852 -- loss: 2.144970417022705\n",
      "2021-04-25 17:53:01,804 [INFO] Training: 3133/6852 -- loss: 2.226724147796631\n",
      "2021-04-25 17:53:01,854 [INFO] Training: 3134/6852 -- loss: 2.192599058151245\n",
      "2021-04-25 17:53:01,907 [INFO] Training: 3135/6852 -- loss: 2.684509038925171\n",
      "2021-04-25 17:53:01,956 [INFO] Training: 3136/6852 -- loss: 2.568324327468872\n",
      "2021-04-25 17:53:02,002 [INFO] Training: 3137/6852 -- loss: 2.3933894634246826\n",
      "2021-04-25 17:53:02,051 [INFO] Training: 3138/6852 -- loss: 2.7755024433135986\n",
      "2021-04-25 17:53:02,102 [INFO] Training: 3139/6852 -- loss: 2.0842249393463135\n",
      "2021-04-25 17:53:02,152 [INFO] Training: 3140/6852 -- loss: 2.1870970726013184\n",
      "2021-04-25 17:53:02,199 [INFO] Training: 3141/6852 -- loss: 2.2021799087524414\n",
      "2021-04-25 17:53:02,248 [INFO] Training: 3142/6852 -- loss: 2.59328031539917\n",
      "2021-04-25 17:53:02,301 [INFO] Training: 3143/6852 -- loss: 2.907820463180542\n",
      "2021-04-25 17:53:02,347 [INFO] Training: 3144/6852 -- loss: 2.1444315910339355\n",
      "2021-04-25 17:53:02,405 [INFO] Training: 3145/6852 -- loss: 2.8931329250335693\n",
      "2021-04-25 17:53:02,452 [INFO] Training: 3146/6852 -- loss: 1.8735706806182861\n",
      "2021-04-25 17:53:02,501 [INFO] Training: 3147/6852 -- loss: 3.6022379398345947\n",
      "2021-04-25 17:53:02,548 [INFO] Training: 3148/6852 -- loss: 2.2576510906219482\n",
      "2021-04-25 17:53:02,596 [INFO] Training: 3149/6852 -- loss: 1.4332376718521118\n",
      "2021-04-25 17:53:02,644 [INFO] Training: 3150/6852 -- loss: 1.4516879320144653\n",
      "2021-04-25 17:53:05,487 [INFO] Training: iteration: 3150/6852 -- epoch: 5 --  train_loss: 2.477 -- train_accuracy: 0.75 valid_loss: 3.056 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:53:05,531 [INFO] Training: 3151/6852 -- loss: 2.9182021617889404\n",
      "2021-04-25 17:53:05,577 [INFO] Training: 3152/6852 -- loss: 2.362278938293457\n",
      "2021-04-25 17:53:05,627 [INFO] Training: 3153/6852 -- loss: 1.6722712516784668\n",
      "2021-04-25 17:53:05,679 [INFO] Training: 3154/6852 -- loss: 3.0221166610717773\n",
      "2021-04-25 17:53:05,726 [INFO] Training: 3155/6852 -- loss: 3.5039069652557373\n",
      "2021-04-25 17:53:05,775 [INFO] Training: 3156/6852 -- loss: 2.294062614440918\n",
      "2021-04-25 17:53:05,821 [INFO] Training: 3157/6852 -- loss: 3.0301780700683594\n",
      "2021-04-25 17:53:05,871 [INFO] Training: 3158/6852 -- loss: 2.1720614433288574\n",
      "2021-04-25 17:53:05,924 [INFO] Training: 3159/6852 -- loss: 2.8354413509368896\n",
      "2021-04-25 17:53:05,975 [INFO] Training: 3160/6852 -- loss: 2.400486707687378\n",
      "2021-04-25 17:53:06,024 [INFO] Training: 3161/6852 -- loss: 2.6049516201019287\n",
      "2021-04-25 17:53:06,076 [INFO] Training: 3162/6852 -- loss: 3.4946978092193604\n",
      "2021-04-25 17:53:06,123 [INFO] Training: 3163/6852 -- loss: 2.4330928325653076\n",
      "2021-04-25 17:53:06,171 [INFO] Training: 3164/6852 -- loss: 2.0857255458831787\n",
      "2021-04-25 17:53:06,219 [INFO] Training: 3165/6852 -- loss: 1.8570668697357178\n",
      "2021-04-25 17:53:06,267 [INFO] Training: 3166/6852 -- loss: 2.432767629623413\n",
      "2021-04-25 17:53:06,316 [INFO] Training: 3167/6852 -- loss: 2.4479711055755615\n",
      "2021-04-25 17:53:06,366 [INFO] Training: 3168/6852 -- loss: 2.5164434909820557\n",
      "2021-04-25 17:53:06,413 [INFO] Training: 3169/6852 -- loss: 2.663799285888672\n",
      "2021-04-25 17:53:06,465 [INFO] Training: 3170/6852 -- loss: 2.433846950531006\n",
      "2021-04-25 17:53:06,513 [INFO] Training: 3171/6852 -- loss: 2.2708444595336914\n",
      "2021-04-25 17:53:06,564 [INFO] Training: 3172/6852 -- loss: 2.5629420280456543\n",
      "2021-04-25 17:53:06,610 [INFO] Training: 3173/6852 -- loss: 2.1726317405700684\n",
      "2021-04-25 17:53:06,658 [INFO] Training: 3174/6852 -- loss: 2.7217648029327393\n",
      "2021-04-25 17:53:06,709 [INFO] Training: 3175/6852 -- loss: 1.8510174751281738\n",
      "2021-04-25 17:53:06,757 [INFO] Training: 3176/6852 -- loss: 2.379746913909912\n",
      "2021-04-25 17:53:06,806 [INFO] Training: 3177/6852 -- loss: 2.2077109813690186\n",
      "2021-04-25 17:53:06,854 [INFO] Training: 3178/6852 -- loss: 3.9808247089385986\n",
      "2021-04-25 17:53:06,904 [INFO] Training: 3179/6852 -- loss: 4.092111110687256\n",
      "2021-04-25 17:53:06,956 [INFO] Training: 3180/6852 -- loss: 2.780181407928467\n",
      "2021-04-25 17:53:07,010 [INFO] Training: 3181/6852 -- loss: 1.9898713827133179\n",
      "2021-04-25 17:53:07,064 [INFO] Training: 3182/6852 -- loss: 3.064100503921509\n",
      "2021-04-25 17:53:07,116 [INFO] Training: 3183/6852 -- loss: 1.8856823444366455\n",
      "2021-04-25 17:53:07,164 [INFO] Training: 3184/6852 -- loss: 2.3443684577941895\n",
      "2021-04-25 17:53:07,215 [INFO] Training: 3185/6852 -- loss: 3.1652050018310547\n",
      "2021-04-25 17:53:07,262 [INFO] Training: 3186/6852 -- loss: 3.1017773151397705\n",
      "2021-04-25 17:53:07,313 [INFO] Training: 3187/6852 -- loss: 3.2771897315979004\n",
      "2021-04-25 17:53:07,362 [INFO] Training: 3188/6852 -- loss: 1.8856031894683838\n",
      "2021-04-25 17:53:07,411 [INFO] Training: 3189/6852 -- loss: 2.3069536685943604\n",
      "2021-04-25 17:53:07,459 [INFO] Training: 3190/6852 -- loss: 1.8079501390457153\n",
      "2021-04-25 17:53:07,507 [INFO] Training: 3191/6852 -- loss: 3.5412678718566895\n",
      "2021-04-25 17:53:07,554 [INFO] Training: 3192/6852 -- loss: 2.870480537414551\n",
      "2021-04-25 17:53:07,606 [INFO] Training: 3193/6852 -- loss: 3.0341739654541016\n",
      "2021-04-25 17:53:07,653 [INFO] Training: 3194/6852 -- loss: 4.414028644561768\n",
      "2021-04-25 17:53:07,705 [INFO] Training: 3195/6852 -- loss: 2.76888108253479\n",
      "2021-04-25 17:53:07,752 [INFO] Training: 3196/6852 -- loss: 2.239321231842041\n",
      "2021-04-25 17:53:07,804 [INFO] Training: 3197/6852 -- loss: 2.9022085666656494\n",
      "2021-04-25 17:53:07,852 [INFO] Training: 3198/6852 -- loss: 2.047236442565918\n",
      "2021-04-25 17:53:07,904 [INFO] Training: 3199/6852 -- loss: 2.488462209701538\n",
      "2021-04-25 17:53:07,953 [INFO] Training: 3200/6852 -- loss: 2.01340651512146\n",
      "2021-04-25 17:53:08,002 [INFO] Training: 3201/6852 -- loss: 1.9360307455062866\n",
      "2021-04-25 17:53:08,051 [INFO] Training: 3202/6852 -- loss: 3.0643348693847656\n",
      "2021-04-25 17:53:08,099 [INFO] Training: 3203/6852 -- loss: 1.6886082887649536\n",
      "2021-04-25 17:53:08,151 [INFO] Training: 3204/6852 -- loss: 2.9397172927856445\n",
      "2021-04-25 17:53:08,198 [INFO] Training: 3205/6852 -- loss: 2.6145105361938477\n",
      "2021-04-25 17:53:08,248 [INFO] Training: 3206/6852 -- loss: 2.733360528945923\n",
      "2021-04-25 17:53:08,299 [INFO] Training: 3207/6852 -- loss: 1.7831441164016724\n",
      "2021-04-25 17:53:08,350 [INFO] Training: 3208/6852 -- loss: 2.780094623565674\n",
      "2021-04-25 17:53:08,402 [INFO] Training: 3209/6852 -- loss: 2.9455204010009766\n",
      "2021-04-25 17:53:08,452 [INFO] Training: 3210/6852 -- loss: 1.938950538635254\n",
      "2021-04-25 17:53:08,501 [INFO] Training: 3211/6852 -- loss: 1.6974520683288574\n",
      "2021-04-25 17:53:08,551 [INFO] Training: 3212/6852 -- loss: 3.1622986793518066\n",
      "2021-04-25 17:53:08,600 [INFO] Training: 3213/6852 -- loss: 2.846187114715576\n",
      "2021-04-25 17:53:08,647 [INFO] Training: 3214/6852 -- loss: 2.058039903640747\n",
      "2021-04-25 17:53:08,697 [INFO] Training: 3215/6852 -- loss: 3.0991666316986084\n",
      "2021-04-25 17:53:08,752 [INFO] Training: 3216/6852 -- loss: 2.451087713241577\n",
      "2021-04-25 17:53:08,802 [INFO] Training: 3217/6852 -- loss: 3.000047206878662\n",
      "2021-04-25 17:53:08,852 [INFO] Training: 3218/6852 -- loss: 1.7037615776062012\n",
      "2021-04-25 17:53:08,902 [INFO] Training: 3219/6852 -- loss: 2.646627426147461\n",
      "2021-04-25 17:53:08,952 [INFO] Training: 3220/6852 -- loss: 1.476269006729126\n",
      "2021-04-25 17:53:09,002 [INFO] Training: 3221/6852 -- loss: 2.809321880340576\n",
      "2021-04-25 17:53:09,048 [INFO] Training: 3222/6852 -- loss: 3.563302755355835\n",
      "2021-04-25 17:53:09,097 [INFO] Training: 3223/6852 -- loss: 2.463107109069824\n",
      "2021-04-25 17:53:09,151 [INFO] Training: 3224/6852 -- loss: 2.084141969680786\n",
      "2021-04-25 17:53:09,200 [INFO] Training: 3225/6852 -- loss: 1.9741660356521606\n",
      "2021-04-25 17:53:09,252 [INFO] Training: 3226/6852 -- loss: 3.3173489570617676\n",
      "2021-04-25 17:53:09,302 [INFO] Training: 3227/6852 -- loss: 2.4855716228485107\n",
      "2021-04-25 17:53:09,353 [INFO] Training: 3228/6852 -- loss: 2.649186611175537\n",
      "2021-04-25 17:53:09,403 [INFO] Training: 3229/6852 -- loss: 1.9507925510406494\n",
      "2021-04-25 17:53:09,453 [INFO] Training: 3230/6852 -- loss: 1.7612595558166504\n",
      "2021-04-25 17:53:09,504 [INFO] Training: 3231/6852 -- loss: 3.337634563446045\n",
      "2021-04-25 17:53:09,555 [INFO] Training: 3232/6852 -- loss: 2.8460423946380615\n",
      "2021-04-25 17:53:09,601 [INFO] Training: 3233/6852 -- loss: 4.214052200317383\n",
      "2021-04-25 17:53:09,651 [INFO] Training: 3234/6852 -- loss: 2.349855661392212\n",
      "2021-04-25 17:53:09,698 [INFO] Training: 3235/6852 -- loss: 2.0061779022216797\n",
      "2021-04-25 17:53:09,745 [INFO] Training: 3236/6852 -- loss: 1.9110811948776245\n",
      "2021-04-25 17:53:09,800 [INFO] Training: 3237/6852 -- loss: 2.6120457649230957\n",
      "2021-04-25 17:53:09,852 [INFO] Training: 3238/6852 -- loss: 2.1230363845825195\n",
      "2021-04-25 17:53:09,905 [INFO] Training: 3239/6852 -- loss: 2.2525131702423096\n",
      "2021-04-25 17:53:09,955 [INFO] Training: 3240/6852 -- loss: 2.9580535888671875\n",
      "2021-04-25 17:53:10,002 [INFO] Training: 3241/6852 -- loss: 2.500633716583252\n",
      "2021-04-25 17:53:10,049 [INFO] Training: 3242/6852 -- loss: 2.681372880935669\n",
      "2021-04-25 17:53:10,100 [INFO] Training: 3243/6852 -- loss: 3.836317539215088\n",
      "2021-04-25 17:53:10,147 [INFO] Training: 3244/6852 -- loss: 2.3451991081237793\n",
      "2021-04-25 17:53:10,196 [INFO] Training: 3245/6852 -- loss: 2.8277626037597656\n",
      "2021-04-25 17:53:10,243 [INFO] Training: 3246/6852 -- loss: 2.3883559703826904\n",
      "2021-04-25 17:53:10,290 [INFO] Training: 3247/6852 -- loss: 2.5397441387176514\n",
      "2021-04-25 17:53:10,338 [INFO] Training: 3248/6852 -- loss: 2.0494112968444824\n",
      "2021-04-25 17:53:10,386 [INFO] Training: 3249/6852 -- loss: 2.3429794311523438\n",
      "2021-04-25 17:53:10,432 [INFO] Training: 3250/6852 -- loss: 1.9174624681472778\n",
      "2021-04-25 17:53:10,482 [INFO] Training: 3251/6852 -- loss: 2.0203213691711426\n",
      "2021-04-25 17:53:10,530 [INFO] Training: 3252/6852 -- loss: 2.6523451805114746\n",
      "2021-04-25 17:53:10,577 [INFO] Training: 3253/6852 -- loss: 2.651082754135132\n",
      "2021-04-25 17:53:10,627 [INFO] Training: 3254/6852 -- loss: 2.0339198112487793\n",
      "2021-04-25 17:53:10,675 [INFO] Training: 3255/6852 -- loss: 2.4536690711975098\n",
      "2021-04-25 17:53:10,724 [INFO] Training: 3256/6852 -- loss: 2.688270092010498\n",
      "2021-04-25 17:53:10,773 [INFO] Training: 3257/6852 -- loss: 1.9730223417282104\n",
      "2021-04-25 17:53:10,822 [INFO] Training: 3258/6852 -- loss: 2.512576103210449\n",
      "2021-04-25 17:53:10,872 [INFO] Training: 3259/6852 -- loss: 3.424285888671875\n",
      "2021-04-25 17:53:10,919 [INFO] Training: 3260/6852 -- loss: 2.3529295921325684\n",
      "2021-04-25 17:53:10,968 [INFO] Training: 3261/6852 -- loss: 3.1255269050598145\n",
      "2021-04-25 17:53:11,020 [INFO] Training: 3262/6852 -- loss: 2.4954705238342285\n",
      "2021-04-25 17:53:11,071 [INFO] Training: 3263/6852 -- loss: 3.379344940185547\n",
      "2021-04-25 17:53:11,122 [INFO] Training: 3264/6852 -- loss: 2.664846658706665\n",
      "2021-04-25 17:53:11,173 [INFO] Training: 3265/6852 -- loss: 2.739762306213379\n",
      "2021-04-25 17:53:11,223 [INFO] Training: 3266/6852 -- loss: 3.2078092098236084\n",
      "2021-04-25 17:53:11,273 [INFO] Training: 3267/6852 -- loss: 2.1215662956237793\n",
      "2021-04-25 17:53:11,322 [INFO] Training: 3268/6852 -- loss: 3.646540641784668\n",
      "2021-04-25 17:53:11,372 [INFO] Training: 3269/6852 -- loss: 1.9151126146316528\n",
      "2021-04-25 17:53:11,425 [INFO] Training: 3270/6852 -- loss: 1.8607419729232788\n",
      "2021-04-25 17:53:11,472 [INFO] Training: 3271/6852 -- loss: 3.0108087062835693\n",
      "2021-04-25 17:53:11,522 [INFO] Training: 3272/6852 -- loss: 1.5567593574523926\n",
      "2021-04-25 17:53:11,569 [INFO] Training: 3273/6852 -- loss: 3.660691022872925\n",
      "2021-04-25 17:53:11,619 [INFO] Training: 3274/6852 -- loss: 2.7869091033935547\n",
      "2021-04-25 17:53:11,667 [INFO] Training: 3275/6852 -- loss: 1.6738274097442627\n",
      "2021-04-25 17:53:11,716 [INFO] Training: 3276/6852 -- loss: 2.5708701610565186\n",
      "2021-04-25 17:53:11,771 [INFO] Training: 3277/6852 -- loss: 2.4076199531555176\n",
      "2021-04-25 17:53:11,818 [INFO] Training: 3278/6852 -- loss: 2.9500958919525146\n",
      "2021-04-25 17:53:11,868 [INFO] Training: 3279/6852 -- loss: 2.4222774505615234\n",
      "2021-04-25 17:53:11,914 [INFO] Training: 3280/6852 -- loss: 3.28397274017334\n",
      "2021-04-25 17:53:11,963 [INFO] Training: 3281/6852 -- loss: 2.4150266647338867\n",
      "2021-04-25 17:53:12,012 [INFO] Training: 3282/6852 -- loss: 2.0299015045166016\n",
      "2021-04-25 17:53:12,065 [INFO] Training: 3283/6852 -- loss: 3.4123682975769043\n",
      "2021-04-25 17:53:12,118 [INFO] Training: 3284/6852 -- loss: 1.9666357040405273\n",
      "2021-04-25 17:53:12,168 [INFO] Training: 3285/6852 -- loss: 2.5186939239501953\n",
      "2021-04-25 17:53:12,218 [INFO] Training: 3286/6852 -- loss: 2.4650800228118896\n",
      "2021-04-25 17:53:12,265 [INFO] Training: 3287/6852 -- loss: 1.0582994222640991\n",
      "2021-04-25 17:53:12,315 [INFO] Training: 3288/6852 -- loss: 1.983246088027954\n",
      "2021-04-25 17:53:12,363 [INFO] Training: 3289/6852 -- loss: 2.5208635330200195\n",
      "2021-04-25 17:53:12,415 [INFO] Training: 3290/6852 -- loss: 1.4275598526000977\n",
      "2021-04-25 17:53:12,463 [INFO] Training: 3291/6852 -- loss: 2.2681829929351807\n",
      "2021-04-25 17:53:12,512 [INFO] Training: 3292/6852 -- loss: 2.3472344875335693\n",
      "2021-04-25 17:53:12,559 [INFO] Training: 3293/6852 -- loss: 1.7910709381103516\n",
      "2021-04-25 17:53:12,607 [INFO] Training: 3294/6852 -- loss: 1.5162235498428345\n",
      "2021-04-25 17:53:12,657 [INFO] Training: 3295/6852 -- loss: 2.3992648124694824\n",
      "2021-04-25 17:53:12,706 [INFO] Training: 3296/6852 -- loss: 1.152958869934082\n",
      "2021-04-25 17:53:12,759 [INFO] Training: 3297/6852 -- loss: 2.0558674335479736\n",
      "2021-04-25 17:53:12,807 [INFO] Training: 3298/6852 -- loss: 2.1664369106292725\n",
      "2021-04-25 17:53:12,857 [INFO] Training: 3299/6852 -- loss: 1.491546630859375\n",
      "2021-04-25 17:53:12,906 [INFO] Training: 3300/6852 -- loss: 2.1788930892944336\n",
      "2021-04-25 17:53:15,788 [INFO] Training: iteration: 3300/6852 -- epoch: 5 --  train_loss: 2.509 -- train_accuracy: 0.12 valid_loss: 3.046 -- valid_accuracy: 0.31\n",
      "2021-04-25 17:53:15,826 [INFO] Training: 3301/6852 -- loss: 3.3679075241088867\n",
      "2021-04-25 17:53:15,876 [INFO] Training: 3302/6852 -- loss: 3.087230920791626\n",
      "2021-04-25 17:53:15,926 [INFO] Training: 3303/6852 -- loss: 2.4895505905151367\n",
      "2021-04-25 17:53:15,975 [INFO] Training: 3304/6852 -- loss: 3.757727861404419\n",
      "2021-04-25 17:53:16,023 [INFO] Training: 3305/6852 -- loss: 2.3163416385650635\n",
      "2021-04-25 17:53:16,073 [INFO] Training: 3306/6852 -- loss: 1.4690260887145996\n",
      "2021-04-25 17:53:16,120 [INFO] Training: 3307/6852 -- loss: 2.7571682929992676\n",
      "2021-04-25 17:53:16,171 [INFO] Training: 3308/6852 -- loss: 2.6373629570007324\n",
      "2021-04-25 17:53:16,220 [INFO] Training: 3309/6852 -- loss: 2.5477895736694336\n",
      "2021-04-25 17:53:16,272 [INFO] Training: 3310/6852 -- loss: 2.5946433544158936\n",
      "2021-04-25 17:53:16,319 [INFO] Training: 3311/6852 -- loss: 2.307039976119995\n",
      "2021-04-25 17:53:16,370 [INFO] Training: 3312/6852 -- loss: 2.4827988147735596\n",
      "2021-04-25 17:53:16,422 [INFO] Training: 3313/6852 -- loss: 1.5869057178497314\n",
      "2021-04-25 17:53:16,472 [INFO] Training: 3314/6852 -- loss: 2.234565019607544\n",
      "2021-04-25 17:53:16,522 [INFO] Training: 3315/6852 -- loss: 2.167363166809082\n",
      "2021-04-25 17:53:16,571 [INFO] Training: 3316/6852 -- loss: 2.074232578277588\n",
      "2021-04-25 17:53:16,621 [INFO] Training: 3317/6852 -- loss: 1.9928075075149536\n",
      "2021-04-25 17:53:16,673 [INFO] Training: 3318/6852 -- loss: 2.391902208328247\n",
      "2021-04-25 17:53:16,725 [INFO] Training: 3319/6852 -- loss: 2.7676382064819336\n",
      "2021-04-25 17:53:16,774 [INFO] Training: 3320/6852 -- loss: 2.163980484008789\n",
      "2021-04-25 17:53:16,827 [INFO] Training: 3321/6852 -- loss: 2.4245171546936035\n",
      "2021-04-25 17:53:16,874 [INFO] Training: 3322/6852 -- loss: 3.65303373336792\n",
      "2021-04-25 17:53:16,924 [INFO] Training: 3323/6852 -- loss: 2.907320022583008\n",
      "2021-04-25 17:53:16,978 [INFO] Training: 3324/6852 -- loss: 2.0164713859558105\n",
      "2021-04-25 17:53:17,027 [INFO] Training: 3325/6852 -- loss: 2.9602177143096924\n",
      "2021-04-25 17:53:17,078 [INFO] Training: 3326/6852 -- loss: 1.9761533737182617\n",
      "2021-04-25 17:53:17,128 [INFO] Training: 3327/6852 -- loss: 3.3335635662078857\n",
      "2021-04-25 17:53:17,179 [INFO] Training: 3328/6852 -- loss: 2.066274642944336\n",
      "2021-04-25 17:53:17,231 [INFO] Training: 3329/6852 -- loss: 2.319863796234131\n",
      "2021-04-25 17:53:17,280 [INFO] Training: 3330/6852 -- loss: 3.3240535259246826\n",
      "2021-04-25 17:53:17,331 [INFO] Training: 3331/6852 -- loss: 1.9423853158950806\n",
      "2021-04-25 17:53:17,378 [INFO] Training: 3332/6852 -- loss: 3.086972713470459\n",
      "2021-04-25 17:53:17,430 [INFO] Training: 3333/6852 -- loss: 3.062605619430542\n",
      "2021-04-25 17:53:17,479 [INFO] Training: 3334/6852 -- loss: 2.175560474395752\n",
      "2021-04-25 17:53:17,526 [INFO] Training: 3335/6852 -- loss: 2.2202937602996826\n",
      "2021-04-25 17:53:17,577 [INFO] Training: 3336/6852 -- loss: 3.2199788093566895\n",
      "2021-04-25 17:53:17,626 [INFO] Training: 3337/6852 -- loss: 2.5449302196502686\n",
      "2021-04-25 17:53:17,678 [INFO] Training: 3338/6852 -- loss: 2.090061902999878\n",
      "2021-04-25 17:53:17,727 [INFO] Training: 3339/6852 -- loss: 3.0230541229248047\n",
      "2021-04-25 17:53:17,780 [INFO] Training: 3340/6852 -- loss: 3.076478958129883\n",
      "2021-04-25 17:53:17,831 [INFO] Training: 3341/6852 -- loss: 1.7544739246368408\n",
      "2021-04-25 17:53:17,883 [INFO] Training: 3342/6852 -- loss: 3.113065242767334\n",
      "2021-04-25 17:53:17,930 [INFO] Training: 3343/6852 -- loss: 1.6238452196121216\n",
      "2021-04-25 17:53:17,981 [INFO] Training: 3344/6852 -- loss: 2.641110897064209\n",
      "2021-04-25 17:53:18,033 [INFO] Training: 3345/6852 -- loss: 2.386920928955078\n",
      "2021-04-25 17:53:18,081 [INFO] Training: 3346/6852 -- loss: 4.161553382873535\n",
      "2021-04-25 17:53:18,128 [INFO] Training: 3347/6852 -- loss: 2.8212890625\n",
      "2021-04-25 17:53:18,179 [INFO] Training: 3348/6852 -- loss: 3.345945358276367\n",
      "2021-04-25 17:53:18,230 [INFO] Training: 3349/6852 -- loss: 2.1543142795562744\n",
      "2021-04-25 17:53:18,278 [INFO] Training: 3350/6852 -- loss: 3.2955963611602783\n",
      "2021-04-25 17:53:18,330 [INFO] Training: 3351/6852 -- loss: 2.3653602600097656\n",
      "2021-04-25 17:53:18,379 [INFO] Training: 3352/6852 -- loss: 2.222031593322754\n",
      "2021-04-25 17:53:18,430 [INFO] Training: 3353/6852 -- loss: 2.4884748458862305\n",
      "2021-04-25 17:53:18,477 [INFO] Training: 3354/6852 -- loss: 1.7478880882263184\n",
      "2021-04-25 17:53:18,526 [INFO] Training: 3355/6852 -- loss: 2.5144779682159424\n",
      "2021-04-25 17:53:18,577 [INFO] Training: 3356/6852 -- loss: 2.3327713012695312\n",
      "2021-04-25 17:53:18,626 [INFO] Training: 3357/6852 -- loss: 3.4617068767547607\n",
      "2021-04-25 17:53:18,674 [INFO] Training: 3358/6852 -- loss: 1.6566393375396729\n",
      "2021-04-25 17:53:18,723 [INFO] Training: 3359/6852 -- loss: 1.4037507772445679\n",
      "2021-04-25 17:53:18,775 [INFO] Training: 3360/6852 -- loss: 2.036181688308716\n",
      "2021-04-25 17:53:18,822 [INFO] Training: 3361/6852 -- loss: 2.7566182613372803\n",
      "2021-04-25 17:53:18,871 [INFO] Training: 3362/6852 -- loss: 2.7249255180358887\n",
      "2021-04-25 17:53:18,922 [INFO] Training: 3363/6852 -- loss: 1.526806116104126\n",
      "2021-04-25 17:53:18,974 [INFO] Training: 3364/6852 -- loss: 2.9807074069976807\n",
      "2021-04-25 17:53:19,026 [INFO] Training: 3365/6852 -- loss: 2.932459831237793\n",
      "2021-04-25 17:53:19,076 [INFO] Training: 3366/6852 -- loss: 1.6924077272415161\n",
      "2021-04-25 17:53:19,129 [INFO] Training: 3367/6852 -- loss: 2.209990978240967\n",
      "2021-04-25 17:53:19,179 [INFO] Training: 3368/6852 -- loss: 2.744717597961426\n",
      "2021-04-25 17:53:19,230 [INFO] Training: 3369/6852 -- loss: 2.1519784927368164\n",
      "2021-04-25 17:53:19,283 [INFO] Training: 3370/6852 -- loss: 2.484311580657959\n",
      "2021-04-25 17:53:19,333 [INFO] Training: 3371/6852 -- loss: 3.093703508377075\n",
      "2021-04-25 17:53:19,383 [INFO] Training: 3372/6852 -- loss: 2.891505479812622\n",
      "2021-04-25 17:53:19,431 [INFO] Training: 3373/6852 -- loss: 2.861468553543091\n",
      "2021-04-25 17:53:19,478 [INFO] Training: 3374/6852 -- loss: 3.151172161102295\n",
      "2021-04-25 17:53:19,526 [INFO] Training: 3375/6852 -- loss: 3.2481963634490967\n",
      "2021-04-25 17:53:19,574 [INFO] Training: 3376/6852 -- loss: 2.932114601135254\n",
      "2021-04-25 17:53:19,626 [INFO] Training: 3377/6852 -- loss: 1.8695710897445679\n",
      "2021-04-25 17:53:19,676 [INFO] Training: 3378/6852 -- loss: 2.886178493499756\n",
      "2021-04-25 17:53:19,724 [INFO] Training: 3379/6852 -- loss: 2.314354419708252\n",
      "2021-04-25 17:53:19,774 [INFO] Training: 3380/6852 -- loss: 1.6786869764328003\n",
      "2021-04-25 17:53:19,821 [INFO] Training: 3381/6852 -- loss: 2.397649049758911\n",
      "2021-04-25 17:53:19,873 [INFO] Training: 3382/6852 -- loss: 2.0995757579803467\n",
      "2021-04-25 17:53:19,923 [INFO] Training: 3383/6852 -- loss: 1.2087531089782715\n",
      "2021-04-25 17:53:19,971 [INFO] Training: 3384/6852 -- loss: 1.3168916702270508\n",
      "2021-04-25 17:53:20,021 [INFO] Training: 3385/6852 -- loss: 3.3309407234191895\n",
      "2021-04-25 17:53:20,067 [INFO] Training: 3386/6852 -- loss: 3.016629457473755\n",
      "2021-04-25 17:53:20,117 [INFO] Training: 3387/6852 -- loss: 1.8523746728897095\n",
      "2021-04-25 17:53:20,167 [INFO] Training: 3388/6852 -- loss: 2.590930223464966\n",
      "2021-04-25 17:53:20,219 [INFO] Training: 3389/6852 -- loss: 2.2347822189331055\n",
      "2021-04-25 17:53:20,270 [INFO] Training: 3390/6852 -- loss: 1.6578559875488281\n",
      "2021-04-25 17:53:20,321 [INFO] Training: 3391/6852 -- loss: 3.156341075897217\n",
      "2021-04-25 17:53:20,373 [INFO] Training: 3392/6852 -- loss: 3.6987383365631104\n",
      "2021-04-25 17:53:20,423 [INFO] Training: 3393/6852 -- loss: 2.4863600730895996\n",
      "2021-04-25 17:53:20,471 [INFO] Training: 3394/6852 -- loss: 2.875152111053467\n",
      "2021-04-25 17:53:20,522 [INFO] Training: 3395/6852 -- loss: 1.7514008283615112\n",
      "2021-04-25 17:53:20,570 [INFO] Training: 3396/6852 -- loss: 1.2426749467849731\n",
      "2021-04-25 17:53:20,621 [INFO] Training: 3397/6852 -- loss: 2.2003002166748047\n",
      "2021-04-25 17:53:20,670 [INFO] Training: 3398/6852 -- loss: 1.5087841749191284\n",
      "2021-04-25 17:53:20,717 [INFO] Training: 3399/6852 -- loss: 2.4817850589752197\n",
      "2021-04-25 17:53:20,770 [INFO] Training: 3400/6852 -- loss: 2.5326147079467773\n",
      "2021-04-25 17:53:20,816 [INFO] Training: 3401/6852 -- loss: 3.085458517074585\n",
      "2021-04-25 17:53:20,867 [INFO] Training: 3402/6852 -- loss: 2.087554693222046\n",
      "2021-04-25 17:53:20,920 [INFO] Training: 3403/6852 -- loss: 2.5768961906433105\n",
      "2021-04-25 17:53:20,971 [INFO] Training: 3404/6852 -- loss: 1.6846652030944824\n",
      "2021-04-25 17:53:21,018 [INFO] Training: 3405/6852 -- loss: 2.812323570251465\n",
      "2021-04-25 17:53:21,066 [INFO] Training: 3406/6852 -- loss: 2.6479203701019287\n",
      "2021-04-25 17:53:21,116 [INFO] Training: 3407/6852 -- loss: 1.8685779571533203\n",
      "2021-04-25 17:53:21,163 [INFO] Training: 3408/6852 -- loss: 2.3484458923339844\n",
      "2021-04-25 17:53:21,214 [INFO] Training: 3409/6852 -- loss: 2.3381543159484863\n",
      "2021-04-25 17:53:21,261 [INFO] Training: 3410/6852 -- loss: 2.2214365005493164\n",
      "2021-04-25 17:53:21,309 [INFO] Training: 3411/6852 -- loss: 4.6295976638793945\n",
      "2021-04-25 17:53:21,363 [INFO] Training: 3412/6852 -- loss: 3.6734988689422607\n",
      "2021-04-25 17:53:21,412 [INFO] Training: 3413/6852 -- loss: 2.1398580074310303\n",
      "2021-04-25 17:53:21,462 [INFO] Training: 3414/6852 -- loss: 1.9297949075698853\n",
      "2021-04-25 17:53:21,510 [INFO] Training: 3415/6852 -- loss: 2.7186927795410156\n",
      "2021-04-25 17:53:21,562 [INFO] Training: 3416/6852 -- loss: 1.4869306087493896\n",
      "2021-04-25 17:53:21,609 [INFO] Training: 3417/6852 -- loss: 2.5298986434936523\n",
      "2021-04-25 17:53:21,661 [INFO] Training: 3418/6852 -- loss: 3.332625150680542\n",
      "2021-04-25 17:53:21,712 [INFO] Training: 3419/6852 -- loss: 2.9103691577911377\n",
      "2021-04-25 17:53:21,758 [INFO] Training: 3420/6852 -- loss: 2.8312103748321533\n",
      "2021-04-25 17:53:21,810 [INFO] Training: 3421/6852 -- loss: 2.5138745307922363\n",
      "2021-04-25 17:53:21,856 [INFO] Training: 3422/6852 -- loss: 2.201037645339966\n",
      "2021-04-25 17:53:21,905 [INFO] Training: 3423/6852 -- loss: 2.5387065410614014\n",
      "2021-04-25 17:53:21,952 [INFO] Training: 3424/6852 -- loss: 3.479860305786133\n",
      "2021-04-25 17:53:21,997 [INFO] Training: 3425/6852 -- loss: 2.277092695236206\n",
      "2021-04-25 17:53:22,272 [INFO] Training: 3426/6852 -- loss: 1.5408602952957153\n",
      "2021-04-25 17:53:22,330 [INFO] Training: 3427/6852 -- loss: 2.3187482357025146\n",
      "2021-04-25 17:53:22,378 [INFO] Training: 3428/6852 -- loss: 3.584528684616089\n",
      "2021-04-25 17:53:22,427 [INFO] Training: 3429/6852 -- loss: 2.2873387336730957\n",
      "2021-04-25 17:53:22,479 [INFO] Training: 3430/6852 -- loss: 2.2485129833221436\n",
      "2021-04-25 17:53:22,529 [INFO] Training: 3431/6852 -- loss: 2.2008349895477295\n",
      "2021-04-25 17:53:22,579 [INFO] Training: 3432/6852 -- loss: 2.3565287590026855\n",
      "2021-04-25 17:53:22,627 [INFO] Training: 3433/6852 -- loss: 0.95316481590271\n",
      "2021-04-25 17:53:22,677 [INFO] Training: 3434/6852 -- loss: 1.3572956323623657\n",
      "2021-04-25 17:53:22,730 [INFO] Training: 3435/6852 -- loss: 1.9830858707427979\n",
      "2021-04-25 17:53:22,779 [INFO] Training: 3436/6852 -- loss: 1.9097959995269775\n",
      "2021-04-25 17:53:22,829 [INFO] Training: 3437/6852 -- loss: 2.929415464401245\n",
      "2021-04-25 17:53:22,879 [INFO] Training: 3438/6852 -- loss: 1.5849285125732422\n",
      "2021-04-25 17:53:22,929 [INFO] Training: 3439/6852 -- loss: 1.3068615198135376\n",
      "2021-04-25 17:53:22,983 [INFO] Training: 3440/6852 -- loss: 2.8416380882263184\n",
      "2021-04-25 17:53:23,033 [INFO] Training: 3441/6852 -- loss: 2.61853289604187\n",
      "2021-04-25 17:53:23,084 [INFO] Training: 3442/6852 -- loss: 1.541703701019287\n",
      "2021-04-25 17:53:23,133 [INFO] Training: 3443/6852 -- loss: 1.7963346242904663\n",
      "2021-04-25 17:53:23,182 [INFO] Training: 3444/6852 -- loss: 1.4491159915924072\n",
      "2021-04-25 17:53:23,231 [INFO] Training: 3445/6852 -- loss: 2.328907012939453\n",
      "2021-04-25 17:53:23,280 [INFO] Training: 3446/6852 -- loss: 1.950297236442566\n",
      "2021-04-25 17:53:23,333 [INFO] Training: 3447/6852 -- loss: 2.7862637042999268\n",
      "2021-04-25 17:53:23,379 [INFO] Training: 3448/6852 -- loss: 2.841183662414551\n",
      "2021-04-25 17:53:23,428 [INFO] Training: 3449/6852 -- loss: 2.3864128589630127\n",
      "2021-04-25 17:53:23,479 [INFO] Training: 3450/6852 -- loss: 1.3841654062271118\n",
      "2021-04-25 17:53:26,363 [INFO] Training: iteration: 3450/6852 -- epoch: 6 --  train_loss: 2.442 -- train_accuracy: 0.50 valid_loss: 3.045 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:53:26,400 [INFO] Training: 3451/6852 -- loss: 1.0843989849090576\n",
      "2021-04-25 17:53:26,451 [INFO] Training: 3452/6852 -- loss: 2.2354965209960938\n",
      "2021-04-25 17:53:26,503 [INFO] Training: 3453/6852 -- loss: 2.1626298427581787\n",
      "2021-04-25 17:53:26,552 [INFO] Training: 3454/6852 -- loss: 2.1774063110351562\n",
      "2021-04-25 17:53:26,603 [INFO] Training: 3455/6852 -- loss: 2.078320026397705\n",
      "2021-04-25 17:53:26,653 [INFO] Training: 3456/6852 -- loss: 2.6967930793762207\n",
      "2021-04-25 17:53:26,705 [INFO] Training: 3457/6852 -- loss: 2.731224775314331\n",
      "2021-04-25 17:53:26,755 [INFO] Training: 3458/6852 -- loss: 2.4660027027130127\n",
      "2021-04-25 17:53:26,807 [INFO] Training: 3459/6852 -- loss: 1.872540831565857\n",
      "2021-04-25 17:53:26,855 [INFO] Training: 3460/6852 -- loss: 2.0265021324157715\n",
      "2021-04-25 17:53:26,903 [INFO] Training: 3461/6852 -- loss: 3.418672561645508\n",
      "2021-04-25 17:53:26,958 [INFO] Training: 3462/6852 -- loss: 2.6468467712402344\n",
      "2021-04-25 17:53:27,009 [INFO] Training: 3463/6852 -- loss: 2.535616874694824\n",
      "2021-04-25 17:53:27,059 [INFO] Training: 3464/6852 -- loss: 1.7508571147918701\n",
      "2021-04-25 17:53:27,109 [INFO] Training: 3465/6852 -- loss: 3.1955950260162354\n",
      "2021-04-25 17:53:27,157 [INFO] Training: 3466/6852 -- loss: 2.5832455158233643\n",
      "2021-04-25 17:53:27,208 [INFO] Training: 3467/6852 -- loss: 1.6302796602249146\n",
      "2021-04-25 17:53:27,259 [INFO] Training: 3468/6852 -- loss: 1.7759225368499756\n",
      "2021-04-25 17:53:27,306 [INFO] Training: 3469/6852 -- loss: 3.1961517333984375\n",
      "2021-04-25 17:53:27,355 [INFO] Training: 3470/6852 -- loss: 1.3555634021759033\n",
      "2021-04-25 17:53:27,405 [INFO] Training: 3471/6852 -- loss: 2.063210964202881\n",
      "2021-04-25 17:53:27,455 [INFO] Training: 3472/6852 -- loss: 2.5101804733276367\n",
      "2021-04-25 17:53:27,502 [INFO] Training: 3473/6852 -- loss: 2.467212200164795\n",
      "2021-04-25 17:53:27,552 [INFO] Training: 3474/6852 -- loss: 2.5830888748168945\n",
      "2021-04-25 17:53:27,603 [INFO] Training: 3475/6852 -- loss: 1.942194938659668\n",
      "2021-04-25 17:53:27,651 [INFO] Training: 3476/6852 -- loss: 2.159893751144409\n",
      "2021-04-25 17:53:27,706 [INFO] Training: 3477/6852 -- loss: 2.333946704864502\n",
      "2021-04-25 17:53:27,753 [INFO] Training: 3478/6852 -- loss: 2.0298027992248535\n",
      "2021-04-25 17:53:27,802 [INFO] Training: 3479/6852 -- loss: 2.102193593978882\n",
      "2021-04-25 17:53:27,850 [INFO] Training: 3480/6852 -- loss: 2.7581286430358887\n",
      "2021-04-25 17:53:27,900 [INFO] Training: 3481/6852 -- loss: 2.3888392448425293\n",
      "2021-04-25 17:53:27,950 [INFO] Training: 3482/6852 -- loss: 1.8599172830581665\n",
      "2021-04-25 17:53:27,999 [INFO] Training: 3483/6852 -- loss: 1.125030517578125\n",
      "2021-04-25 17:53:28,049 [INFO] Training: 3484/6852 -- loss: 2.8376715183258057\n",
      "2021-04-25 17:53:28,097 [INFO] Training: 3485/6852 -- loss: 2.3963189125061035\n",
      "2021-04-25 17:53:28,146 [INFO] Training: 3486/6852 -- loss: 1.4627735614776611\n",
      "2021-04-25 17:53:28,195 [INFO] Training: 3487/6852 -- loss: 0.9433342218399048\n",
      "2021-04-25 17:53:28,242 [INFO] Training: 3488/6852 -- loss: 1.7468268871307373\n",
      "2021-04-25 17:53:28,296 [INFO] Training: 3489/6852 -- loss: 2.579657793045044\n",
      "2021-04-25 17:53:28,347 [INFO] Training: 3490/6852 -- loss: 2.2430851459503174\n",
      "2021-04-25 17:53:28,397 [INFO] Training: 3491/6852 -- loss: 1.759440541267395\n",
      "2021-04-25 17:53:28,448 [INFO] Training: 3492/6852 -- loss: 2.367191791534424\n",
      "2021-04-25 17:53:28,499 [INFO] Training: 3493/6852 -- loss: 2.1826798915863037\n",
      "2021-04-25 17:53:28,548 [INFO] Training: 3494/6852 -- loss: 3.7530388832092285\n",
      "2021-04-25 17:53:28,598 [INFO] Training: 3495/6852 -- loss: 3.0131514072418213\n",
      "2021-04-25 17:53:28,645 [INFO] Training: 3496/6852 -- loss: 2.408967971801758\n",
      "2021-04-25 17:53:28,699 [INFO] Training: 3497/6852 -- loss: 2.8827297687530518\n",
      "2021-04-25 17:53:28,745 [INFO] Training: 3498/6852 -- loss: 2.4115843772888184\n",
      "2021-04-25 17:53:28,797 [INFO] Training: 3499/6852 -- loss: 4.410120487213135\n",
      "2021-04-25 17:53:28,845 [INFO] Training: 3500/6852 -- loss: 3.538250207901001\n",
      "2021-04-25 17:53:28,897 [INFO] Training: 3501/6852 -- loss: 2.0911788940429688\n",
      "2021-04-25 17:53:28,951 [INFO] Training: 3502/6852 -- loss: 2.36790132522583\n",
      "2021-04-25 17:53:29,002 [INFO] Training: 3503/6852 -- loss: 0.8867723941802979\n",
      "2021-04-25 17:53:29,053 [INFO] Training: 3504/6852 -- loss: 1.3066296577453613\n",
      "2021-04-25 17:53:29,102 [INFO] Training: 3505/6852 -- loss: 3.335657835006714\n",
      "2021-04-25 17:53:29,153 [INFO] Training: 3506/6852 -- loss: 2.5729455947875977\n",
      "2021-04-25 17:53:29,204 [INFO] Training: 3507/6852 -- loss: 2.1541426181793213\n",
      "2021-04-25 17:53:29,253 [INFO] Training: 3508/6852 -- loss: 2.579052209854126\n",
      "2021-04-25 17:53:29,306 [INFO] Training: 3509/6852 -- loss: 2.347824811935425\n",
      "2021-04-25 17:53:29,354 [INFO] Training: 3510/6852 -- loss: 3.276594638824463\n",
      "2021-04-25 17:53:29,407 [INFO] Training: 3511/6852 -- loss: 1.892653465270996\n",
      "2021-04-25 17:53:29,458 [INFO] Training: 3512/6852 -- loss: 2.62542724609375\n",
      "2021-04-25 17:53:29,510 [INFO] Training: 3513/6852 -- loss: 2.525909423828125\n",
      "2021-04-25 17:53:29,563 [INFO] Training: 3514/6852 -- loss: 2.842219352722168\n",
      "2021-04-25 17:53:29,613 [INFO] Training: 3515/6852 -- loss: 1.2600653171539307\n",
      "2021-04-25 17:53:29,660 [INFO] Training: 3516/6852 -- loss: 0.7278733849525452\n",
      "2021-04-25 17:53:29,710 [INFO] Training: 3517/6852 -- loss: 2.2679660320281982\n",
      "2021-04-25 17:53:29,763 [INFO] Training: 3518/6852 -- loss: 1.2225477695465088\n",
      "2021-04-25 17:53:29,812 [INFO] Training: 3519/6852 -- loss: 1.630581259727478\n",
      "2021-04-25 17:53:29,863 [INFO] Training: 3520/6852 -- loss: 2.6410021781921387\n",
      "2021-04-25 17:53:29,909 [INFO] Training: 3521/6852 -- loss: 2.149224042892456\n",
      "2021-04-25 17:53:29,957 [INFO] Training: 3522/6852 -- loss: 1.9044305086135864\n",
      "2021-04-25 17:53:30,008 [INFO] Training: 3523/6852 -- loss: 3.2322373390197754\n",
      "2021-04-25 17:53:30,059 [INFO] Training: 3524/6852 -- loss: 3.350027322769165\n",
      "2021-04-25 17:53:30,109 [INFO] Training: 3525/6852 -- loss: 1.9671097993850708\n",
      "2021-04-25 17:53:30,160 [INFO] Training: 3526/6852 -- loss: 2.6485931873321533\n",
      "2021-04-25 17:53:30,210 [INFO] Training: 3527/6852 -- loss: 1.9453636407852173\n",
      "2021-04-25 17:53:30,261 [INFO] Training: 3528/6852 -- loss: 3.107452869415283\n",
      "2021-04-25 17:53:30,309 [INFO] Training: 3529/6852 -- loss: 2.941551923751831\n",
      "2021-04-25 17:53:30,356 [INFO] Training: 3530/6852 -- loss: 2.0566601753234863\n",
      "2021-04-25 17:53:30,405 [INFO] Training: 3531/6852 -- loss: 2.6013169288635254\n",
      "2021-04-25 17:53:30,453 [INFO] Training: 3532/6852 -- loss: 2.5867116451263428\n",
      "2021-04-25 17:53:30,505 [INFO] Training: 3533/6852 -- loss: 2.068390369415283\n",
      "2021-04-25 17:53:30,555 [INFO] Training: 3534/6852 -- loss: 2.2067689895629883\n",
      "2021-04-25 17:53:30,603 [INFO] Training: 3535/6852 -- loss: 2.254549503326416\n",
      "2021-04-25 17:53:30,657 [INFO] Training: 3536/6852 -- loss: 2.1467018127441406\n",
      "2021-04-25 17:53:30,705 [INFO] Training: 3537/6852 -- loss: 1.908927083015442\n",
      "2021-04-25 17:53:30,756 [INFO] Training: 3538/6852 -- loss: 2.616950511932373\n",
      "2021-04-25 17:53:30,806 [INFO] Training: 3539/6852 -- loss: 2.2793936729431152\n",
      "2021-04-25 17:53:30,856 [INFO] Training: 3540/6852 -- loss: 2.882049560546875\n",
      "2021-04-25 17:53:30,906 [INFO] Training: 3541/6852 -- loss: 1.7129149436950684\n",
      "2021-04-25 17:53:30,958 [INFO] Training: 3542/6852 -- loss: 2.2693393230438232\n",
      "2021-04-25 17:53:31,006 [INFO] Training: 3543/6852 -- loss: 1.9748315811157227\n",
      "2021-04-25 17:53:31,056 [INFO] Training: 3544/6852 -- loss: 1.8975129127502441\n",
      "2021-04-25 17:53:31,112 [INFO] Training: 3545/6852 -- loss: 3.6968138217926025\n",
      "2021-04-25 17:53:31,162 [INFO] Training: 3546/6852 -- loss: 3.041384220123291\n",
      "2021-04-25 17:53:31,209 [INFO] Training: 3547/6852 -- loss: 2.4182803630828857\n",
      "2021-04-25 17:53:31,259 [INFO] Training: 3548/6852 -- loss: 2.912973642349243\n",
      "2021-04-25 17:53:31,307 [INFO] Training: 3549/6852 -- loss: 1.9414429664611816\n",
      "2021-04-25 17:53:31,357 [INFO] Training: 3550/6852 -- loss: 1.7340611219406128\n",
      "2021-04-25 17:53:31,408 [INFO] Training: 3551/6852 -- loss: 1.8782927989959717\n",
      "2021-04-25 17:53:31,456 [INFO] Training: 3552/6852 -- loss: 2.005427122116089\n",
      "2021-04-25 17:53:31,508 [INFO] Training: 3553/6852 -- loss: 1.7205549478530884\n",
      "2021-04-25 17:53:31,558 [INFO] Training: 3554/6852 -- loss: 3.2294363975524902\n",
      "2021-04-25 17:53:31,608 [INFO] Training: 3555/6852 -- loss: 2.0952470302581787\n",
      "2021-04-25 17:53:31,656 [INFO] Training: 3556/6852 -- loss: 2.2035603523254395\n",
      "2021-04-25 17:53:31,705 [INFO] Training: 3557/6852 -- loss: 2.7854812145233154\n",
      "2021-04-25 17:53:31,755 [INFO] Training: 3558/6852 -- loss: 2.2386584281921387\n",
      "2021-04-25 17:53:31,806 [INFO] Training: 3559/6852 -- loss: 2.338447093963623\n",
      "2021-04-25 17:53:31,857 [INFO] Training: 3560/6852 -- loss: 2.0339443683624268\n",
      "2021-04-25 17:53:31,905 [INFO] Training: 3561/6852 -- loss: 1.2499154806137085\n",
      "2021-04-25 17:53:31,954 [INFO] Training: 3562/6852 -- loss: 2.046945571899414\n",
      "2021-04-25 17:53:32,001 [INFO] Training: 3563/6852 -- loss: 1.8330944776535034\n",
      "2021-04-25 17:53:32,048 [INFO] Training: 3564/6852 -- loss: 1.771943211555481\n",
      "2021-04-25 17:53:32,099 [INFO] Training: 3565/6852 -- loss: 2.592249631881714\n",
      "2021-04-25 17:53:32,151 [INFO] Training: 3566/6852 -- loss: 1.9085124731063843\n",
      "2021-04-25 17:53:32,200 [INFO] Training: 3567/6852 -- loss: 2.6482293605804443\n",
      "2021-04-25 17:53:32,247 [INFO] Training: 3568/6852 -- loss: 1.4037975072860718\n",
      "2021-04-25 17:53:32,297 [INFO] Training: 3569/6852 -- loss: 0.9476798176765442\n",
      "2021-04-25 17:53:32,348 [INFO] Training: 3570/6852 -- loss: 2.057037830352783\n",
      "2021-04-25 17:53:32,396 [INFO] Training: 3571/6852 -- loss: 2.952892541885376\n",
      "2021-04-25 17:53:32,444 [INFO] Training: 3572/6852 -- loss: 2.1986889839172363\n",
      "2021-04-25 17:53:32,491 [INFO] Training: 3573/6852 -- loss: 2.3463590145111084\n",
      "2021-04-25 17:53:32,540 [INFO] Training: 3574/6852 -- loss: 3.387861490249634\n",
      "2021-04-25 17:53:32,591 [INFO] Training: 3575/6852 -- loss: 2.1611411571502686\n",
      "2021-04-25 17:53:32,638 [INFO] Training: 3576/6852 -- loss: 2.436300277709961\n",
      "2021-04-25 17:53:32,688 [INFO] Training: 3577/6852 -- loss: 2.6509323120117188\n",
      "2021-04-25 17:53:32,737 [INFO] Training: 3578/6852 -- loss: 2.648399829864502\n",
      "2021-04-25 17:53:32,786 [INFO] Training: 3579/6852 -- loss: 1.8663452863693237\n",
      "2021-04-25 17:53:32,835 [INFO] Training: 3580/6852 -- loss: 2.6862637996673584\n",
      "2021-04-25 17:53:32,884 [INFO] Training: 3581/6852 -- loss: 1.9783556461334229\n",
      "2021-04-25 17:53:32,932 [INFO] Training: 3582/6852 -- loss: 1.3797160387039185\n",
      "2021-04-25 17:53:32,981 [INFO] Training: 3583/6852 -- loss: 3.1449832916259766\n",
      "2021-04-25 17:53:33,032 [INFO] Training: 3584/6852 -- loss: 2.959526538848877\n",
      "2021-04-25 17:53:33,081 [INFO] Training: 3585/6852 -- loss: 2.9778382778167725\n",
      "2021-04-25 17:53:33,135 [INFO] Training: 3586/6852 -- loss: 3.609260082244873\n",
      "2021-04-25 17:53:33,184 [INFO] Training: 3587/6852 -- loss: 3.0888524055480957\n",
      "2021-04-25 17:53:33,234 [INFO] Training: 3588/6852 -- loss: 2.5260825157165527\n",
      "2021-04-25 17:53:33,281 [INFO] Training: 3589/6852 -- loss: 2.9701120853424072\n",
      "2021-04-25 17:53:33,336 [INFO] Training: 3590/6852 -- loss: 2.3443706035614014\n",
      "2021-04-25 17:53:33,385 [INFO] Training: 3591/6852 -- loss: 2.6165459156036377\n",
      "2021-04-25 17:53:33,433 [INFO] Training: 3592/6852 -- loss: 0.9937011003494263\n",
      "2021-04-25 17:53:33,482 [INFO] Training: 3593/6852 -- loss: 2.236694097518921\n",
      "2021-04-25 17:53:33,529 [INFO] Training: 3594/6852 -- loss: 1.7615426778793335\n",
      "2021-04-25 17:53:33,582 [INFO] Training: 3595/6852 -- loss: 2.5251903533935547\n",
      "2021-04-25 17:53:33,630 [INFO] Training: 3596/6852 -- loss: 2.207900285720825\n",
      "2021-04-25 17:53:33,681 [INFO] Training: 3597/6852 -- loss: 1.757416844367981\n",
      "2021-04-25 17:53:33,736 [INFO] Training: 3598/6852 -- loss: 1.8986799716949463\n",
      "2021-04-25 17:53:33,788 [INFO] Training: 3599/6852 -- loss: 1.3859001398086548\n",
      "2021-04-25 17:53:33,836 [INFO] Training: 3600/6852 -- loss: 1.9623088836669922\n",
      "2021-04-25 17:53:36,712 [INFO] Training: iteration: 3600/6852 -- epoch: 6 --  train_loss: 2.297 -- train_accuracy: 0.38 valid_loss: 3.055 -- valid_accuracy: 0.32\n",
      "2021-04-25 17:53:36,751 [INFO] Training: 3601/6852 -- loss: 2.1439192295074463\n",
      "2021-04-25 17:53:36,799 [INFO] Training: 3602/6852 -- loss: 2.0855767726898193\n",
      "2021-04-25 17:53:36,849 [INFO] Training: 3603/6852 -- loss: 2.923970937728882\n",
      "2021-04-25 17:53:36,900 [INFO] Training: 3604/6852 -- loss: 3.4301598072052\n",
      "2021-04-25 17:53:36,948 [INFO] Training: 3605/6852 -- loss: 3.850830078125\n",
      "2021-04-25 17:53:36,998 [INFO] Training: 3606/6852 -- loss: 3.2135655879974365\n",
      "2021-04-25 17:53:37,046 [INFO] Training: 3607/6852 -- loss: 2.701012372970581\n",
      "2021-04-25 17:53:37,098 [INFO] Training: 3608/6852 -- loss: 2.766906261444092\n",
      "2021-04-25 17:53:37,146 [INFO] Training: 3609/6852 -- loss: 1.2647274732589722\n",
      "2021-04-25 17:53:37,199 [INFO] Training: 3610/6852 -- loss: 2.3244779109954834\n",
      "2021-04-25 17:53:37,251 [INFO] Training: 3611/6852 -- loss: 3.173130750656128\n",
      "2021-04-25 17:53:37,302 [INFO] Training: 3612/6852 -- loss: 1.9534258842468262\n",
      "2021-04-25 17:53:37,352 [INFO] Training: 3613/6852 -- loss: 2.056281089782715\n",
      "2021-04-25 17:53:37,401 [INFO] Training: 3614/6852 -- loss: 2.4599342346191406\n",
      "2021-04-25 17:53:37,451 [INFO] Training: 3615/6852 -- loss: 1.670520544052124\n",
      "2021-04-25 17:53:37,498 [INFO] Training: 3616/6852 -- loss: 1.052269458770752\n",
      "2021-04-25 17:53:37,549 [INFO] Training: 3617/6852 -- loss: 2.755457639694214\n",
      "2021-04-25 17:53:37,598 [INFO] Training: 3618/6852 -- loss: 1.4373208284378052\n",
      "2021-04-25 17:53:37,651 [INFO] Training: 3619/6852 -- loss: 1.9760013818740845\n",
      "2021-04-25 17:53:37,701 [INFO] Training: 3620/6852 -- loss: 1.7367457151412964\n",
      "2021-04-25 17:53:37,752 [INFO] Training: 3621/6852 -- loss: 1.7840708494186401\n",
      "2021-04-25 17:53:37,799 [INFO] Training: 3622/6852 -- loss: 3.9897284507751465\n",
      "2021-04-25 17:53:37,849 [INFO] Training: 3623/6852 -- loss: 2.0437774658203125\n",
      "2021-04-25 17:53:37,897 [INFO] Training: 3624/6852 -- loss: 4.242445945739746\n",
      "2021-04-25 17:53:37,945 [INFO] Training: 3625/6852 -- loss: 2.699540138244629\n",
      "2021-04-25 17:53:37,994 [INFO] Training: 3626/6852 -- loss: 2.3632876873016357\n",
      "2021-04-25 17:53:38,046 [INFO] Training: 3627/6852 -- loss: 1.6975932121276855\n",
      "2021-04-25 17:53:38,098 [INFO] Training: 3628/6852 -- loss: 3.068274736404419\n",
      "2021-04-25 17:53:38,149 [INFO] Training: 3629/6852 -- loss: 2.915390729904175\n",
      "2021-04-25 17:53:38,197 [INFO] Training: 3630/6852 -- loss: 2.1132709980010986\n",
      "2021-04-25 17:53:38,246 [INFO] Training: 3631/6852 -- loss: 2.4521842002868652\n",
      "2021-04-25 17:53:38,298 [INFO] Training: 3632/6852 -- loss: 2.66154146194458\n",
      "2021-04-25 17:53:38,345 [INFO] Training: 3633/6852 -- loss: 2.2091891765594482\n",
      "2021-04-25 17:53:38,398 [INFO] Training: 3634/6852 -- loss: 2.8774592876434326\n",
      "2021-04-25 17:53:38,445 [INFO] Training: 3635/6852 -- loss: 2.675032615661621\n",
      "2021-04-25 17:53:38,494 [INFO] Training: 3636/6852 -- loss: 1.6240895986557007\n",
      "2021-04-25 17:53:38,542 [INFO] Training: 3637/6852 -- loss: 2.6096343994140625\n",
      "2021-04-25 17:53:38,594 [INFO] Training: 3638/6852 -- loss: 2.784884452819824\n",
      "2021-04-25 17:53:38,643 [INFO] Training: 3639/6852 -- loss: 1.9286214113235474\n",
      "2021-04-25 17:53:38,695 [INFO] Training: 3640/6852 -- loss: 3.040743589401245\n",
      "2021-04-25 17:53:38,745 [INFO] Training: 3641/6852 -- loss: 2.9216392040252686\n",
      "2021-04-25 17:53:38,796 [INFO] Training: 3642/6852 -- loss: 2.1254935264587402\n",
      "2021-04-25 17:53:38,845 [INFO] Training: 3643/6852 -- loss: 2.1369214057922363\n",
      "2021-04-25 17:53:38,895 [INFO] Training: 3644/6852 -- loss: 2.9458813667297363\n",
      "2021-04-25 17:53:38,946 [INFO] Training: 3645/6852 -- loss: 2.2544491291046143\n",
      "2021-04-25 17:53:39,000 [INFO] Training: 3646/6852 -- loss: 1.7139122486114502\n",
      "2021-04-25 17:53:39,048 [INFO] Training: 3647/6852 -- loss: 2.48738956451416\n",
      "2021-04-25 17:53:39,095 [INFO] Training: 3648/6852 -- loss: 1.7281838655471802\n",
      "2021-04-25 17:53:39,142 [INFO] Training: 3649/6852 -- loss: 2.820176362991333\n",
      "2021-04-25 17:53:39,192 [INFO] Training: 3650/6852 -- loss: 3.2127227783203125\n",
      "2021-04-25 17:53:39,239 [INFO] Training: 3651/6852 -- loss: 1.5497995615005493\n",
      "2021-04-25 17:53:39,291 [INFO] Training: 3652/6852 -- loss: 2.6234095096588135\n",
      "2021-04-25 17:53:39,341 [INFO] Training: 3653/6852 -- loss: 1.7027170658111572\n",
      "2021-04-25 17:53:39,390 [INFO] Training: 3654/6852 -- loss: 2.3552751541137695\n",
      "2021-04-25 17:53:39,441 [INFO] Training: 3655/6852 -- loss: 2.382606267929077\n",
      "2021-04-25 17:53:39,490 [INFO] Training: 3656/6852 -- loss: 3.073338031768799\n",
      "2021-04-25 17:53:39,540 [INFO] Training: 3657/6852 -- loss: 1.864875078201294\n",
      "2021-04-25 17:53:39,589 [INFO] Training: 3658/6852 -- loss: 2.190713405609131\n",
      "2021-04-25 17:53:39,639 [INFO] Training: 3659/6852 -- loss: 2.5126559734344482\n",
      "2021-04-25 17:53:39,689 [INFO] Training: 3660/6852 -- loss: 2.5513381958007812\n",
      "2021-04-25 17:53:39,739 [INFO] Training: 3661/6852 -- loss: 2.000145196914673\n",
      "2021-04-25 17:53:39,789 [INFO] Training: 3662/6852 -- loss: 2.601783514022827\n",
      "2021-04-25 17:53:39,841 [INFO] Training: 3663/6852 -- loss: 2.172083616256714\n",
      "2021-04-25 17:53:39,891 [INFO] Training: 3664/6852 -- loss: 2.006150245666504\n",
      "2021-04-25 17:53:39,942 [INFO] Training: 3665/6852 -- loss: 2.235304832458496\n",
      "2021-04-25 17:53:39,992 [INFO] Training: 3666/6852 -- loss: 1.9979479312896729\n",
      "2021-04-25 17:53:40,045 [INFO] Training: 3667/6852 -- loss: 2.223580837249756\n",
      "2021-04-25 17:53:40,093 [INFO] Training: 3668/6852 -- loss: 2.7622530460357666\n",
      "2021-04-25 17:53:40,143 [INFO] Training: 3669/6852 -- loss: 2.9541962146759033\n",
      "2021-04-25 17:53:40,192 [INFO] Training: 3670/6852 -- loss: 3.764403820037842\n",
      "2021-04-25 17:53:40,246 [INFO] Training: 3671/6852 -- loss: 2.9379186630249023\n",
      "2021-04-25 17:53:40,293 [INFO] Training: 3672/6852 -- loss: 1.9894168376922607\n",
      "2021-04-25 17:53:40,347 [INFO] Training: 3673/6852 -- loss: 1.7953952550888062\n",
      "2021-04-25 17:53:40,394 [INFO] Training: 3674/6852 -- loss: 1.8946499824523926\n",
      "2021-04-25 17:53:40,441 [INFO] Training: 3675/6852 -- loss: 2.6769819259643555\n",
      "2021-04-25 17:53:40,494 [INFO] Training: 3676/6852 -- loss: 1.4023566246032715\n",
      "2021-04-25 17:53:40,544 [INFO] Training: 3677/6852 -- loss: 1.0283329486846924\n",
      "2021-04-25 17:53:40,593 [INFO] Training: 3678/6852 -- loss: 1.7048277854919434\n",
      "2021-04-25 17:53:40,641 [INFO] Training: 3679/6852 -- loss: 2.4343161582946777\n",
      "2021-04-25 17:53:40,692 [INFO] Training: 3680/6852 -- loss: 1.5975227355957031\n",
      "2021-04-25 17:53:40,743 [INFO] Training: 3681/6852 -- loss: 1.9244762659072876\n",
      "2021-04-25 17:53:40,797 [INFO] Training: 3682/6852 -- loss: 1.764050841331482\n",
      "2021-04-25 17:53:40,843 [INFO] Training: 3683/6852 -- loss: 2.872091293334961\n",
      "2021-04-25 17:53:40,894 [INFO] Training: 3684/6852 -- loss: 1.7382181882858276\n",
      "2021-04-25 17:53:40,943 [INFO] Training: 3685/6852 -- loss: 1.5407170057296753\n",
      "2021-04-25 17:53:40,991 [INFO] Training: 3686/6852 -- loss: 1.235311508178711\n",
      "2021-04-25 17:53:41,043 [INFO] Training: 3687/6852 -- loss: 2.3808844089508057\n",
      "2021-04-25 17:53:41,094 [INFO] Training: 3688/6852 -- loss: 2.7021408081054688\n",
      "2021-04-25 17:53:41,148 [INFO] Training: 3689/6852 -- loss: 1.8210161924362183\n",
      "2021-04-25 17:53:41,196 [INFO] Training: 3690/6852 -- loss: 1.7844281196594238\n",
      "2021-04-25 17:53:41,251 [INFO] Training: 3691/6852 -- loss: 2.61782169342041\n",
      "2021-04-25 17:53:41,301 [INFO] Training: 3692/6852 -- loss: 1.2399446964263916\n",
      "2021-04-25 17:53:41,353 [INFO] Training: 3693/6852 -- loss: 1.698568344116211\n",
      "2021-04-25 17:53:41,402 [INFO] Training: 3694/6852 -- loss: 1.4708480834960938\n",
      "2021-04-25 17:53:41,450 [INFO] Training: 3695/6852 -- loss: 2.1384897232055664\n",
      "2021-04-25 17:53:41,499 [INFO] Training: 3696/6852 -- loss: 2.0725314617156982\n",
      "2021-04-25 17:53:41,548 [INFO] Training: 3697/6852 -- loss: 2.6434295177459717\n",
      "2021-04-25 17:53:41,597 [INFO] Training: 3698/6852 -- loss: 2.9315409660339355\n",
      "2021-04-25 17:53:41,647 [INFO] Training: 3699/6852 -- loss: 2.6219019889831543\n",
      "2021-04-25 17:53:41,695 [INFO] Training: 3700/6852 -- loss: 5.051070690155029\n",
      "2021-04-25 17:53:41,746 [INFO] Training: 3701/6852 -- loss: 1.894086480140686\n",
      "2021-04-25 17:53:41,794 [INFO] Training: 3702/6852 -- loss: 2.6483683586120605\n",
      "2021-04-25 17:53:41,844 [INFO] Training: 3703/6852 -- loss: 2.5005836486816406\n",
      "2021-04-25 17:53:41,892 [INFO] Training: 3704/6852 -- loss: 2.3749139308929443\n",
      "2021-04-25 17:53:41,939 [INFO] Training: 3705/6852 -- loss: 2.1746206283569336\n",
      "2021-04-25 17:53:41,989 [INFO] Training: 3706/6852 -- loss: 2.475506067276001\n",
      "2021-04-25 17:53:42,039 [INFO] Training: 3707/6852 -- loss: 2.3132710456848145\n",
      "2021-04-25 17:53:42,086 [INFO] Training: 3708/6852 -- loss: 1.6333105564117432\n",
      "2021-04-25 17:53:42,136 [INFO] Training: 3709/6852 -- loss: 1.7378625869750977\n",
      "2021-04-25 17:53:42,183 [INFO] Training: 3710/6852 -- loss: 2.0959548950195312\n",
      "2021-04-25 17:53:42,233 [INFO] Training: 3711/6852 -- loss: 2.1191489696502686\n",
      "2021-04-25 17:53:42,281 [INFO] Training: 3712/6852 -- loss: 2.507984161376953\n",
      "2021-04-25 17:53:42,330 [INFO] Training: 3713/6852 -- loss: 2.014064311981201\n",
      "2021-04-25 17:53:42,379 [INFO] Training: 3714/6852 -- loss: 3.2434921264648438\n",
      "2021-04-25 17:53:42,431 [INFO] Training: 3715/6852 -- loss: 2.061330556869507\n",
      "2021-04-25 17:53:42,486 [INFO] Training: 3716/6852 -- loss: 2.0683083534240723\n",
      "2021-04-25 17:53:42,536 [INFO] Training: 3717/6852 -- loss: 2.159182071685791\n",
      "2021-04-25 17:53:42,584 [INFO] Training: 3718/6852 -- loss: 2.43746018409729\n",
      "2021-04-25 17:53:42,637 [INFO] Training: 3719/6852 -- loss: 3.6461009979248047\n",
      "2021-04-25 17:53:42,689 [INFO] Training: 3720/6852 -- loss: 2.1934640407562256\n",
      "2021-04-25 17:53:42,738 [INFO] Training: 3721/6852 -- loss: 2.5051872730255127\n",
      "2021-04-25 17:53:42,787 [INFO] Training: 3722/6852 -- loss: 2.514737129211426\n",
      "2021-04-25 17:53:42,836 [INFO] Training: 3723/6852 -- loss: 2.475189685821533\n",
      "2021-04-25 17:53:42,886 [INFO] Training: 3724/6852 -- loss: 3.024535894393921\n",
      "2021-04-25 17:53:42,937 [INFO] Training: 3725/6852 -- loss: 2.198316812515259\n",
      "2021-04-25 17:53:42,987 [INFO] Training: 3726/6852 -- loss: 1.9704349040985107\n",
      "2021-04-25 17:53:43,036 [INFO] Training: 3727/6852 -- loss: 2.261991024017334\n",
      "2021-04-25 17:53:43,091 [INFO] Training: 3728/6852 -- loss: 3.3319599628448486\n",
      "2021-04-25 17:53:43,137 [INFO] Training: 3729/6852 -- loss: 1.889228343963623\n",
      "2021-04-25 17:53:43,189 [INFO] Training: 3730/6852 -- loss: 1.8723194599151611\n",
      "2021-04-25 17:53:43,242 [INFO] Training: 3731/6852 -- loss: 2.6813364028930664\n",
      "2021-04-25 17:53:43,292 [INFO] Training: 3732/6852 -- loss: 3.306952953338623\n",
      "2021-04-25 17:53:43,343 [INFO] Training: 3733/6852 -- loss: 1.6669645309448242\n",
      "2021-04-25 17:53:43,393 [INFO] Training: 3734/6852 -- loss: 2.6651082038879395\n",
      "2021-04-25 17:53:43,443 [INFO] Training: 3735/6852 -- loss: 2.9602103233337402\n",
      "2021-04-25 17:53:43,498 [INFO] Training: 3736/6852 -- loss: 4.002174377441406\n",
      "2021-04-25 17:53:43,551 [INFO] Training: 3737/6852 -- loss: 1.8874294757843018\n",
      "2021-04-25 17:53:43,603 [INFO] Training: 3738/6852 -- loss: 2.4894866943359375\n",
      "2021-04-25 17:53:43,652 [INFO] Training: 3739/6852 -- loss: 1.6497257947921753\n",
      "2021-04-25 17:53:43,703 [INFO] Training: 3740/6852 -- loss: 1.5522152185440063\n",
      "2021-04-25 17:53:43,753 [INFO] Training: 3741/6852 -- loss: 2.7927887439727783\n",
      "2021-04-25 17:53:43,801 [INFO] Training: 3742/6852 -- loss: 2.435318946838379\n",
      "2021-04-25 17:53:43,855 [INFO] Training: 3743/6852 -- loss: 2.018284797668457\n",
      "2021-04-25 17:53:43,903 [INFO] Training: 3744/6852 -- loss: 2.3204548358917236\n",
      "2021-04-25 17:53:43,951 [INFO] Training: 3745/6852 -- loss: 3.0612690448760986\n",
      "2021-04-25 17:53:44,000 [INFO] Training: 3746/6852 -- loss: 3.053297758102417\n",
      "2021-04-25 17:53:44,048 [INFO] Training: 3747/6852 -- loss: 2.047112226486206\n",
      "2021-04-25 17:53:44,098 [INFO] Training: 3748/6852 -- loss: 2.6488876342773438\n",
      "2021-04-25 17:53:44,146 [INFO] Training: 3749/6852 -- loss: 1.7116482257843018\n",
      "2021-04-25 17:53:44,193 [INFO] Training: 3750/6852 -- loss: 2.120635986328125\n",
      "2021-04-25 17:53:47,056 [INFO] Training: iteration: 3750/6852 -- epoch: 6 --  train_loss: 2.358 -- train_accuracy: 0.38 valid_loss: 3.039 -- valid_accuracy: 0.30\n",
      "2021-04-25 17:53:47,101 [INFO] Training: 3751/6852 -- loss: 1.5966122150421143\n",
      "2021-04-25 17:53:47,150 [INFO] Training: 3752/6852 -- loss: 3.1494803428649902\n",
      "2021-04-25 17:53:47,199 [INFO] Training: 3753/6852 -- loss: 2.8611605167388916\n",
      "2021-04-25 17:53:47,249 [INFO] Training: 3754/6852 -- loss: 2.2423794269561768\n",
      "2021-04-25 17:53:47,300 [INFO] Training: 3755/6852 -- loss: 1.9198848009109497\n",
      "2021-04-25 17:53:47,351 [INFO] Training: 3756/6852 -- loss: 1.9967193603515625\n",
      "2021-04-25 17:53:47,401 [INFO] Training: 3757/6852 -- loss: 3.0385031700134277\n",
      "2021-04-25 17:53:47,448 [INFO] Training: 3758/6852 -- loss: 3.1569924354553223\n",
      "2021-04-25 17:53:47,499 [INFO] Training: 3759/6852 -- loss: 1.7448400259017944\n",
      "2021-04-25 17:53:47,547 [INFO] Training: 3760/6852 -- loss: 1.7911509275436401\n",
      "2021-04-25 17:53:47,596 [INFO] Training: 3761/6852 -- loss: 1.9838756322860718\n",
      "2021-04-25 17:53:47,644 [INFO] Training: 3762/6852 -- loss: 1.5722192525863647\n",
      "2021-04-25 17:53:47,690 [INFO] Training: 3763/6852 -- loss: 2.284815549850464\n",
      "2021-04-25 17:53:47,740 [INFO] Training: 3764/6852 -- loss: 2.5503458976745605\n",
      "2021-04-25 17:53:47,793 [INFO] Training: 3765/6852 -- loss: 1.257621169090271\n",
      "2021-04-25 17:53:47,843 [INFO] Training: 3766/6852 -- loss: 2.4894824028015137\n",
      "2021-04-25 17:53:47,890 [INFO] Training: 3767/6852 -- loss: 1.49440598487854\n",
      "2021-04-25 17:53:47,941 [INFO] Training: 3768/6852 -- loss: 2.666886329650879\n",
      "2021-04-25 17:53:47,991 [INFO] Training: 3769/6852 -- loss: 1.9858851432800293\n",
      "2021-04-25 17:53:48,040 [INFO] Training: 3770/6852 -- loss: 1.6802972555160522\n",
      "2021-04-25 17:53:48,090 [INFO] Training: 3771/6852 -- loss: 2.3983662128448486\n",
      "2021-04-25 17:53:48,136 [INFO] Training: 3772/6852 -- loss: 3.1380457878112793\n",
      "2021-04-25 17:53:48,185 [INFO] Training: 3773/6852 -- loss: 1.6493234634399414\n",
      "2021-04-25 17:53:48,233 [INFO] Training: 3774/6852 -- loss: 2.3606481552124023\n",
      "2021-04-25 17:53:48,280 [INFO] Training: 3775/6852 -- loss: 2.246549606323242\n",
      "2021-04-25 17:53:48,332 [INFO] Training: 3776/6852 -- loss: 1.7231727838516235\n",
      "2021-04-25 17:53:48,383 [INFO] Training: 3777/6852 -- loss: 1.940251350402832\n",
      "2021-04-25 17:53:48,433 [INFO] Training: 3778/6852 -- loss: 2.7290096282958984\n",
      "2021-04-25 17:53:48,481 [INFO] Training: 3779/6852 -- loss: 1.8287434577941895\n",
      "2021-04-25 17:53:48,531 [INFO] Training: 3780/6852 -- loss: 3.0392725467681885\n",
      "2021-04-25 17:53:48,578 [INFO] Training: 3781/6852 -- loss: 2.255932092666626\n",
      "2021-04-25 17:53:48,627 [INFO] Training: 3782/6852 -- loss: 2.70802903175354\n",
      "2021-04-25 17:53:48,675 [INFO] Training: 3783/6852 -- loss: 2.879244804382324\n",
      "2021-04-25 17:53:48,723 [INFO] Training: 3784/6852 -- loss: 2.744980812072754\n",
      "2021-04-25 17:53:48,770 [INFO] Training: 3785/6852 -- loss: 3.326805591583252\n",
      "2021-04-25 17:53:48,818 [INFO] Training: 3786/6852 -- loss: 2.4794955253601074\n",
      "2021-04-25 17:53:48,867 [INFO] Training: 3787/6852 -- loss: 1.2835510969161987\n",
      "2021-04-25 17:53:48,915 [INFO] Training: 3788/6852 -- loss: 1.8303382396697998\n",
      "2021-04-25 17:53:48,963 [INFO] Training: 3789/6852 -- loss: 2.8468663692474365\n",
      "2021-04-25 17:53:49,014 [INFO] Training: 3790/6852 -- loss: 1.430582046508789\n",
      "2021-04-25 17:53:49,062 [INFO] Training: 3791/6852 -- loss: 2.474553346633911\n",
      "2021-04-25 17:53:49,109 [INFO] Training: 3792/6852 -- loss: 2.005150079727173\n",
      "2021-04-25 17:53:49,163 [INFO] Training: 3793/6852 -- loss: 1.8024282455444336\n",
      "2021-04-25 17:53:49,210 [INFO] Training: 3794/6852 -- loss: 1.8583693504333496\n",
      "2021-04-25 17:53:49,258 [INFO] Training: 3795/6852 -- loss: 3.0634684562683105\n",
      "2021-04-25 17:53:49,308 [INFO] Training: 3796/6852 -- loss: 2.508790969848633\n",
      "2021-04-25 17:53:49,366 [INFO] Training: 3797/6852 -- loss: 1.19899582862854\n",
      "2021-04-25 17:53:49,413 [INFO] Training: 3798/6852 -- loss: 2.9079935550689697\n",
      "2021-04-25 17:53:49,462 [INFO] Training: 3799/6852 -- loss: 2.0227532386779785\n",
      "2021-04-25 17:53:49,512 [INFO] Training: 3800/6852 -- loss: 1.1171486377716064\n",
      "2021-04-25 17:53:49,559 [INFO] Training: 3801/6852 -- loss: 1.8245983123779297\n",
      "2021-04-25 17:53:49,608 [INFO] Training: 3802/6852 -- loss: 2.6405322551727295\n",
      "2021-04-25 17:53:49,657 [INFO] Training: 3803/6852 -- loss: 2.04677677154541\n",
      "2021-04-25 17:53:49,704 [INFO] Training: 3804/6852 -- loss: 1.5062921047210693\n",
      "2021-04-25 17:53:49,757 [INFO] Training: 3805/6852 -- loss: 1.1894218921661377\n",
      "2021-04-25 17:53:49,806 [INFO] Training: 3806/6852 -- loss: 2.108435869216919\n",
      "2021-04-25 17:53:49,858 [INFO] Training: 3807/6852 -- loss: 3.368955612182617\n",
      "2021-04-25 17:53:49,906 [INFO] Training: 3808/6852 -- loss: 2.4932098388671875\n",
      "2021-04-25 17:53:49,955 [INFO] Training: 3809/6852 -- loss: 2.6682920455932617\n",
      "2021-04-25 17:53:50,002 [INFO] Training: 3810/6852 -- loss: 2.3997607231140137\n",
      "2021-04-25 17:53:50,054 [INFO] Training: 3811/6852 -- loss: 3.346734046936035\n",
      "2021-04-25 17:53:50,102 [INFO] Training: 3812/6852 -- loss: 3.0606319904327393\n",
      "2021-04-25 17:53:50,152 [INFO] Training: 3813/6852 -- loss: 0.8823321461677551\n",
      "2021-04-25 17:53:50,203 [INFO] Training: 3814/6852 -- loss: 1.722890019416809\n",
      "2021-04-25 17:53:50,252 [INFO] Training: 3815/6852 -- loss: 2.2116711139678955\n",
      "2021-04-25 17:53:50,302 [INFO] Training: 3816/6852 -- loss: 2.831062078475952\n",
      "2021-04-25 17:53:50,350 [INFO] Training: 3817/6852 -- loss: 3.1279616355895996\n",
      "2021-04-25 17:53:50,401 [INFO] Training: 3818/6852 -- loss: 1.2659803628921509\n",
      "2021-04-25 17:53:50,449 [INFO] Training: 3819/6852 -- loss: 2.896601915359497\n",
      "2021-04-25 17:53:50,498 [INFO] Training: 3820/6852 -- loss: 2.2634332180023193\n",
      "2021-04-25 17:53:50,548 [INFO] Training: 3821/6852 -- loss: 1.6998282670974731\n",
      "2021-04-25 17:53:50,596 [INFO] Training: 3822/6852 -- loss: 1.7484010457992554\n",
      "2021-04-25 17:53:50,644 [INFO] Training: 3823/6852 -- loss: 2.694843292236328\n",
      "2021-04-25 17:53:50,692 [INFO] Training: 3824/6852 -- loss: 1.6620869636535645\n",
      "2021-04-25 17:53:50,739 [INFO] Training: 3825/6852 -- loss: 2.452256679534912\n",
      "2021-04-25 17:53:50,792 [INFO] Training: 3826/6852 -- loss: 2.203228235244751\n",
      "2021-04-25 17:53:50,840 [INFO] Training: 3827/6852 -- loss: 1.7939634323120117\n",
      "2021-04-25 17:53:50,893 [INFO] Training: 3828/6852 -- loss: 2.1186842918395996\n",
      "2021-04-25 17:53:50,942 [INFO] Training: 3829/6852 -- loss: 1.6377846002578735\n",
      "2021-04-25 17:53:50,992 [INFO] Training: 3830/6852 -- loss: 2.497877836227417\n",
      "2021-04-25 17:53:51,044 [INFO] Training: 3831/6852 -- loss: 2.441042184829712\n",
      "2021-04-25 17:53:51,094 [INFO] Training: 3832/6852 -- loss: 1.5863759517669678\n",
      "2021-04-25 17:53:51,142 [INFO] Training: 3833/6852 -- loss: 3.4693524837493896\n",
      "2021-04-25 17:53:51,194 [INFO] Training: 3834/6852 -- loss: 1.9360512495040894\n",
      "2021-04-25 17:53:51,244 [INFO] Training: 3835/6852 -- loss: 2.4739267826080322\n",
      "2021-04-25 17:53:51,292 [INFO] Training: 3836/6852 -- loss: 2.7590222358703613\n",
      "2021-04-25 17:53:51,343 [INFO] Training: 3837/6852 -- loss: 2.3209025859832764\n",
      "2021-04-25 17:53:51,394 [INFO] Training: 3838/6852 -- loss: 1.5228320360183716\n",
      "2021-04-25 17:53:51,447 [INFO] Training: 3839/6852 -- loss: 2.6862950325012207\n",
      "2021-04-25 17:53:51,495 [INFO] Training: 3840/6852 -- loss: 1.4234092235565186\n",
      "2021-04-25 17:53:51,549 [INFO] Training: 3841/6852 -- loss: 2.4776089191436768\n",
      "2021-04-25 17:53:51,597 [INFO] Training: 3842/6852 -- loss: 2.401712656021118\n",
      "2021-04-25 17:53:51,644 [INFO] Training: 3843/6852 -- loss: 2.69041109085083\n",
      "2021-04-25 17:53:51,692 [INFO] Training: 3844/6852 -- loss: 1.8481703996658325\n",
      "2021-04-25 17:53:51,741 [INFO] Training: 3845/6852 -- loss: 2.32316517829895\n",
      "2021-04-25 17:53:51,790 [INFO] Training: 3846/6852 -- loss: 1.787061333656311\n",
      "2021-04-25 17:53:51,839 [INFO] Training: 3847/6852 -- loss: 1.4055534601211548\n",
      "2021-04-25 17:53:51,892 [INFO] Training: 3848/6852 -- loss: 3.128945827484131\n",
      "2021-04-25 17:53:51,940 [INFO] Training: 3849/6852 -- loss: 1.6274694204330444\n",
      "2021-04-25 17:53:51,994 [INFO] Training: 3850/6852 -- loss: 1.9630703926086426\n",
      "2021-04-25 17:53:52,046 [INFO] Training: 3851/6852 -- loss: 3.0966055393218994\n",
      "2021-04-25 17:53:52,093 [INFO] Training: 3852/6852 -- loss: 1.6158791780471802\n",
      "2021-04-25 17:53:52,142 [INFO] Training: 3853/6852 -- loss: 2.8588547706604004\n",
      "2021-04-25 17:53:52,191 [INFO] Training: 3854/6852 -- loss: 2.1090290546417236\n",
      "2021-04-25 17:53:52,240 [INFO] Training: 3855/6852 -- loss: 2.1669728755950928\n",
      "2021-04-25 17:53:52,290 [INFO] Training: 3856/6852 -- loss: 2.449089527130127\n",
      "2021-04-25 17:53:52,338 [INFO] Training: 3857/6852 -- loss: 1.6657437086105347\n",
      "2021-04-25 17:53:52,390 [INFO] Training: 3858/6852 -- loss: 1.5853723287582397\n",
      "2021-04-25 17:53:52,440 [INFO] Training: 3859/6852 -- loss: 2.0829436779022217\n",
      "2021-04-25 17:53:52,487 [INFO] Training: 3860/6852 -- loss: 1.8514947891235352\n",
      "2021-04-25 17:53:52,535 [INFO] Training: 3861/6852 -- loss: 1.5187318325042725\n",
      "2021-04-25 17:53:52,585 [INFO] Training: 3862/6852 -- loss: 2.0972273349761963\n",
      "2021-04-25 17:53:52,637 [INFO] Training: 3863/6852 -- loss: 1.6228752136230469\n",
      "2021-04-25 17:53:52,683 [INFO] Training: 3864/6852 -- loss: 1.642132043838501\n",
      "2021-04-25 17:53:52,735 [INFO] Training: 3865/6852 -- loss: 2.8947689533233643\n",
      "2021-04-25 17:53:52,784 [INFO] Training: 3866/6852 -- loss: 1.6106767654418945\n",
      "2021-04-25 17:53:52,830 [INFO] Training: 3867/6852 -- loss: 2.1620242595672607\n",
      "2021-04-25 17:53:52,880 [INFO] Training: 3868/6852 -- loss: 2.6976261138916016\n",
      "2021-04-25 17:53:52,930 [INFO] Training: 3869/6852 -- loss: 1.9003065824508667\n",
      "2021-04-25 17:53:52,979 [INFO] Training: 3870/6852 -- loss: 1.3832359313964844\n",
      "2021-04-25 17:53:53,026 [INFO] Training: 3871/6852 -- loss: 2.34694766998291\n",
      "2021-04-25 17:53:53,074 [INFO] Training: 3872/6852 -- loss: 1.6931370496749878\n",
      "2021-04-25 17:53:53,128 [INFO] Training: 3873/6852 -- loss: 2.417849540710449\n",
      "2021-04-25 17:53:53,175 [INFO] Training: 3874/6852 -- loss: 2.929706335067749\n",
      "2021-04-25 17:53:53,224 [INFO] Training: 3875/6852 -- loss: 2.705566883087158\n",
      "2021-04-25 17:53:53,275 [INFO] Training: 3876/6852 -- loss: 2.820845127105713\n",
      "2021-04-25 17:53:53,321 [INFO] Training: 3877/6852 -- loss: 2.4994778633117676\n",
      "2021-04-25 17:53:53,372 [INFO] Training: 3878/6852 -- loss: 2.5683674812316895\n",
      "2021-04-25 17:53:53,424 [INFO] Training: 3879/6852 -- loss: 2.351123332977295\n",
      "2021-04-25 17:53:53,473 [INFO] Training: 3880/6852 -- loss: 2.527682065963745\n",
      "2021-04-25 17:53:53,521 [INFO] Training: 3881/6852 -- loss: 1.869728922843933\n",
      "2021-04-25 17:53:53,570 [INFO] Training: 3882/6852 -- loss: 3.2434706687927246\n",
      "2021-04-25 17:53:53,619 [INFO] Training: 3883/6852 -- loss: 1.8409976959228516\n",
      "2021-04-25 17:53:53,670 [INFO] Training: 3884/6852 -- loss: 2.0301387310028076\n",
      "2021-04-25 17:53:53,718 [INFO] Training: 3885/6852 -- loss: 1.9110313653945923\n",
      "2021-04-25 17:53:53,765 [INFO] Training: 3886/6852 -- loss: 1.423003077507019\n",
      "2021-04-25 17:53:53,814 [INFO] Training: 3887/6852 -- loss: 1.7857698202133179\n",
      "2021-04-25 17:53:53,863 [INFO] Training: 3888/6852 -- loss: 1.9673328399658203\n",
      "2021-04-25 17:53:53,909 [INFO] Training: 3889/6852 -- loss: 1.6471760272979736\n",
      "2021-04-25 17:53:53,957 [INFO] Training: 3890/6852 -- loss: 1.917286992073059\n",
      "2021-04-25 17:53:54,006 [INFO] Training: 3891/6852 -- loss: 2.42515230178833\n",
      "2021-04-25 17:53:54,056 [INFO] Training: 3892/6852 -- loss: 2.2676830291748047\n",
      "2021-04-25 17:53:54,106 [INFO] Training: 3893/6852 -- loss: 1.5283738374710083\n",
      "2021-04-25 17:53:54,154 [INFO] Training: 3894/6852 -- loss: 2.9384379386901855\n",
      "2021-04-25 17:53:54,206 [INFO] Training: 3895/6852 -- loss: 2.212388277053833\n",
      "2021-04-25 17:53:54,254 [INFO] Training: 3896/6852 -- loss: 2.8854708671569824\n",
      "2021-04-25 17:53:54,304 [INFO] Training: 3897/6852 -- loss: 3.396251916885376\n",
      "2021-04-25 17:53:54,351 [INFO] Training: 3898/6852 -- loss: 1.8959543704986572\n",
      "2021-04-25 17:53:54,403 [INFO] Training: 3899/6852 -- loss: 2.8992154598236084\n",
      "2021-04-25 17:53:54,452 [INFO] Training: 3900/6852 -- loss: 2.2376015186309814\n",
      "2021-04-25 17:53:57,293 [INFO] Training: iteration: 3900/6852 -- epoch: 6 --  train_loss: 2.214 -- train_accuracy: 0.25 valid_loss: 3.070 -- valid_accuracy: 0.30\n",
      "2021-04-25 17:53:57,329 [INFO] Training: 3901/6852 -- loss: 2.180331230163574\n",
      "2021-04-25 17:53:57,377 [INFO] Training: 3902/6852 -- loss: 2.310060501098633\n",
      "2021-04-25 17:53:57,423 [INFO] Training: 3903/6852 -- loss: 1.7317955493927002\n",
      "2021-04-25 17:53:57,472 [INFO] Training: 3904/6852 -- loss: 3.233726978302002\n",
      "2021-04-25 17:53:57,522 [INFO] Training: 3905/6852 -- loss: 2.4797401428222656\n",
      "2021-04-25 17:53:57,570 [INFO] Training: 3906/6852 -- loss: 2.6244821548461914\n",
      "2021-04-25 17:53:57,618 [INFO] Training: 3907/6852 -- loss: 1.7674671411514282\n",
      "2021-04-25 17:53:57,665 [INFO] Training: 3908/6852 -- loss: 2.1106414794921875\n",
      "2021-04-25 17:53:57,713 [INFO] Training: 3909/6852 -- loss: 2.9532248973846436\n",
      "2021-04-25 17:53:57,763 [INFO] Training: 3910/6852 -- loss: 3.25887131690979\n",
      "2021-04-25 17:53:57,812 [INFO] Training: 3911/6852 -- loss: 2.073442220687866\n",
      "2021-04-25 17:53:57,861 [INFO] Training: 3912/6852 -- loss: 2.7026443481445312\n",
      "2021-04-25 17:53:57,909 [INFO] Training: 3913/6852 -- loss: 2.2085022926330566\n",
      "2021-04-25 17:53:57,963 [INFO] Training: 3914/6852 -- loss: 2.6634504795074463\n",
      "2021-04-25 17:53:58,012 [INFO] Training: 3915/6852 -- loss: 1.4974020719528198\n",
      "2021-04-25 17:53:58,060 [INFO] Training: 3916/6852 -- loss: 1.7844147682189941\n",
      "2021-04-25 17:53:58,108 [INFO] Training: 3917/6852 -- loss: 2.260467529296875\n",
      "2021-04-25 17:53:58,156 [INFO] Training: 3918/6852 -- loss: 1.757946491241455\n",
      "2021-04-25 17:53:58,210 [INFO] Training: 3919/6852 -- loss: 2.044896125793457\n",
      "2021-04-25 17:53:58,258 [INFO] Training: 3920/6852 -- loss: 2.4937872886657715\n",
      "2021-04-25 17:53:58,309 [INFO] Training: 3921/6852 -- loss: 2.451087474822998\n",
      "2021-04-25 17:53:58,357 [INFO] Training: 3922/6852 -- loss: 1.6365736722946167\n",
      "2021-04-25 17:53:58,410 [INFO] Training: 3923/6852 -- loss: 2.2125723361968994\n",
      "2021-04-25 17:53:58,460 [INFO] Training: 3924/6852 -- loss: 1.4871771335601807\n",
      "2021-04-25 17:53:58,511 [INFO] Training: 3925/6852 -- loss: 2.1069374084472656\n",
      "2021-04-25 17:53:58,561 [INFO] Training: 3926/6852 -- loss: 3.192326784133911\n",
      "2021-04-25 17:53:58,609 [INFO] Training: 3927/6852 -- loss: 2.6752359867095947\n",
      "2021-04-25 17:53:58,659 [INFO] Training: 3928/6852 -- loss: 2.882350206375122\n",
      "2021-04-25 17:53:58,707 [INFO] Training: 3929/6852 -- loss: 2.1453351974487305\n",
      "2021-04-25 17:53:58,755 [INFO] Training: 3930/6852 -- loss: 2.3531315326690674\n",
      "2021-04-25 17:53:58,807 [INFO] Training: 3931/6852 -- loss: 1.3923505544662476\n",
      "2021-04-25 17:53:58,854 [INFO] Training: 3932/6852 -- loss: 1.561667799949646\n",
      "2021-04-25 17:53:58,902 [INFO] Training: 3933/6852 -- loss: 2.7100090980529785\n",
      "2021-04-25 17:53:58,950 [INFO] Training: 3934/6852 -- loss: 2.095162868499756\n",
      "2021-04-25 17:53:58,998 [INFO] Training: 3935/6852 -- loss: 2.4656894207000732\n",
      "2021-04-25 17:53:59,045 [INFO] Training: 3936/6852 -- loss: 3.651341676712036\n",
      "2021-04-25 17:53:59,099 [INFO] Training: 3937/6852 -- loss: 2.9563186168670654\n",
      "2021-04-25 17:53:59,146 [INFO] Training: 3938/6852 -- loss: 2.834909200668335\n",
      "2021-04-25 17:53:59,194 [INFO] Training: 3939/6852 -- loss: 2.526313066482544\n",
      "2021-04-25 17:53:59,244 [INFO] Training: 3940/6852 -- loss: 1.6020313501358032\n",
      "2021-04-25 17:53:59,291 [INFO] Training: 3941/6852 -- loss: 1.8609554767608643\n",
      "2021-04-25 17:53:59,340 [INFO] Training: 3942/6852 -- loss: 1.767347812652588\n",
      "2021-04-25 17:53:59,387 [INFO] Training: 3943/6852 -- loss: 3.906412363052368\n",
      "2021-04-25 17:53:59,436 [INFO] Training: 3944/6852 -- loss: 3.0820512771606445\n",
      "2021-04-25 17:53:59,486 [INFO] Training: 3945/6852 -- loss: 2.0506129264831543\n",
      "2021-04-25 17:53:59,532 [INFO] Training: 3946/6852 -- loss: 2.4126534461975098\n",
      "2021-04-25 17:53:59,580 [INFO] Training: 3947/6852 -- loss: 1.8965541124343872\n",
      "2021-04-25 17:53:59,629 [INFO] Training: 3948/6852 -- loss: 1.9637997150421143\n",
      "2021-04-25 17:53:59,677 [INFO] Training: 3949/6852 -- loss: 2.5382931232452393\n",
      "2021-04-25 17:53:59,727 [INFO] Training: 3950/6852 -- loss: 3.0092217922210693\n",
      "2021-04-25 17:53:59,776 [INFO] Training: 3951/6852 -- loss: 2.352703332901001\n",
      "2021-04-25 17:53:59,823 [INFO] Training: 3952/6852 -- loss: 1.8265281915664673\n",
      "2021-04-25 17:53:59,872 [INFO] Training: 3953/6852 -- loss: 2.164546489715576\n",
      "2021-04-25 17:53:59,920 [INFO] Training: 3954/6852 -- loss: 1.2664134502410889\n",
      "2021-04-25 17:53:59,969 [INFO] Training: 3955/6852 -- loss: 1.527071475982666\n",
      "2021-04-25 17:54:00,016 [INFO] Training: 3956/6852 -- loss: 1.7707068920135498\n",
      "2021-04-25 17:54:00,064 [INFO] Training: 3957/6852 -- loss: 1.378494143486023\n",
      "2021-04-25 17:54:00,113 [INFO] Training: 3958/6852 -- loss: 2.3321666717529297\n",
      "2021-04-25 17:54:00,161 [INFO] Training: 3959/6852 -- loss: 2.5728492736816406\n",
      "2021-04-25 17:54:00,209 [INFO] Training: 3960/6852 -- loss: 2.1620121002197266\n",
      "2021-04-25 17:54:00,259 [INFO] Training: 3961/6852 -- loss: 1.1539020538330078\n",
      "2021-04-25 17:54:00,305 [INFO] Training: 3962/6852 -- loss: 1.8330631256103516\n",
      "2021-04-25 17:54:00,353 [INFO] Training: 3963/6852 -- loss: 2.2196898460388184\n",
      "2021-04-25 17:54:00,401 [INFO] Training: 3964/6852 -- loss: 2.3819186687469482\n",
      "2021-04-25 17:54:00,447 [INFO] Training: 3965/6852 -- loss: 2.2099642753601074\n",
      "2021-04-25 17:54:00,498 [INFO] Training: 3966/6852 -- loss: 2.279836654663086\n",
      "2021-04-25 17:54:00,549 [INFO] Training: 3967/6852 -- loss: 1.839728832244873\n",
      "2021-04-25 17:54:00,599 [INFO] Training: 3968/6852 -- loss: 2.7314062118530273\n",
      "2021-04-25 17:54:00,647 [INFO] Training: 3969/6852 -- loss: 1.722449779510498\n",
      "2021-04-25 17:54:00,697 [INFO] Training: 3970/6852 -- loss: 3.1774797439575195\n",
      "2021-04-25 17:54:00,748 [INFO] Training: 3971/6852 -- loss: 2.017216920852661\n",
      "2021-04-25 17:54:00,796 [INFO] Training: 3972/6852 -- loss: 2.2102978229522705\n",
      "2021-04-25 17:54:00,846 [INFO] Training: 3973/6852 -- loss: 1.8099291324615479\n",
      "2021-04-25 17:54:00,895 [INFO] Training: 3974/6852 -- loss: 2.1850998401641846\n",
      "2021-04-25 17:54:00,946 [INFO] Training: 3975/6852 -- loss: 2.735590696334839\n",
      "2021-04-25 17:54:00,993 [INFO] Training: 3976/6852 -- loss: 3.277143716812134\n",
      "2021-04-25 17:54:01,041 [INFO] Training: 3977/6852 -- loss: 2.270517349243164\n",
      "2021-04-25 17:54:01,089 [INFO] Training: 3978/6852 -- loss: 2.7167699337005615\n",
      "2021-04-25 17:54:01,136 [INFO] Training: 3979/6852 -- loss: 2.3585593700408936\n",
      "2021-04-25 17:54:01,184 [INFO] Training: 3980/6852 -- loss: 2.3580868244171143\n",
      "2021-04-25 17:54:01,232 [INFO] Training: 3981/6852 -- loss: 2.3301613330841064\n",
      "2021-04-25 17:54:01,283 [INFO] Training: 3982/6852 -- loss: 2.354705333709717\n",
      "2021-04-25 17:54:01,331 [INFO] Training: 3983/6852 -- loss: 1.9775242805480957\n",
      "2021-04-25 17:54:01,379 [INFO] Training: 3984/6852 -- loss: 1.6644597053527832\n",
      "2021-04-25 17:54:01,432 [INFO] Training: 3985/6852 -- loss: 2.9420719146728516\n",
      "2021-04-25 17:54:01,481 [INFO] Training: 3986/6852 -- loss: 1.4118105173110962\n",
      "2021-04-25 17:54:01,531 [INFO] Training: 3987/6852 -- loss: 0.9263289570808411\n",
      "2021-04-25 17:54:01,580 [INFO] Training: 3988/6852 -- loss: 2.0368905067443848\n",
      "2021-04-25 17:54:01,629 [INFO] Training: 3989/6852 -- loss: 1.9647706747055054\n",
      "2021-04-25 17:54:01,677 [INFO] Training: 3990/6852 -- loss: 1.673160433769226\n",
      "2021-04-25 17:54:01,726 [INFO] Training: 3991/6852 -- loss: 1.8943239450454712\n",
      "2021-04-25 17:54:01,776 [INFO] Training: 3992/6852 -- loss: 1.8568644523620605\n",
      "2021-04-25 17:54:01,824 [INFO] Training: 3993/6852 -- loss: 3.6135034561157227\n",
      "2021-04-25 17:54:01,873 [INFO] Training: 3994/6852 -- loss: 3.1892895698547363\n",
      "2021-04-25 17:54:01,922 [INFO] Training: 3995/6852 -- loss: 2.4229612350463867\n",
      "2021-04-25 17:54:01,965 [INFO] Training: 3996/6852 -- loss: 1.548377275466919\n",
      "2021-04-25 17:54:02,230 [INFO] Training: 3997/6852 -- loss: 1.7519603967666626\n",
      "2021-04-25 17:54:02,290 [INFO] Training: 3998/6852 -- loss: 1.5102635622024536\n",
      "2021-04-25 17:54:02,342 [INFO] Training: 3999/6852 -- loss: 2.111753225326538\n",
      "2021-04-25 17:54:02,389 [INFO] Training: 4000/6852 -- loss: 1.7183362245559692\n",
      "2021-04-25 17:54:02,439 [INFO] Training: 4001/6852 -- loss: 1.1583516597747803\n",
      "2021-04-25 17:54:02,491 [INFO] Training: 4002/6852 -- loss: 2.614567756652832\n",
      "2021-04-25 17:54:02,540 [INFO] Training: 4003/6852 -- loss: 2.913822650909424\n",
      "2021-04-25 17:54:02,594 [INFO] Training: 4004/6852 -- loss: 1.858506679534912\n",
      "2021-04-25 17:54:02,639 [INFO] Training: 4005/6852 -- loss: 2.045855760574341\n",
      "2021-04-25 17:54:02,691 [INFO] Training: 4006/6852 -- loss: 2.542909622192383\n",
      "2021-04-25 17:54:02,739 [INFO] Training: 4007/6852 -- loss: 1.5297273397445679\n",
      "2021-04-25 17:54:02,790 [INFO] Training: 4008/6852 -- loss: 1.4394848346710205\n",
      "2021-04-25 17:54:02,842 [INFO] Training: 4009/6852 -- loss: 0.8970677256584167\n",
      "2021-04-25 17:54:02,894 [INFO] Training: 4010/6852 -- loss: 2.112117052078247\n",
      "2021-04-25 17:54:02,943 [INFO] Training: 4011/6852 -- loss: 1.8172051906585693\n",
      "2021-04-25 17:54:02,994 [INFO] Training: 4012/6852 -- loss: 1.403421401977539\n",
      "2021-04-25 17:54:03,041 [INFO] Training: 4013/6852 -- loss: 1.9805715084075928\n",
      "2021-04-25 17:54:03,093 [INFO] Training: 4014/6852 -- loss: 0.983834981918335\n",
      "2021-04-25 17:54:03,144 [INFO] Training: 4015/6852 -- loss: 2.2818050384521484\n",
      "2021-04-25 17:54:03,193 [INFO] Training: 4016/6852 -- loss: 2.158411979675293\n",
      "2021-04-25 17:54:03,242 [INFO] Training: 4017/6852 -- loss: 1.628475546836853\n",
      "2021-04-25 17:54:03,291 [INFO] Training: 4018/6852 -- loss: 2.911325454711914\n",
      "2021-04-25 17:54:03,343 [INFO] Training: 4019/6852 -- loss: 1.0125045776367188\n",
      "2021-04-25 17:54:03,392 [INFO] Training: 4020/6852 -- loss: 1.6731858253479004\n",
      "2021-04-25 17:54:03,444 [INFO] Training: 4021/6852 -- loss: 2.0452985763549805\n",
      "2021-04-25 17:54:03,492 [INFO] Training: 4022/6852 -- loss: 2.9965250492095947\n",
      "2021-04-25 17:54:03,542 [INFO] Training: 4023/6852 -- loss: 2.5565149784088135\n",
      "2021-04-25 17:54:03,590 [INFO] Training: 4024/6852 -- loss: 1.2590208053588867\n",
      "2021-04-25 17:54:03,641 [INFO] Training: 4025/6852 -- loss: 2.080395221710205\n",
      "2021-04-25 17:54:03,690 [INFO] Training: 4026/6852 -- loss: 1.8181679248809814\n",
      "2021-04-25 17:54:03,739 [INFO] Training: 4027/6852 -- loss: 1.7330806255340576\n",
      "2021-04-25 17:54:03,792 [INFO] Training: 4028/6852 -- loss: 1.5932469367980957\n",
      "2021-04-25 17:54:03,839 [INFO] Training: 4029/6852 -- loss: 1.6754097938537598\n",
      "2021-04-25 17:54:03,893 [INFO] Training: 4030/6852 -- loss: 1.3680405616760254\n",
      "2021-04-25 17:54:03,946 [INFO] Training: 4031/6852 -- loss: 2.3724024295806885\n",
      "2021-04-25 17:54:03,997 [INFO] Training: 4032/6852 -- loss: 1.9839742183685303\n",
      "2021-04-25 17:54:04,051 [INFO] Training: 4033/6852 -- loss: 2.99859881401062\n",
      "2021-04-25 17:54:04,100 [INFO] Training: 4034/6852 -- loss: 2.1862237453460693\n",
      "2021-04-25 17:54:04,148 [INFO] Training: 4035/6852 -- loss: 2.805701732635498\n",
      "2021-04-25 17:54:04,197 [INFO] Training: 4036/6852 -- loss: 1.4827449321746826\n",
      "2021-04-25 17:54:04,243 [INFO] Training: 4037/6852 -- loss: 3.1935384273529053\n",
      "2021-04-25 17:54:04,297 [INFO] Training: 4038/6852 -- loss: 1.0588903427124023\n",
      "2021-04-25 17:54:04,344 [INFO] Training: 4039/6852 -- loss: 3.5970683097839355\n",
      "2021-04-25 17:54:04,396 [INFO] Training: 4040/6852 -- loss: 1.8628909587860107\n",
      "2021-04-25 17:54:04,448 [INFO] Training: 4041/6852 -- loss: 2.5811376571655273\n",
      "2021-04-25 17:54:04,499 [INFO] Training: 4042/6852 -- loss: 2.546231269836426\n",
      "2021-04-25 17:54:04,547 [INFO] Training: 4043/6852 -- loss: 1.157812237739563\n",
      "2021-04-25 17:54:04,599 [INFO] Training: 4044/6852 -- loss: 1.8184428215026855\n",
      "2021-04-25 17:54:04,648 [INFO] Training: 4045/6852 -- loss: 1.811051368713379\n",
      "2021-04-25 17:54:04,698 [INFO] Training: 4046/6852 -- loss: 1.895466923713684\n",
      "2021-04-25 17:54:04,744 [INFO] Training: 4047/6852 -- loss: 1.9323458671569824\n",
      "2021-04-25 17:54:04,792 [INFO] Training: 4048/6852 -- loss: 1.5259109735488892\n",
      "2021-04-25 17:54:04,844 [INFO] Training: 4049/6852 -- loss: 1.4138753414154053\n",
      "2021-04-25 17:54:04,892 [INFO] Training: 4050/6852 -- loss: 1.3776849508285522\n",
      "2021-04-25 17:54:07,747 [INFO] Training: iteration: 4050/6852 -- epoch: 7 --  train_loss: 2.140 -- train_accuracy: 0.75 valid_loss: 3.109 -- valid_accuracy: 0.30\n",
      "2021-04-25 17:54:07,786 [INFO] Training: 4051/6852 -- loss: 3.379727840423584\n",
      "2021-04-25 17:54:07,842 [INFO] Training: 4052/6852 -- loss: 1.324755311012268\n",
      "2021-04-25 17:54:07,890 [INFO] Training: 4053/6852 -- loss: 0.9894784688949585\n",
      "2021-04-25 17:54:07,938 [INFO] Training: 4054/6852 -- loss: 2.1090569496154785\n",
      "2021-04-25 17:54:07,985 [INFO] Training: 4055/6852 -- loss: 2.404507637023926\n",
      "2021-04-25 17:54:08,034 [INFO] Training: 4056/6852 -- loss: 1.6072183847427368\n",
      "2021-04-25 17:54:08,083 [INFO] Training: 4057/6852 -- loss: 3.6342875957489014\n",
      "2021-04-25 17:54:08,135 [INFO] Training: 4058/6852 -- loss: 1.4094449281692505\n",
      "2021-04-25 17:54:08,184 [INFO] Training: 4059/6852 -- loss: 2.1740379333496094\n",
      "2021-04-25 17:54:08,235 [INFO] Training: 4060/6852 -- loss: 2.0677711963653564\n",
      "2021-04-25 17:54:08,282 [INFO] Training: 4061/6852 -- loss: 2.30975341796875\n",
      "2021-04-25 17:54:08,332 [INFO] Training: 4062/6852 -- loss: 1.8338167667388916\n",
      "2021-04-25 17:54:08,383 [INFO] Training: 4063/6852 -- loss: 1.8931372165679932\n",
      "2021-04-25 17:54:08,430 [INFO] Training: 4064/6852 -- loss: 3.680920362472534\n",
      "2021-04-25 17:54:08,480 [INFO] Training: 4065/6852 -- loss: 1.9539729356765747\n",
      "2021-04-25 17:54:08,527 [INFO] Training: 4066/6852 -- loss: 3.9496755599975586\n",
      "2021-04-25 17:54:08,575 [INFO] Training: 4067/6852 -- loss: 1.5519134998321533\n",
      "2021-04-25 17:54:08,627 [INFO] Training: 4068/6852 -- loss: 2.2273659706115723\n",
      "2021-04-25 17:54:08,677 [INFO] Training: 4069/6852 -- loss: 1.88948392868042\n",
      "2021-04-25 17:54:08,729 [INFO] Training: 4070/6852 -- loss: 3.1274986267089844\n",
      "2021-04-25 17:54:08,781 [INFO] Training: 4071/6852 -- loss: 2.3861682415008545\n",
      "2021-04-25 17:54:08,831 [INFO] Training: 4072/6852 -- loss: 1.90186607837677\n",
      "2021-04-25 17:54:08,877 [INFO] Training: 4073/6852 -- loss: 2.7186899185180664\n",
      "2021-04-25 17:54:08,927 [INFO] Training: 4074/6852 -- loss: 1.6588237285614014\n",
      "2021-04-25 17:54:08,973 [INFO] Training: 4075/6852 -- loss: 1.665748953819275\n",
      "2021-04-25 17:54:09,020 [INFO] Training: 4076/6852 -- loss: 2.0899062156677246\n",
      "2021-04-25 17:54:09,070 [INFO] Training: 4077/6852 -- loss: 2.823819637298584\n",
      "2021-04-25 17:54:09,117 [INFO] Training: 4078/6852 -- loss: 1.3982799053192139\n",
      "2021-04-25 17:54:09,166 [INFO] Training: 4079/6852 -- loss: 2.7113418579101562\n",
      "2021-04-25 17:54:09,216 [INFO] Training: 4080/6852 -- loss: 1.8341501951217651\n",
      "2021-04-25 17:54:09,263 [INFO] Training: 4081/6852 -- loss: 2.1193437576293945\n",
      "2021-04-25 17:54:09,312 [INFO] Training: 4082/6852 -- loss: 1.76383376121521\n",
      "2021-04-25 17:54:09,360 [INFO] Training: 4083/6852 -- loss: 1.183813452720642\n",
      "2021-04-25 17:54:09,410 [INFO] Training: 4084/6852 -- loss: 1.8125677108764648\n",
      "2021-04-25 17:54:09,458 [INFO] Training: 4085/6852 -- loss: 2.5008902549743652\n",
      "2021-04-25 17:54:09,510 [INFO] Training: 4086/6852 -- loss: 2.7955517768859863\n",
      "2021-04-25 17:54:09,561 [INFO] Training: 4087/6852 -- loss: 1.9244149923324585\n",
      "2021-04-25 17:54:09,608 [INFO] Training: 4088/6852 -- loss: 1.6185309886932373\n",
      "2021-04-25 17:54:09,656 [INFO] Training: 4089/6852 -- loss: 2.125173330307007\n",
      "2021-04-25 17:54:09,705 [INFO] Training: 4090/6852 -- loss: 2.521998882293701\n",
      "2021-04-25 17:54:09,757 [INFO] Training: 4091/6852 -- loss: 2.2713723182678223\n",
      "2021-04-25 17:54:09,803 [INFO] Training: 4092/6852 -- loss: 2.3464059829711914\n",
      "2021-04-25 17:54:09,851 [INFO] Training: 4093/6852 -- loss: 2.1108689308166504\n",
      "2021-04-25 17:54:09,900 [INFO] Training: 4094/6852 -- loss: 1.925025224685669\n",
      "2021-04-25 17:54:09,952 [INFO] Training: 4095/6852 -- loss: 2.135892152786255\n",
      "2021-04-25 17:54:10,006 [INFO] Training: 4096/6852 -- loss: 2.4048757553100586\n",
      "2021-04-25 17:54:10,054 [INFO] Training: 4097/6852 -- loss: 1.9317584037780762\n",
      "2021-04-25 17:54:10,103 [INFO] Training: 4098/6852 -- loss: 1.6983258724212646\n",
      "2021-04-25 17:54:10,150 [INFO] Training: 4099/6852 -- loss: 1.6819255352020264\n",
      "2021-04-25 17:54:10,199 [INFO] Training: 4100/6852 -- loss: 3.149454355239868\n",
      "2021-04-25 17:54:10,253 [INFO] Training: 4101/6852 -- loss: 2.7990949153900146\n",
      "2021-04-25 17:54:10,303 [INFO] Training: 4102/6852 -- loss: 1.9651654958724976\n",
      "2021-04-25 17:54:10,355 [INFO] Training: 4103/6852 -- loss: 1.9378821849822998\n",
      "2021-04-25 17:54:10,403 [INFO] Training: 4104/6852 -- loss: 1.8321998119354248\n",
      "2021-04-25 17:54:10,453 [INFO] Training: 4105/6852 -- loss: 2.491586923599243\n",
      "2021-04-25 17:54:10,503 [INFO] Training: 4106/6852 -- loss: 2.347444772720337\n",
      "2021-04-25 17:54:10,551 [INFO] Training: 4107/6852 -- loss: 1.702116847038269\n",
      "2021-04-25 17:54:10,598 [INFO] Training: 4108/6852 -- loss: 1.8307108879089355\n",
      "2021-04-25 17:54:10,646 [INFO] Training: 4109/6852 -- loss: 1.6151981353759766\n",
      "2021-04-25 17:54:10,699 [INFO] Training: 4110/6852 -- loss: 2.2664318084716797\n",
      "2021-04-25 17:54:10,751 [INFO] Training: 4111/6852 -- loss: 1.2176638841629028\n",
      "2021-04-25 17:54:10,803 [INFO] Training: 4112/6852 -- loss: 2.2462213039398193\n",
      "2021-04-25 17:54:10,853 [INFO] Training: 4113/6852 -- loss: 2.5980887413024902\n",
      "2021-04-25 17:54:10,903 [INFO] Training: 4114/6852 -- loss: 2.236271858215332\n",
      "2021-04-25 17:54:10,951 [INFO] Training: 4115/6852 -- loss: 1.8105615377426147\n",
      "2021-04-25 17:54:10,998 [INFO] Training: 4116/6852 -- loss: 1.9781116247177124\n",
      "2021-04-25 17:54:11,045 [INFO] Training: 4117/6852 -- loss: 1.912780523300171\n",
      "2021-04-25 17:54:11,093 [INFO] Training: 4118/6852 -- loss: 2.3623924255371094\n",
      "2021-04-25 17:54:11,143 [INFO] Training: 4119/6852 -- loss: 2.392629861831665\n",
      "2021-04-25 17:54:11,192 [INFO] Training: 4120/6852 -- loss: 1.7302839756011963\n",
      "2021-04-25 17:54:11,241 [INFO] Training: 4121/6852 -- loss: 2.383910655975342\n",
      "2021-04-25 17:54:11,290 [INFO] Training: 4122/6852 -- loss: 1.7662546634674072\n",
      "2021-04-25 17:54:11,342 [INFO] Training: 4123/6852 -- loss: 2.553628444671631\n",
      "2021-04-25 17:54:11,393 [INFO] Training: 4124/6852 -- loss: 2.172114133834839\n",
      "2021-04-25 17:54:11,445 [INFO] Training: 4125/6852 -- loss: 2.5433897972106934\n",
      "2021-04-25 17:54:11,494 [INFO] Training: 4126/6852 -- loss: 1.5616264343261719\n",
      "2021-04-25 17:54:11,546 [INFO] Training: 4127/6852 -- loss: 3.0819244384765625\n",
      "2021-04-25 17:54:11,596 [INFO] Training: 4128/6852 -- loss: 2.2072324752807617\n",
      "2021-04-25 17:54:11,645 [INFO] Training: 4129/6852 -- loss: 2.1783289909362793\n",
      "2021-04-25 17:54:11,700 [INFO] Training: 4130/6852 -- loss: 2.9771766662597656\n",
      "2021-04-25 17:54:11,747 [INFO] Training: 4131/6852 -- loss: 1.8118436336517334\n",
      "2021-04-25 17:54:11,796 [INFO] Training: 4132/6852 -- loss: 2.2584633827209473\n",
      "2021-04-25 17:54:11,847 [INFO] Training: 4133/6852 -- loss: 1.6485968828201294\n",
      "2021-04-25 17:54:11,897 [INFO] Training: 4134/6852 -- loss: 0.9458179473876953\n",
      "2021-04-25 17:54:11,945 [INFO] Training: 4135/6852 -- loss: 2.1547727584838867\n",
      "2021-04-25 17:54:11,993 [INFO] Training: 4136/6852 -- loss: 1.9810340404510498\n",
      "2021-04-25 17:54:12,041 [INFO] Training: 4137/6852 -- loss: 2.124584674835205\n",
      "2021-04-25 17:54:12,094 [INFO] Training: 4138/6852 -- loss: 2.263781785964966\n",
      "2021-04-25 17:54:12,141 [INFO] Training: 4139/6852 -- loss: 1.8500638008117676\n",
      "2021-04-25 17:54:12,192 [INFO] Training: 4140/6852 -- loss: 2.6519410610198975\n",
      "2021-04-25 17:54:12,240 [INFO] Training: 4141/6852 -- loss: 1.670939326286316\n",
      "2021-04-25 17:54:12,288 [INFO] Training: 4142/6852 -- loss: 2.0763611793518066\n",
      "2021-04-25 17:54:12,336 [INFO] Training: 4143/6852 -- loss: 1.7665871381759644\n",
      "2021-04-25 17:54:12,384 [INFO] Training: 4144/6852 -- loss: 2.3310368061065674\n",
      "2021-04-25 17:54:12,434 [INFO] Training: 4145/6852 -- loss: 1.9186296463012695\n",
      "2021-04-25 17:54:12,484 [INFO] Training: 4146/6852 -- loss: 0.9626910090446472\n",
      "2021-04-25 17:54:12,532 [INFO] Training: 4147/6852 -- loss: 2.6449642181396484\n",
      "2021-04-25 17:54:12,585 [INFO] Training: 4148/6852 -- loss: 2.5218701362609863\n",
      "2021-04-25 17:54:12,636 [INFO] Training: 4149/6852 -- loss: 1.4912911653518677\n",
      "2021-04-25 17:54:12,684 [INFO] Training: 4150/6852 -- loss: 2.0219695568084717\n",
      "2021-04-25 17:54:12,738 [INFO] Training: 4151/6852 -- loss: 2.337911605834961\n",
      "2021-04-25 17:54:12,784 [INFO] Training: 4152/6852 -- loss: 2.457002639770508\n",
      "2021-04-25 17:54:12,834 [INFO] Training: 4153/6852 -- loss: 1.3612929582595825\n",
      "2021-04-25 17:54:12,887 [INFO] Training: 4154/6852 -- loss: 1.189749002456665\n",
      "2021-04-25 17:54:12,937 [INFO] Training: 4155/6852 -- loss: 1.9967012405395508\n",
      "2021-04-25 17:54:12,987 [INFO] Training: 4156/6852 -- loss: 1.616131067276001\n",
      "2021-04-25 17:54:13,037 [INFO] Training: 4157/6852 -- loss: 1.8245823383331299\n",
      "2021-04-25 17:54:13,089 [INFO] Training: 4158/6852 -- loss: 0.9864336848258972\n",
      "2021-04-25 17:54:13,139 [INFO] Training: 4159/6852 -- loss: 2.5845227241516113\n",
      "2021-04-25 17:54:13,190 [INFO] Training: 4160/6852 -- loss: 1.6242151260375977\n",
      "2021-04-25 17:54:13,242 [INFO] Training: 4161/6852 -- loss: 2.7701144218444824\n",
      "2021-04-25 17:54:13,292 [INFO] Training: 4162/6852 -- loss: 0.8414008617401123\n",
      "2021-04-25 17:54:13,344 [INFO] Training: 4163/6852 -- loss: 1.5864176750183105\n",
      "2021-04-25 17:54:13,395 [INFO] Training: 4164/6852 -- loss: 1.592748999595642\n",
      "2021-04-25 17:54:13,447 [INFO] Training: 4165/6852 -- loss: 1.8753546476364136\n",
      "2021-04-25 17:54:13,497 [INFO] Training: 4166/6852 -- loss: 1.0497080087661743\n",
      "2021-04-25 17:54:13,547 [INFO] Training: 4167/6852 -- loss: 3.0629618167877197\n",
      "2021-04-25 17:54:13,596 [INFO] Training: 4168/6852 -- loss: 1.5307395458221436\n",
      "2021-04-25 17:54:13,647 [INFO] Training: 4169/6852 -- loss: 2.434330463409424\n",
      "2021-04-25 17:54:13,697 [INFO] Training: 4170/6852 -- loss: 2.8192648887634277\n",
      "2021-04-25 17:54:13,744 [INFO] Training: 4171/6852 -- loss: 2.5506129264831543\n",
      "2021-04-25 17:54:13,792 [INFO] Training: 4172/6852 -- loss: 1.5061874389648438\n",
      "2021-04-25 17:54:13,840 [INFO] Training: 4173/6852 -- loss: 3.4340474605560303\n",
      "2021-04-25 17:54:13,886 [INFO] Training: 4174/6852 -- loss: 1.3643906116485596\n",
      "2021-04-25 17:54:13,934 [INFO] Training: 4175/6852 -- loss: 3.2616546154022217\n",
      "2021-04-25 17:54:13,983 [INFO] Training: 4176/6852 -- loss: 2.6179914474487305\n",
      "2021-04-25 17:54:14,031 [INFO] Training: 4177/6852 -- loss: 1.8628171682357788\n",
      "2021-04-25 17:54:14,083 [INFO] Training: 4178/6852 -- loss: 1.574154019355774\n",
      "2021-04-25 17:54:14,131 [INFO] Training: 4179/6852 -- loss: 2.0425379276275635\n",
      "2021-04-25 17:54:14,179 [INFO] Training: 4180/6852 -- loss: 1.5670043230056763\n",
      "2021-04-25 17:54:14,227 [INFO] Training: 4181/6852 -- loss: 2.313523292541504\n",
      "2021-04-25 17:54:14,274 [INFO] Training: 4182/6852 -- loss: 2.8040430545806885\n",
      "2021-04-25 17:54:14,325 [INFO] Training: 4183/6852 -- loss: 1.5784122943878174\n",
      "2021-04-25 17:54:14,377 [INFO] Training: 4184/6852 -- loss: 2.400928020477295\n",
      "2021-04-25 17:54:14,427 [INFO] Training: 4185/6852 -- loss: 2.765608310699463\n",
      "2021-04-25 17:54:14,473 [INFO] Training: 4186/6852 -- loss: 2.609584093093872\n",
      "2021-04-25 17:54:14,523 [INFO] Training: 4187/6852 -- loss: 2.7659311294555664\n",
      "2021-04-25 17:54:14,571 [INFO] Training: 4188/6852 -- loss: 3.6317903995513916\n",
      "2021-04-25 17:54:14,620 [INFO] Training: 4189/6852 -- loss: 3.1195783615112305\n",
      "2021-04-25 17:54:14,669 [INFO] Training: 4190/6852 -- loss: 2.6613144874572754\n",
      "2021-04-25 17:54:14,717 [INFO] Training: 4191/6852 -- loss: 2.2195372581481934\n",
      "2021-04-25 17:54:14,765 [INFO] Training: 4192/6852 -- loss: 1.7202086448669434\n",
      "2021-04-25 17:54:14,814 [INFO] Training: 4193/6852 -- loss: 2.401190757751465\n",
      "2021-04-25 17:54:14,861 [INFO] Training: 4194/6852 -- loss: 2.7020492553710938\n",
      "2021-04-25 17:54:14,912 [INFO] Training: 4195/6852 -- loss: 3.430760145187378\n",
      "2021-04-25 17:54:14,959 [INFO] Training: 4196/6852 -- loss: 1.3384859561920166\n",
      "2021-04-25 17:54:15,006 [INFO] Training: 4197/6852 -- loss: 1.7749685049057007\n",
      "2021-04-25 17:54:15,057 [INFO] Training: 4198/6852 -- loss: 2.7748494148254395\n",
      "2021-04-25 17:54:15,107 [INFO] Training: 4199/6852 -- loss: 2.712742567062378\n",
      "2021-04-25 17:54:15,161 [INFO] Training: 4200/6852 -- loss: 2.5623574256896973\n",
      "2021-04-25 17:54:18,001 [INFO] Training: iteration: 4200/6852 -- epoch: 7 --  train_loss: 2.148 -- train_accuracy: 0.25 valid_loss: 3.111 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:54:18,048 [INFO] Training: 4201/6852 -- loss: 1.666407585144043\n",
      "2021-04-25 17:54:18,095 [INFO] Training: 4202/6852 -- loss: 2.635399341583252\n",
      "2021-04-25 17:54:18,147 [INFO] Training: 4203/6852 -- loss: 2.3603696823120117\n",
      "2021-04-25 17:54:18,193 [INFO] Training: 4204/6852 -- loss: 2.2407569885253906\n",
      "2021-04-25 17:54:18,243 [INFO] Training: 4205/6852 -- loss: 1.6804347038269043\n",
      "2021-04-25 17:54:18,291 [INFO] Training: 4206/6852 -- loss: 2.8366785049438477\n",
      "2021-04-25 17:54:18,344 [INFO] Training: 4207/6852 -- loss: 2.4441068172454834\n",
      "2021-04-25 17:54:18,394 [INFO] Training: 4208/6852 -- loss: 1.9416824579238892\n",
      "2021-04-25 17:54:18,442 [INFO] Training: 4209/6852 -- loss: 1.247883677482605\n",
      "2021-04-25 17:54:18,495 [INFO] Training: 4210/6852 -- loss: 1.594666838645935\n",
      "2021-04-25 17:54:18,543 [INFO] Training: 4211/6852 -- loss: 3.3277647495269775\n",
      "2021-04-25 17:54:18,592 [INFO] Training: 4212/6852 -- loss: 1.7309637069702148\n",
      "2021-04-25 17:54:18,640 [INFO] Training: 4213/6852 -- loss: 2.4843485355377197\n",
      "2021-04-25 17:54:18,689 [INFO] Training: 4214/6852 -- loss: 2.288090229034424\n",
      "2021-04-25 17:54:18,739 [INFO] Training: 4215/6852 -- loss: 2.2851364612579346\n",
      "2021-04-25 17:54:18,793 [INFO] Training: 4216/6852 -- loss: 1.3873800039291382\n",
      "2021-04-25 17:54:18,842 [INFO] Training: 4217/6852 -- loss: 1.564011573791504\n",
      "2021-04-25 17:54:18,892 [INFO] Training: 4218/6852 -- loss: 3.458489418029785\n",
      "2021-04-25 17:54:18,940 [INFO] Training: 4219/6852 -- loss: 1.9490771293640137\n",
      "2021-04-25 17:54:18,989 [INFO] Training: 4220/6852 -- loss: 1.7604947090148926\n",
      "2021-04-25 17:54:19,039 [INFO] Training: 4221/6852 -- loss: 2.3530001640319824\n",
      "2021-04-25 17:54:19,085 [INFO] Training: 4222/6852 -- loss: 1.8801758289337158\n",
      "2021-04-25 17:54:19,136 [INFO] Training: 4223/6852 -- loss: 2.3485677242279053\n",
      "2021-04-25 17:54:19,186 [INFO] Training: 4224/6852 -- loss: 2.143155813217163\n",
      "2021-04-25 17:54:19,237 [INFO] Training: 4225/6852 -- loss: 3.0997657775878906\n",
      "2021-04-25 17:54:19,290 [INFO] Training: 4226/6852 -- loss: 1.4084855318069458\n",
      "2021-04-25 17:54:19,342 [INFO] Training: 4227/6852 -- loss: 1.6292946338653564\n",
      "2021-04-25 17:54:19,388 [INFO] Training: 4228/6852 -- loss: 1.2981711626052856\n",
      "2021-04-25 17:54:19,441 [INFO] Training: 4229/6852 -- loss: 2.0573158264160156\n",
      "2021-04-25 17:54:19,489 [INFO] Training: 4230/6852 -- loss: 3.1138007640838623\n",
      "2021-04-25 17:54:19,539 [INFO] Training: 4231/6852 -- loss: 2.0875935554504395\n",
      "2021-04-25 17:54:19,587 [INFO] Training: 4232/6852 -- loss: 2.6945009231567383\n",
      "2021-04-25 17:54:19,634 [INFO] Training: 4233/6852 -- loss: 1.4706875085830688\n",
      "2021-04-25 17:54:19,685 [INFO] Training: 4234/6852 -- loss: 2.4912290573120117\n",
      "2021-04-25 17:54:19,737 [INFO] Training: 4235/6852 -- loss: 2.860743284225464\n",
      "2021-04-25 17:54:19,787 [INFO] Training: 4236/6852 -- loss: 2.4512786865234375\n",
      "2021-04-25 17:54:19,836 [INFO] Training: 4237/6852 -- loss: 1.6053690910339355\n",
      "2021-04-25 17:54:19,890 [INFO] Training: 4238/6852 -- loss: 1.7091408967971802\n",
      "2021-04-25 17:54:19,938 [INFO] Training: 4239/6852 -- loss: 3.0192971229553223\n",
      "2021-04-25 17:54:19,985 [INFO] Training: 4240/6852 -- loss: 1.8102766275405884\n",
      "2021-04-25 17:54:20,037 [INFO] Training: 4241/6852 -- loss: 2.824575424194336\n",
      "2021-04-25 17:54:20,085 [INFO] Training: 4242/6852 -- loss: 1.5332021713256836\n",
      "2021-04-25 17:54:20,136 [INFO] Training: 4243/6852 -- loss: 2.5896363258361816\n",
      "2021-04-25 17:54:20,182 [INFO] Training: 4244/6852 -- loss: 2.573773145675659\n",
      "2021-04-25 17:54:20,234 [INFO] Training: 4245/6852 -- loss: 2.3303515911102295\n",
      "2021-04-25 17:54:20,284 [INFO] Training: 4246/6852 -- loss: 2.5284910202026367\n",
      "2021-04-25 17:54:20,337 [INFO] Training: 4247/6852 -- loss: 2.13126277923584\n",
      "2021-04-25 17:54:20,388 [INFO] Training: 4248/6852 -- loss: 2.0775296688079834\n",
      "2021-04-25 17:54:20,440 [INFO] Training: 4249/6852 -- loss: 2.1889071464538574\n",
      "2021-04-25 17:54:20,488 [INFO] Training: 4250/6852 -- loss: 2.1086935997009277\n",
      "2021-04-25 17:54:20,537 [INFO] Training: 4251/6852 -- loss: 2.019037961959839\n",
      "2021-04-25 17:54:20,586 [INFO] Training: 4252/6852 -- loss: 2.1115801334381104\n",
      "2021-04-25 17:54:20,638 [INFO] Training: 4253/6852 -- loss: 1.0327717065811157\n",
      "2021-04-25 17:54:20,685 [INFO] Training: 4254/6852 -- loss: 2.0665652751922607\n",
      "2021-04-25 17:54:20,734 [INFO] Training: 4255/6852 -- loss: 1.227034091949463\n",
      "2021-04-25 17:54:20,784 [INFO] Training: 4256/6852 -- loss: 1.7032650709152222\n",
      "2021-04-25 17:54:20,833 [INFO] Training: 4257/6852 -- loss: 1.9636662006378174\n",
      "2021-04-25 17:54:20,883 [INFO] Training: 4258/6852 -- loss: 3.6826655864715576\n",
      "2021-04-25 17:54:20,931 [INFO] Training: 4259/6852 -- loss: 1.6050699949264526\n",
      "2021-04-25 17:54:20,983 [INFO] Training: 4260/6852 -- loss: 1.6516873836517334\n",
      "2021-04-25 17:54:21,031 [INFO] Training: 4261/6852 -- loss: 2.2884716987609863\n",
      "2021-04-25 17:54:21,081 [INFO] Training: 4262/6852 -- loss: 1.5156102180480957\n",
      "2021-04-25 17:54:21,130 [INFO] Training: 4263/6852 -- loss: 1.7288254499435425\n",
      "2021-04-25 17:54:21,177 [INFO] Training: 4264/6852 -- loss: 2.378283977508545\n",
      "2021-04-25 17:54:21,229 [INFO] Training: 4265/6852 -- loss: 2.0972275733947754\n",
      "2021-04-25 17:54:21,277 [INFO] Training: 4266/6852 -- loss: 2.516514301300049\n",
      "2021-04-25 17:54:21,326 [INFO] Training: 4267/6852 -- loss: 1.0620849132537842\n",
      "2021-04-25 17:54:21,380 [INFO] Training: 4268/6852 -- loss: 2.7237696647644043\n",
      "2021-04-25 17:54:21,429 [INFO] Training: 4269/6852 -- loss: 2.839853525161743\n",
      "2021-04-25 17:54:21,479 [INFO] Training: 4270/6852 -- loss: 2.434201240539551\n",
      "2021-04-25 17:54:21,525 [INFO] Training: 4271/6852 -- loss: 2.392909526824951\n",
      "2021-04-25 17:54:21,577 [INFO] Training: 4272/6852 -- loss: 2.719312906265259\n",
      "2021-04-25 17:54:21,624 [INFO] Training: 4273/6852 -- loss: 2.1927778720855713\n",
      "2021-04-25 17:54:21,673 [INFO] Training: 4274/6852 -- loss: 2.34663462638855\n",
      "2021-04-25 17:54:21,721 [INFO] Training: 4275/6852 -- loss: 2.7729063034057617\n",
      "2021-04-25 17:54:21,768 [INFO] Training: 4276/6852 -- loss: 2.247570753097534\n",
      "2021-04-25 17:54:21,818 [INFO] Training: 4277/6852 -- loss: 1.368559718132019\n",
      "2021-04-25 17:54:21,867 [INFO] Training: 4278/6852 -- loss: 2.9908316135406494\n",
      "2021-04-25 17:54:21,916 [INFO] Training: 4279/6852 -- loss: 2.7518210411071777\n",
      "2021-04-25 17:54:21,969 [INFO] Training: 4280/6852 -- loss: 2.3110318183898926\n",
      "2021-04-25 17:54:22,018 [INFO] Training: 4281/6852 -- loss: 1.648674726486206\n",
      "2021-04-25 17:54:22,067 [INFO] Training: 4282/6852 -- loss: 1.536318302154541\n",
      "2021-04-25 17:54:22,120 [INFO] Training: 4283/6852 -- loss: 1.8571054935455322\n",
      "2021-04-25 17:54:22,170 [INFO] Training: 4284/6852 -- loss: 1.9672694206237793\n",
      "2021-04-25 17:54:22,221 [INFO] Training: 4285/6852 -- loss: 1.5356924533843994\n",
      "2021-04-25 17:54:22,268 [INFO] Training: 4286/6852 -- loss: 2.3982157707214355\n",
      "2021-04-25 17:54:22,320 [INFO] Training: 4287/6852 -- loss: 2.214142322540283\n",
      "2021-04-25 17:54:22,369 [INFO] Training: 4288/6852 -- loss: 1.8136887550354004\n",
      "2021-04-25 17:54:22,418 [INFO] Training: 4289/6852 -- loss: 2.478976011276245\n",
      "2021-04-25 17:54:22,472 [INFO] Training: 4290/6852 -- loss: 1.3112083673477173\n",
      "2021-04-25 17:54:22,523 [INFO] Training: 4291/6852 -- loss: 1.2467368841171265\n",
      "2021-04-25 17:54:22,572 [INFO] Training: 4292/6852 -- loss: 2.280137300491333\n",
      "2021-04-25 17:54:22,622 [INFO] Training: 4293/6852 -- loss: 1.1967625617980957\n",
      "2021-04-25 17:54:22,672 [INFO] Training: 4294/6852 -- loss: 2.4226832389831543\n",
      "2021-04-25 17:54:22,721 [INFO] Training: 4295/6852 -- loss: 1.8829050064086914\n",
      "2021-04-25 17:54:22,774 [INFO] Training: 4296/6852 -- loss: 2.365199089050293\n",
      "2021-04-25 17:54:22,829 [INFO] Training: 4297/6852 -- loss: 2.3404858112335205\n",
      "2021-04-25 17:54:22,883 [INFO] Training: 4298/6852 -- loss: 2.361436128616333\n",
      "2021-04-25 17:54:22,935 [INFO] Training: 4299/6852 -- loss: 2.3802173137664795\n",
      "2021-04-25 17:54:22,983 [INFO] Training: 4300/6852 -- loss: 2.567416191101074\n",
      "2021-04-25 17:54:23,030 [INFO] Training: 4301/6852 -- loss: 2.0414063930511475\n",
      "2021-04-25 17:54:23,079 [INFO] Training: 4302/6852 -- loss: 3.366177797317505\n",
      "2021-04-25 17:54:23,126 [INFO] Training: 4303/6852 -- loss: 1.862573504447937\n",
      "2021-04-25 17:54:23,175 [INFO] Training: 4304/6852 -- loss: 2.1309876441955566\n",
      "2021-04-25 17:54:23,226 [INFO] Training: 4305/6852 -- loss: 2.4670257568359375\n",
      "2021-04-25 17:54:23,274 [INFO] Training: 4306/6852 -- loss: 1.8832014799118042\n",
      "2021-04-25 17:54:23,325 [INFO] Training: 4307/6852 -- loss: 1.9981422424316406\n",
      "2021-04-25 17:54:23,377 [INFO] Training: 4308/6852 -- loss: 2.737698793411255\n",
      "2021-04-25 17:54:23,425 [INFO] Training: 4309/6852 -- loss: 1.078036904335022\n",
      "2021-04-25 17:54:23,472 [INFO] Training: 4310/6852 -- loss: 1.5686098337173462\n",
      "2021-04-25 17:54:23,522 [INFO] Training: 4311/6852 -- loss: 2.408395528793335\n",
      "2021-04-25 17:54:23,569 [INFO] Training: 4312/6852 -- loss: 1.8974308967590332\n",
      "2021-04-25 17:54:23,617 [INFO] Training: 4313/6852 -- loss: 1.8055554628372192\n",
      "2021-04-25 17:54:23,665 [INFO] Training: 4314/6852 -- loss: 3.0728509426116943\n",
      "2021-04-25 17:54:23,713 [INFO] Training: 4315/6852 -- loss: 3.010603189468384\n",
      "2021-04-25 17:54:23,760 [INFO] Training: 4316/6852 -- loss: 2.0733723640441895\n",
      "2021-04-25 17:54:23,811 [INFO] Training: 4317/6852 -- loss: 3.1708996295928955\n",
      "2021-04-25 17:54:23,859 [INFO] Training: 4318/6852 -- loss: 2.0343964099884033\n",
      "2021-04-25 17:54:23,916 [INFO] Training: 4319/6852 -- loss: 1.5501388311386108\n",
      "2021-04-25 17:54:23,965 [INFO] Training: 4320/6852 -- loss: 1.3610942363739014\n",
      "2021-04-25 17:54:24,016 [INFO] Training: 4321/6852 -- loss: 1.175410270690918\n",
      "2021-04-25 17:54:24,069 [INFO] Training: 4322/6852 -- loss: 1.31435227394104\n",
      "2021-04-25 17:54:24,116 [INFO] Training: 4323/6852 -- loss: 2.388765811920166\n",
      "2021-04-25 17:54:24,164 [INFO] Training: 4324/6852 -- loss: 2.3582491874694824\n",
      "2021-04-25 17:54:24,215 [INFO] Training: 4325/6852 -- loss: 1.9772391319274902\n",
      "2021-04-25 17:54:24,264 [INFO] Training: 4326/6852 -- loss: 2.5260205268859863\n",
      "2021-04-25 17:54:24,314 [INFO] Training: 4327/6852 -- loss: 2.3146026134490967\n",
      "2021-04-25 17:54:24,364 [INFO] Training: 4328/6852 -- loss: 1.6205344200134277\n",
      "2021-04-25 17:54:24,415 [INFO] Training: 4329/6852 -- loss: 1.7672767639160156\n",
      "2021-04-25 17:54:24,463 [INFO] Training: 4330/6852 -- loss: 2.668081760406494\n",
      "2021-04-25 17:54:24,509 [INFO] Training: 4331/6852 -- loss: 2.4814136028289795\n",
      "2021-04-25 17:54:24,561 [INFO] Training: 4332/6852 -- loss: 2.721158981323242\n",
      "2021-04-25 17:54:24,607 [INFO] Training: 4333/6852 -- loss: 2.2833642959594727\n",
      "2021-04-25 17:54:24,656 [INFO] Training: 4334/6852 -- loss: 2.72725248336792\n",
      "2021-04-25 17:54:24,704 [INFO] Training: 4335/6852 -- loss: 2.0280256271362305\n",
      "2021-04-25 17:54:24,756 [INFO] Training: 4336/6852 -- loss: 1.9346208572387695\n",
      "2021-04-25 17:54:24,809 [INFO] Training: 4337/6852 -- loss: 2.1714468002319336\n",
      "2021-04-25 17:54:24,857 [INFO] Training: 4338/6852 -- loss: 1.3059725761413574\n",
      "2021-04-25 17:54:24,906 [INFO] Training: 4339/6852 -- loss: 3.6405599117279053\n",
      "2021-04-25 17:54:24,956 [INFO] Training: 4340/6852 -- loss: 2.718292713165283\n",
      "2021-04-25 17:54:25,008 [INFO] Training: 4341/6852 -- loss: 2.0221686363220215\n",
      "2021-04-25 17:54:25,057 [INFO] Training: 4342/6852 -- loss: 2.243436098098755\n",
      "2021-04-25 17:54:25,107 [INFO] Training: 4343/6852 -- loss: 1.9110445976257324\n",
      "2021-04-25 17:54:25,157 [INFO] Training: 4344/6852 -- loss: 1.06710946559906\n",
      "2021-04-25 17:54:25,204 [INFO] Training: 4345/6852 -- loss: 1.486090064048767\n",
      "2021-04-25 17:54:25,256 [INFO] Training: 4346/6852 -- loss: 3.360769748687744\n",
      "2021-04-25 17:54:25,302 [INFO] Training: 4347/6852 -- loss: 3.4140305519104004\n",
      "2021-04-25 17:54:25,357 [INFO] Training: 4348/6852 -- loss: 1.6370965242385864\n",
      "2021-04-25 17:54:25,403 [INFO] Training: 4349/6852 -- loss: 2.7229983806610107\n",
      "2021-04-25 17:54:25,455 [INFO] Training: 4350/6852 -- loss: 1.6058090925216675\n",
      "2021-04-25 17:54:28,302 [INFO] Training: iteration: 4350/6852 -- epoch: 7 --  train_loss: 2.153 -- train_accuracy: 0.38 valid_loss: 3.112 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:54:28,356 [INFO] Training: 4351/6852 -- loss: 1.6576141119003296\n",
      "2021-04-25 17:54:28,406 [INFO] Training: 4352/6852 -- loss: 2.853959798812866\n",
      "2021-04-25 17:54:28,455 [INFO] Training: 4353/6852 -- loss: 2.1057651042938232\n",
      "2021-04-25 17:54:28,504 [INFO] Training: 4354/6852 -- loss: 1.6897830963134766\n",
      "2021-04-25 17:54:28,551 [INFO] Training: 4355/6852 -- loss: 2.1133270263671875\n",
      "2021-04-25 17:54:28,599 [INFO] Training: 4356/6852 -- loss: 1.8991553783416748\n",
      "2021-04-25 17:54:28,649 [INFO] Training: 4357/6852 -- loss: 2.562833309173584\n",
      "2021-04-25 17:54:28,695 [INFO] Training: 4358/6852 -- loss: 2.1085283756256104\n",
      "2021-04-25 17:54:28,744 [INFO] Training: 4359/6852 -- loss: 2.3963782787323\n",
      "2021-04-25 17:54:28,794 [INFO] Training: 4360/6852 -- loss: 2.1272969245910645\n",
      "2021-04-25 17:54:28,844 [INFO] Training: 4361/6852 -- loss: 3.646746873855591\n",
      "2021-04-25 17:54:28,894 [INFO] Training: 4362/6852 -- loss: 2.2072598934173584\n",
      "2021-04-25 17:54:28,943 [INFO] Training: 4363/6852 -- loss: 1.3898975849151611\n",
      "2021-04-25 17:54:28,996 [INFO] Training: 4364/6852 -- loss: 1.8990328311920166\n",
      "2021-04-25 17:54:29,045 [INFO] Training: 4365/6852 -- loss: 2.0365817546844482\n",
      "2021-04-25 17:54:29,096 [INFO] Training: 4366/6852 -- loss: 3.0315558910369873\n",
      "2021-04-25 17:54:29,142 [INFO] Training: 4367/6852 -- loss: 1.622445821762085\n",
      "2021-04-25 17:54:29,194 [INFO] Training: 4368/6852 -- loss: 2.997509002685547\n",
      "2021-04-25 17:54:29,247 [INFO] Training: 4369/6852 -- loss: 1.182232141494751\n",
      "2021-04-25 17:54:29,297 [INFO] Training: 4370/6852 -- loss: 1.9752960205078125\n",
      "2021-04-25 17:54:29,345 [INFO] Training: 4371/6852 -- loss: 3.5698728561401367\n",
      "2021-04-25 17:54:29,394 [INFO] Training: 4372/6852 -- loss: 2.4617838859558105\n",
      "2021-04-25 17:54:29,446 [INFO] Training: 4373/6852 -- loss: 2.7317662239074707\n",
      "2021-04-25 17:54:29,494 [INFO] Training: 4374/6852 -- loss: 1.6918249130249023\n",
      "2021-04-25 17:54:29,547 [INFO] Training: 4375/6852 -- loss: 3.2305262088775635\n",
      "2021-04-25 17:54:29,596 [INFO] Training: 4376/6852 -- loss: 2.324021100997925\n",
      "2021-04-25 17:54:29,644 [INFO] Training: 4377/6852 -- loss: 2.211884021759033\n",
      "2021-04-25 17:54:29,694 [INFO] Training: 4378/6852 -- loss: 2.0979156494140625\n",
      "2021-04-25 17:54:29,744 [INFO] Training: 4379/6852 -- loss: 2.377758026123047\n",
      "2021-04-25 17:54:29,794 [INFO] Training: 4380/6852 -- loss: 2.3218729496002197\n",
      "2021-04-25 17:54:29,845 [INFO] Training: 4381/6852 -- loss: 1.8051427602767944\n",
      "2021-04-25 17:54:29,892 [INFO] Training: 4382/6852 -- loss: 1.822884440422058\n",
      "2021-04-25 17:54:29,939 [INFO] Training: 4383/6852 -- loss: 1.764969825744629\n",
      "2021-04-25 17:54:29,992 [INFO] Training: 4384/6852 -- loss: 2.2576818466186523\n",
      "2021-04-25 17:54:30,041 [INFO] Training: 4385/6852 -- loss: 2.2258412837982178\n",
      "2021-04-25 17:54:30,088 [INFO] Training: 4386/6852 -- loss: 1.8677146434783936\n",
      "2021-04-25 17:54:30,141 [INFO] Training: 4387/6852 -- loss: 2.7579288482666016\n",
      "2021-04-25 17:54:30,190 [INFO] Training: 4388/6852 -- loss: 2.3765625953674316\n",
      "2021-04-25 17:54:30,244 [INFO] Training: 4389/6852 -- loss: 1.9531152248382568\n",
      "2021-04-25 17:54:30,292 [INFO] Training: 4390/6852 -- loss: 2.6408233642578125\n",
      "2021-04-25 17:54:30,341 [INFO] Training: 4391/6852 -- loss: 2.648104667663574\n",
      "2021-04-25 17:54:30,388 [INFO] Training: 4392/6852 -- loss: 1.3524761199951172\n",
      "2021-04-25 17:54:30,437 [INFO] Training: 4393/6852 -- loss: 2.44476318359375\n",
      "2021-04-25 17:54:30,487 [INFO] Training: 4394/6852 -- loss: 1.7159851789474487\n",
      "2021-04-25 17:54:30,536 [INFO] Training: 4395/6852 -- loss: 1.4792016744613647\n",
      "2021-04-25 17:54:30,585 [INFO] Training: 4396/6852 -- loss: 1.1093361377716064\n",
      "2021-04-25 17:54:30,634 [INFO] Training: 4397/6852 -- loss: 2.865630626678467\n",
      "2021-04-25 17:54:30,686 [INFO] Training: 4398/6852 -- loss: 1.966315746307373\n",
      "2021-04-25 17:54:30,734 [INFO] Training: 4399/6852 -- loss: 1.8409234285354614\n",
      "2021-04-25 17:54:30,781 [INFO] Training: 4400/6852 -- loss: 1.4151331186294556\n",
      "2021-04-25 17:54:30,830 [INFO] Training: 4401/6852 -- loss: 1.776401400566101\n",
      "2021-04-25 17:54:30,878 [INFO] Training: 4402/6852 -- loss: 1.5170032978057861\n",
      "2021-04-25 17:54:30,928 [INFO] Training: 4403/6852 -- loss: 2.060861349105835\n",
      "2021-04-25 17:54:30,977 [INFO] Training: 4404/6852 -- loss: 1.9164037704467773\n",
      "2021-04-25 17:54:31,028 [INFO] Training: 4405/6852 -- loss: 2.2573604583740234\n",
      "2021-04-25 17:54:31,077 [INFO] Training: 4406/6852 -- loss: 2.35939884185791\n",
      "2021-04-25 17:54:31,125 [INFO] Training: 4407/6852 -- loss: 3.211644172668457\n",
      "2021-04-25 17:54:31,176 [INFO] Training: 4408/6852 -- loss: 1.919418215751648\n",
      "2021-04-25 17:54:31,226 [INFO] Training: 4409/6852 -- loss: 1.6699268817901611\n",
      "2021-04-25 17:54:31,278 [INFO] Training: 4410/6852 -- loss: 1.9975674152374268\n",
      "2021-04-25 17:54:31,329 [INFO] Training: 4411/6852 -- loss: 2.068596601486206\n",
      "2021-04-25 17:54:31,377 [INFO] Training: 4412/6852 -- loss: 0.9818586707115173\n",
      "2021-04-25 17:54:31,425 [INFO] Training: 4413/6852 -- loss: 2.8464837074279785\n",
      "2021-04-25 17:54:31,477 [INFO] Training: 4414/6852 -- loss: 1.10355544090271\n",
      "2021-04-25 17:54:31,525 [INFO] Training: 4415/6852 -- loss: 1.5181362628936768\n",
      "2021-04-25 17:54:31,572 [INFO] Training: 4416/6852 -- loss: 3.2142715454101562\n",
      "2021-04-25 17:54:31,624 [INFO] Training: 4417/6852 -- loss: 1.1002589464187622\n",
      "2021-04-25 17:54:31,673 [INFO] Training: 4418/6852 -- loss: 1.500271201133728\n",
      "2021-04-25 17:54:31,723 [INFO] Training: 4419/6852 -- loss: 2.0965051651000977\n",
      "2021-04-25 17:54:31,774 [INFO] Training: 4420/6852 -- loss: 3.2000937461853027\n",
      "2021-04-25 17:54:31,822 [INFO] Training: 4421/6852 -- loss: 2.907087802886963\n",
      "2021-04-25 17:54:31,870 [INFO] Training: 4422/6852 -- loss: 2.6875226497650146\n",
      "2021-04-25 17:54:31,918 [INFO] Training: 4423/6852 -- loss: 2.976752996444702\n",
      "2021-04-25 17:54:31,969 [INFO] Training: 4424/6852 -- loss: 1.326384425163269\n",
      "2021-04-25 17:54:32,017 [INFO] Training: 4425/6852 -- loss: 2.0761656761169434\n",
      "2021-04-25 17:54:32,067 [INFO] Training: 4426/6852 -- loss: 2.4375979900360107\n",
      "2021-04-25 17:54:32,117 [INFO] Training: 4427/6852 -- loss: 2.8521921634674072\n",
      "2021-04-25 17:54:32,167 [INFO] Training: 4428/6852 -- loss: 1.5720230340957642\n",
      "2021-04-25 17:54:32,216 [INFO] Training: 4429/6852 -- loss: 1.6713321208953857\n",
      "2021-04-25 17:54:32,267 [INFO] Training: 4430/6852 -- loss: 1.5383167266845703\n",
      "2021-04-25 17:54:32,316 [INFO] Training: 4431/6852 -- loss: 2.2789714336395264\n",
      "2021-04-25 17:54:32,365 [INFO] Training: 4432/6852 -- loss: 2.476818084716797\n",
      "2021-04-25 17:54:32,413 [INFO] Training: 4433/6852 -- loss: 2.265228748321533\n",
      "2021-04-25 17:54:32,461 [INFO] Training: 4434/6852 -- loss: 3.207181453704834\n",
      "2021-04-25 17:54:32,509 [INFO] Training: 4435/6852 -- loss: 2.9813616275787354\n",
      "2021-04-25 17:54:32,557 [INFO] Training: 4436/6852 -- loss: 1.9600669145584106\n",
      "2021-04-25 17:54:32,605 [INFO] Training: 4437/6852 -- loss: 2.1974377632141113\n",
      "2021-04-25 17:54:32,657 [INFO] Training: 4438/6852 -- loss: 2.223665952682495\n",
      "2021-04-25 17:54:32,707 [INFO] Training: 4439/6852 -- loss: 2.212357521057129\n",
      "2021-04-25 17:54:32,756 [INFO] Training: 4440/6852 -- loss: 1.1445285081863403\n",
      "2021-04-25 17:54:32,805 [INFO] Training: 4441/6852 -- loss: 1.3449090719223022\n",
      "2021-04-25 17:54:32,854 [INFO] Training: 4442/6852 -- loss: 2.3153128623962402\n",
      "2021-04-25 17:54:32,906 [INFO] Training: 4443/6852 -- loss: 1.4550185203552246\n",
      "2021-04-25 17:54:32,953 [INFO] Training: 4444/6852 -- loss: 2.0956406593322754\n",
      "2021-04-25 17:54:33,002 [INFO] Training: 4445/6852 -- loss: 1.6203035116195679\n",
      "2021-04-25 17:54:33,056 [INFO] Training: 4446/6852 -- loss: 2.436279058456421\n",
      "2021-04-25 17:54:33,109 [INFO] Training: 4447/6852 -- loss: 2.8129546642303467\n",
      "2021-04-25 17:54:33,156 [INFO] Training: 4448/6852 -- loss: 1.5246058702468872\n",
      "2021-04-25 17:54:33,210 [INFO] Training: 4449/6852 -- loss: 1.633071780204773\n",
      "2021-04-25 17:54:33,261 [INFO] Training: 4450/6852 -- loss: 1.3125518560409546\n",
      "2021-04-25 17:54:33,311 [INFO] Training: 4451/6852 -- loss: 1.969694972038269\n",
      "2021-04-25 17:54:33,364 [INFO] Training: 4452/6852 -- loss: 2.1679162979125977\n",
      "2021-04-25 17:54:33,415 [INFO] Training: 4453/6852 -- loss: 1.8971413373947144\n",
      "2021-04-25 17:54:33,464 [INFO] Training: 4454/6852 -- loss: 3.026780843734741\n",
      "2021-04-25 17:54:33,514 [INFO] Training: 4455/6852 -- loss: 1.6280920505523682\n",
      "2021-04-25 17:54:33,562 [INFO] Training: 4456/6852 -- loss: 1.2151380777359009\n",
      "2021-04-25 17:54:33,609 [INFO] Training: 4457/6852 -- loss: 3.7953128814697266\n",
      "2021-04-25 17:54:33,657 [INFO] Training: 4458/6852 -- loss: 1.1429007053375244\n",
      "2021-04-25 17:54:33,704 [INFO] Training: 4459/6852 -- loss: 1.614122986793518\n",
      "2021-04-25 17:54:33,751 [INFO] Training: 4460/6852 -- loss: 1.8569649457931519\n",
      "2021-04-25 17:54:33,801 [INFO] Training: 4461/6852 -- loss: 3.250208854675293\n",
      "2021-04-25 17:54:33,849 [INFO] Training: 4462/6852 -- loss: 1.555037498474121\n",
      "2021-04-25 17:54:33,899 [INFO] Training: 4463/6852 -- loss: 1.6428073644638062\n",
      "2021-04-25 17:54:33,951 [INFO] Training: 4464/6852 -- loss: 1.2941900491714478\n",
      "2021-04-25 17:54:34,000 [INFO] Training: 4465/6852 -- loss: 1.9999892711639404\n",
      "2021-04-25 17:54:34,053 [INFO] Training: 4466/6852 -- loss: 2.942392349243164\n",
      "2021-04-25 17:54:34,105 [INFO] Training: 4467/6852 -- loss: 2.6377761363983154\n",
      "2021-04-25 17:54:34,155 [INFO] Training: 4468/6852 -- loss: 1.5287882089614868\n",
      "2021-04-25 17:54:34,204 [INFO] Training: 4469/6852 -- loss: 2.2740871906280518\n",
      "2021-04-25 17:54:34,253 [INFO] Training: 4470/6852 -- loss: 1.6079814434051514\n",
      "2021-04-25 17:54:34,301 [INFO] Training: 4471/6852 -- loss: 2.227313280105591\n",
      "2021-04-25 17:54:34,353 [INFO] Training: 4472/6852 -- loss: 2.6173698902130127\n",
      "2021-04-25 17:54:34,404 [INFO] Training: 4473/6852 -- loss: 2.1008517742156982\n",
      "2021-04-25 17:54:34,456 [INFO] Training: 4474/6852 -- loss: 1.936953067779541\n",
      "2021-04-25 17:54:34,504 [INFO] Training: 4475/6852 -- loss: 2.182249069213867\n",
      "2021-04-25 17:54:34,554 [INFO] Training: 4476/6852 -- loss: 1.7596585750579834\n",
      "2021-04-25 17:54:34,602 [INFO] Training: 4477/6852 -- loss: 2.746537446975708\n",
      "2021-04-25 17:54:34,653 [INFO] Training: 4478/6852 -- loss: 1.7873471975326538\n",
      "2021-04-25 17:54:34,699 [INFO] Training: 4479/6852 -- loss: 1.6001659631729126\n",
      "2021-04-25 17:54:34,751 [INFO] Training: 4480/6852 -- loss: 2.82499361038208\n",
      "2021-04-25 17:54:34,799 [INFO] Training: 4481/6852 -- loss: 2.615901231765747\n",
      "2021-04-25 17:54:34,847 [INFO] Training: 4482/6852 -- loss: 1.0714703798294067\n",
      "2021-04-25 17:54:34,895 [INFO] Training: 4483/6852 -- loss: 3.8560922145843506\n",
      "2021-04-25 17:54:34,945 [INFO] Training: 4484/6852 -- loss: 2.468107223510742\n",
      "2021-04-25 17:54:34,992 [INFO] Training: 4485/6852 -- loss: 1.725882887840271\n",
      "2021-04-25 17:54:35,044 [INFO] Training: 4486/6852 -- loss: 2.1057229042053223\n",
      "2021-04-25 17:54:35,096 [INFO] Training: 4487/6852 -- loss: 1.6010581254959106\n",
      "2021-04-25 17:54:35,146 [INFO] Training: 4488/6852 -- loss: 2.0770106315612793\n",
      "2021-04-25 17:54:35,197 [INFO] Training: 4489/6852 -- loss: 1.2487140893936157\n",
      "2021-04-25 17:54:35,248 [INFO] Training: 4490/6852 -- loss: 1.785628080368042\n",
      "2021-04-25 17:54:35,300 [INFO] Training: 4491/6852 -- loss: 1.9741277694702148\n",
      "2021-04-25 17:54:35,349 [INFO] Training: 4492/6852 -- loss: 3.048717975616455\n",
      "2021-04-25 17:54:35,402 [INFO] Training: 4493/6852 -- loss: 2.265282154083252\n",
      "2021-04-25 17:54:35,452 [INFO] Training: 4494/6852 -- loss: 2.4064621925354004\n",
      "2021-04-25 17:54:35,503 [INFO] Training: 4495/6852 -- loss: 2.166454553604126\n",
      "2021-04-25 17:54:35,551 [INFO] Training: 4496/6852 -- loss: 2.375370740890503\n",
      "2021-04-25 17:54:35,598 [INFO] Training: 4497/6852 -- loss: 1.6662129163742065\n",
      "2021-04-25 17:54:35,649 [INFO] Training: 4498/6852 -- loss: 2.3138771057128906\n",
      "2021-04-25 17:54:35,697 [INFO] Training: 4499/6852 -- loss: 2.116556406021118\n",
      "2021-04-25 17:54:35,743 [INFO] Training: 4500/6852 -- loss: 2.825599193572998\n",
      "2021-04-25 17:54:38,615 [INFO] Training: iteration: 4500/6852 -- epoch: 7 --  train_loss: 2.128 -- train_accuracy: 0.25 valid_loss: 3.125 -- valid_accuracy: 0.30\n",
      "2021-04-25 17:54:38,660 [INFO] Training: 4501/6852 -- loss: 1.364113688468933\n",
      "2021-04-25 17:54:38,709 [INFO] Training: 4502/6852 -- loss: 2.3119187355041504\n",
      "2021-04-25 17:54:38,761 [INFO] Training: 4503/6852 -- loss: 2.989487886428833\n",
      "2021-04-25 17:54:38,812 [INFO] Training: 4504/6852 -- loss: 2.5944483280181885\n",
      "2021-04-25 17:54:38,863 [INFO] Training: 4505/6852 -- loss: 2.0907673835754395\n",
      "2021-04-25 17:54:38,913 [INFO] Training: 4506/6852 -- loss: 2.714914083480835\n",
      "2021-04-25 17:54:38,962 [INFO] Training: 4507/6852 -- loss: 3.6536903381347656\n",
      "2021-04-25 17:54:39,011 [INFO] Training: 4508/6852 -- loss: 2.163334369659424\n",
      "2021-04-25 17:54:39,061 [INFO] Training: 4509/6852 -- loss: 2.0644311904907227\n",
      "2021-04-25 17:54:39,112 [INFO] Training: 4510/6852 -- loss: 1.126462459564209\n",
      "2021-04-25 17:54:39,161 [INFO] Training: 4511/6852 -- loss: 2.2807700634002686\n",
      "2021-04-25 17:54:39,214 [INFO] Training: 4512/6852 -- loss: 2.431558609008789\n",
      "2021-04-25 17:54:39,261 [INFO] Training: 4513/6852 -- loss: 1.7654757499694824\n",
      "2021-04-25 17:54:39,316 [INFO] Training: 4514/6852 -- loss: 2.1657369136810303\n",
      "2021-04-25 17:54:39,365 [INFO] Training: 4515/6852 -- loss: 2.3861083984375\n",
      "2021-04-25 17:54:39,414 [INFO] Training: 4516/6852 -- loss: 0.9817833304405212\n",
      "2021-04-25 17:54:39,465 [INFO] Training: 4517/6852 -- loss: 2.009037494659424\n",
      "2021-04-25 17:54:39,513 [INFO] Training: 4518/6852 -- loss: 1.9426838159561157\n",
      "2021-04-25 17:54:39,565 [INFO] Training: 4519/6852 -- loss: 1.7635643482208252\n",
      "2021-04-25 17:54:39,614 [INFO] Training: 4520/6852 -- loss: 3.044109582901001\n",
      "2021-04-25 17:54:39,665 [INFO] Training: 4521/6852 -- loss: 1.6839078664779663\n",
      "2021-04-25 17:54:39,714 [INFO] Training: 4522/6852 -- loss: 1.7775909900665283\n",
      "2021-04-25 17:54:39,767 [INFO] Training: 4523/6852 -- loss: 2.827439069747925\n",
      "2021-04-25 17:54:39,813 [INFO] Training: 4524/6852 -- loss: 1.1985357999801636\n",
      "2021-04-25 17:54:39,865 [INFO] Training: 4525/6852 -- loss: 1.4279918670654297\n",
      "2021-04-25 17:54:39,911 [INFO] Training: 4526/6852 -- loss: 3.3391575813293457\n",
      "2021-04-25 17:54:39,962 [INFO] Training: 4527/6852 -- loss: 2.4030678272247314\n",
      "2021-04-25 17:54:40,009 [INFO] Training: 4528/6852 -- loss: 2.4516830444335938\n",
      "2021-04-25 17:54:40,060 [INFO] Training: 4529/6852 -- loss: 2.867579936981201\n",
      "2021-04-25 17:54:40,112 [INFO] Training: 4530/6852 -- loss: 1.930663824081421\n",
      "2021-04-25 17:54:40,163 [INFO] Training: 4531/6852 -- loss: 2.764946460723877\n",
      "2021-04-25 17:54:40,213 [INFO] Training: 4532/6852 -- loss: 1.375488042831421\n",
      "2021-04-25 17:54:40,268 [INFO] Training: 4533/6852 -- loss: 1.5180747509002686\n",
      "2021-04-25 17:54:40,315 [INFO] Training: 4534/6852 -- loss: 3.2698004245758057\n",
      "2021-04-25 17:54:40,362 [INFO] Training: 4535/6852 -- loss: 1.132340431213379\n",
      "2021-04-25 17:54:40,413 [INFO] Training: 4536/6852 -- loss: 1.650875449180603\n",
      "2021-04-25 17:54:40,461 [INFO] Training: 4537/6852 -- loss: 1.512169599533081\n",
      "2021-04-25 17:54:40,509 [INFO] Training: 4538/6852 -- loss: 2.13163685798645\n",
      "2021-04-25 17:54:40,557 [INFO] Training: 4539/6852 -- loss: 2.1964101791381836\n",
      "2021-04-25 17:54:40,604 [INFO] Training: 4540/6852 -- loss: 2.0978965759277344\n",
      "2021-04-25 17:54:40,653 [INFO] Training: 4541/6852 -- loss: 1.1989901065826416\n",
      "2021-04-25 17:54:40,703 [INFO] Training: 4542/6852 -- loss: 2.4120311737060547\n",
      "2021-04-25 17:54:40,750 [INFO] Training: 4543/6852 -- loss: 1.771090030670166\n",
      "2021-04-25 17:54:40,799 [INFO] Training: 4544/6852 -- loss: 1.8627440929412842\n",
      "2021-04-25 17:54:40,846 [INFO] Training: 4545/6852 -- loss: 1.5945950746536255\n",
      "2021-04-25 17:54:40,893 [INFO] Training: 4546/6852 -- loss: 2.167309522628784\n",
      "2021-04-25 17:54:40,941 [INFO] Training: 4547/6852 -- loss: 2.6860947608947754\n",
      "2021-04-25 17:54:40,989 [INFO] Training: 4548/6852 -- loss: 1.8277411460876465\n",
      "2021-04-25 17:54:41,041 [INFO] Training: 4549/6852 -- loss: 2.653066396713257\n",
      "2021-04-25 17:54:41,090 [INFO] Training: 4550/6852 -- loss: 2.554939031600952\n",
      "2021-04-25 17:54:41,140 [INFO] Training: 4551/6852 -- loss: 2.083390951156616\n",
      "2021-04-25 17:54:41,193 [INFO] Training: 4552/6852 -- loss: 2.861475944519043\n",
      "2021-04-25 17:54:41,243 [INFO] Training: 4553/6852 -- loss: 2.0257420539855957\n",
      "2021-04-25 17:54:41,291 [INFO] Training: 4554/6852 -- loss: 2.1845955848693848\n",
      "2021-04-25 17:54:41,338 [INFO] Training: 4555/6852 -- loss: 3.3920786380767822\n",
      "2021-04-25 17:54:41,386 [INFO] Training: 4556/6852 -- loss: 2.2091407775878906\n",
      "2021-04-25 17:54:41,436 [INFO] Training: 4557/6852 -- loss: 1.7789462804794312\n",
      "2021-04-25 17:54:41,483 [INFO] Training: 4558/6852 -- loss: 2.1442952156066895\n",
      "2021-04-25 17:54:41,533 [INFO] Training: 4559/6852 -- loss: 1.7896320819854736\n",
      "2021-04-25 17:54:41,581 [INFO] Training: 4560/6852 -- loss: 1.1421571969985962\n",
      "2021-04-25 17:54:41,629 [INFO] Training: 4561/6852 -- loss: 1.5145888328552246\n",
      "2021-04-25 17:54:41,678 [INFO] Training: 4562/6852 -- loss: 2.043396234512329\n",
      "2021-04-25 17:54:41,732 [INFO] Training: 4563/6852 -- loss: 1.732743263244629\n",
      "2021-04-25 17:54:41,780 [INFO] Training: 4564/6852 -- loss: 3.657350540161133\n",
      "2021-04-25 17:54:41,827 [INFO] Training: 4565/6852 -- loss: 2.629758596420288\n",
      "2021-04-25 17:54:41,875 [INFO] Training: 4566/6852 -- loss: 2.6060667037963867\n",
      "2021-04-25 17:54:41,919 [INFO] Training: 4567/6852 -- loss: 2.5315279960632324\n",
      "2021-04-25 17:54:42,203 [INFO] Training: 4568/6852 -- loss: 2.743366241455078\n",
      "2021-04-25 17:54:42,261 [INFO] Training: 4569/6852 -- loss: 1.528215765953064\n",
      "2021-04-25 17:54:42,310 [INFO] Training: 4570/6852 -- loss: 1.7217862606048584\n",
      "2021-04-25 17:54:42,360 [INFO] Training: 4571/6852 -- loss: 1.386492371559143\n",
      "2021-04-25 17:54:42,409 [INFO] Training: 4572/6852 -- loss: 1.5931541919708252\n",
      "2021-04-25 17:54:42,458 [INFO] Training: 4573/6852 -- loss: 2.4450297355651855\n",
      "2021-04-25 17:54:42,506 [INFO] Training: 4574/6852 -- loss: 2.3995134830474854\n",
      "2021-04-25 17:54:42,555 [INFO] Training: 4575/6852 -- loss: 0.9587032198905945\n",
      "2021-04-25 17:54:42,603 [INFO] Training: 4576/6852 -- loss: 3.030621290206909\n",
      "2021-04-25 17:54:42,652 [INFO] Training: 4577/6852 -- loss: 2.0124549865722656\n",
      "2021-04-25 17:54:42,699 [INFO] Training: 4578/6852 -- loss: 2.179851531982422\n",
      "2021-04-25 17:54:42,751 [INFO] Training: 4579/6852 -- loss: 1.5066040754318237\n",
      "2021-04-25 17:54:42,799 [INFO] Training: 4580/6852 -- loss: 2.5073506832122803\n",
      "2021-04-25 17:54:42,846 [INFO] Training: 4581/6852 -- loss: 2.2631843090057373\n",
      "2021-04-25 17:54:42,897 [INFO] Training: 4582/6852 -- loss: 0.939281702041626\n",
      "2021-04-25 17:54:42,946 [INFO] Training: 4583/6852 -- loss: 3.4794838428497314\n",
      "2021-04-25 17:54:42,998 [INFO] Training: 4584/6852 -- loss: 1.0245991945266724\n",
      "2021-04-25 17:54:43,048 [INFO] Training: 4585/6852 -- loss: 2.2508928775787354\n",
      "2021-04-25 17:54:43,102 [INFO] Training: 4586/6852 -- loss: 2.469773292541504\n",
      "2021-04-25 17:54:43,153 [INFO] Training: 4587/6852 -- loss: 2.2293100357055664\n",
      "2021-04-25 17:54:43,205 [INFO] Training: 4588/6852 -- loss: 2.1536600589752197\n",
      "2021-04-25 17:54:43,256 [INFO] Training: 4589/6852 -- loss: 2.3784897327423096\n",
      "2021-04-25 17:54:43,307 [INFO] Training: 4590/6852 -- loss: 1.7261021137237549\n",
      "2021-04-25 17:54:43,359 [INFO] Training: 4591/6852 -- loss: 2.4255211353302\n",
      "2021-04-25 17:54:43,406 [INFO] Training: 4592/6852 -- loss: 1.5673068761825562\n",
      "2021-04-25 17:54:43,455 [INFO] Training: 4593/6852 -- loss: 1.861534833908081\n",
      "2021-04-25 17:54:43,504 [INFO] Training: 4594/6852 -- loss: 2.877115249633789\n",
      "2021-04-25 17:54:43,550 [INFO] Training: 4595/6852 -- loss: 2.5328426361083984\n",
      "2021-04-25 17:54:43,600 [INFO] Training: 4596/6852 -- loss: 1.7377654314041138\n",
      "2021-04-25 17:54:43,650 [INFO] Training: 4597/6852 -- loss: 2.3859503269195557\n",
      "2021-04-25 17:54:43,701 [INFO] Training: 4598/6852 -- loss: 1.4102262258529663\n",
      "2021-04-25 17:54:43,750 [INFO] Training: 4599/6852 -- loss: 1.8204081058502197\n",
      "2021-04-25 17:54:43,800 [INFO] Training: 4600/6852 -- loss: 3.1858320236206055\n",
      "2021-04-25 17:54:43,849 [INFO] Training: 4601/6852 -- loss: 2.638514518737793\n",
      "2021-04-25 17:54:43,899 [INFO] Training: 4602/6852 -- loss: 2.1613690853118896\n",
      "2021-04-25 17:54:43,951 [INFO] Training: 4603/6852 -- loss: 2.55808687210083\n",
      "2021-04-25 17:54:44,000 [INFO] Training: 4604/6852 -- loss: 1.9332783222198486\n",
      "2021-04-25 17:54:44,048 [INFO] Training: 4605/6852 -- loss: 2.1114819049835205\n",
      "2021-04-25 17:54:44,099 [INFO] Training: 4606/6852 -- loss: 2.7886438369750977\n",
      "2021-04-25 17:54:44,145 [INFO] Training: 4607/6852 -- loss: 1.2515106201171875\n",
      "2021-04-25 17:54:44,196 [INFO] Training: 4608/6852 -- loss: 1.5197346210479736\n",
      "2021-04-25 17:54:44,245 [INFO] Training: 4609/6852 -- loss: 1.5561420917510986\n",
      "2021-04-25 17:54:44,292 [INFO] Training: 4610/6852 -- loss: 1.3175759315490723\n",
      "2021-04-25 17:54:44,341 [INFO] Training: 4611/6852 -- loss: 2.128627061843872\n",
      "2021-04-25 17:54:44,393 [INFO] Training: 4612/6852 -- loss: 1.5138477087020874\n",
      "2021-04-25 17:54:44,442 [INFO] Training: 4613/6852 -- loss: 1.8149237632751465\n",
      "2021-04-25 17:54:44,491 [INFO] Training: 4614/6852 -- loss: 1.6309398412704468\n",
      "2021-04-25 17:54:44,540 [INFO] Training: 4615/6852 -- loss: 1.6969304084777832\n",
      "2021-04-25 17:54:44,589 [INFO] Training: 4616/6852 -- loss: 0.946133017539978\n",
      "2021-04-25 17:54:44,637 [INFO] Training: 4617/6852 -- loss: 1.8947322368621826\n",
      "2021-04-25 17:54:44,689 [INFO] Training: 4618/6852 -- loss: 3.2373716831207275\n",
      "2021-04-25 17:54:44,741 [INFO] Training: 4619/6852 -- loss: 1.8909120559692383\n",
      "2021-04-25 17:54:44,791 [INFO] Training: 4620/6852 -- loss: 1.5912131071090698\n",
      "2021-04-25 17:54:44,838 [INFO] Training: 4621/6852 -- loss: 1.8778120279312134\n",
      "2021-04-25 17:54:44,886 [INFO] Training: 4622/6852 -- loss: 2.254239082336426\n",
      "2021-04-25 17:54:44,934 [INFO] Training: 4623/6852 -- loss: 2.2781615257263184\n",
      "2021-04-25 17:54:44,981 [INFO] Training: 4624/6852 -- loss: 1.1433078050613403\n",
      "2021-04-25 17:54:45,032 [INFO] Training: 4625/6852 -- loss: 2.302762746810913\n",
      "2021-04-25 17:54:45,082 [INFO] Training: 4626/6852 -- loss: 3.385049819946289\n",
      "2021-04-25 17:54:45,132 [INFO] Training: 4627/6852 -- loss: 1.2454508543014526\n",
      "2021-04-25 17:54:45,179 [INFO] Training: 4628/6852 -- loss: 0.96272212266922\n",
      "2021-04-25 17:54:45,230 [INFO] Training: 4629/6852 -- loss: 2.8176584243774414\n",
      "2021-04-25 17:54:45,278 [INFO] Training: 4630/6852 -- loss: 2.930427074432373\n",
      "2021-04-25 17:54:45,327 [INFO] Training: 4631/6852 -- loss: 1.921250581741333\n",
      "2021-04-25 17:54:45,375 [INFO] Training: 4632/6852 -- loss: 2.059767484664917\n",
      "2021-04-25 17:54:45,423 [INFO] Training: 4633/6852 -- loss: 1.1089650392532349\n",
      "2021-04-25 17:54:45,470 [INFO] Training: 4634/6852 -- loss: 1.3176199197769165\n",
      "2021-04-25 17:54:45,524 [INFO] Training: 4635/6852 -- loss: 2.0452029705047607\n",
      "2021-04-25 17:54:45,571 [INFO] Training: 4636/6852 -- loss: 2.7275171279907227\n",
      "2021-04-25 17:54:45,623 [INFO] Training: 4637/6852 -- loss: 2.6742117404937744\n",
      "2021-04-25 17:54:45,670 [INFO] Training: 4638/6852 -- loss: 1.6784155368804932\n",
      "2021-04-25 17:54:45,720 [INFO] Training: 4639/6852 -- loss: 1.0270220041275024\n",
      "2021-04-25 17:54:45,768 [INFO] Training: 4640/6852 -- loss: 1.6313600540161133\n",
      "2021-04-25 17:54:45,816 [INFO] Training: 4641/6852 -- loss: 1.1687347888946533\n",
      "2021-04-25 17:54:45,869 [INFO] Training: 4642/6852 -- loss: 1.094443678855896\n",
      "2021-04-25 17:54:45,916 [INFO] Training: 4643/6852 -- loss: 2.633234977722168\n",
      "2021-04-25 17:54:45,964 [INFO] Training: 4644/6852 -- loss: 1.7497272491455078\n",
      "2021-04-25 17:54:46,012 [INFO] Training: 4645/6852 -- loss: 2.1854124069213867\n",
      "2021-04-25 17:54:46,060 [INFO] Training: 4646/6852 -- loss: 2.5497217178344727\n",
      "2021-04-25 17:54:46,111 [INFO] Training: 4647/6852 -- loss: 2.2987842559814453\n",
      "2021-04-25 17:54:46,161 [INFO] Training: 4648/6852 -- loss: 2.2871339321136475\n",
      "2021-04-25 17:54:46,215 [INFO] Training: 4649/6852 -- loss: 1.336253046989441\n",
      "2021-04-25 17:54:46,263 [INFO] Training: 4650/6852 -- loss: 1.92745041847229\n",
      "2021-04-25 17:54:49,115 [INFO] Training: iteration: 4650/6852 -- epoch: 8 --  train_loss: 2.067 -- train_accuracy: 0.75 valid_loss: 3.133 -- valid_accuracy: 0.31\n",
      "2021-04-25 17:54:49,161 [INFO] Training: 4651/6852 -- loss: 1.7659149169921875\n",
      "2021-04-25 17:54:49,209 [INFO] Training: 4652/6852 -- loss: 2.2589831352233887\n",
      "2021-04-25 17:54:49,266 [INFO] Training: 4653/6852 -- loss: 2.8400211334228516\n",
      "2021-04-25 17:54:49,317 [INFO] Training: 4654/6852 -- loss: 2.2426507472991943\n",
      "2021-04-25 17:54:49,364 [INFO] Training: 4655/6852 -- loss: 1.1440730094909668\n",
      "2021-04-25 17:54:49,417 [INFO] Training: 4656/6852 -- loss: 1.1816329956054688\n",
      "2021-04-25 17:54:49,469 [INFO] Training: 4657/6852 -- loss: 1.593780755996704\n",
      "2021-04-25 17:54:49,516 [INFO] Training: 4658/6852 -- loss: 1.2102986574172974\n",
      "2021-04-25 17:54:49,567 [INFO] Training: 4659/6852 -- loss: 1.7198128700256348\n",
      "2021-04-25 17:54:49,616 [INFO] Training: 4660/6852 -- loss: 2.0027389526367188\n",
      "2021-04-25 17:54:49,663 [INFO] Training: 4661/6852 -- loss: 1.3692725896835327\n",
      "2021-04-25 17:54:49,714 [INFO] Training: 4662/6852 -- loss: 1.9941312074661255\n",
      "2021-04-25 17:54:49,766 [INFO] Training: 4663/6852 -- loss: 2.1220874786376953\n",
      "2021-04-25 17:54:49,812 [INFO] Training: 4664/6852 -- loss: 2.6987197399139404\n",
      "2021-04-25 17:54:49,865 [INFO] Training: 4665/6852 -- loss: 1.5752184391021729\n",
      "2021-04-25 17:54:49,912 [INFO] Training: 4666/6852 -- loss: 1.807149052619934\n",
      "2021-04-25 17:54:49,964 [INFO] Training: 4667/6852 -- loss: 1.3070411682128906\n",
      "2021-04-25 17:54:50,015 [INFO] Training: 4668/6852 -- loss: 1.9571386575698853\n",
      "2021-04-25 17:54:50,071 [INFO] Training: 4669/6852 -- loss: 1.8343640565872192\n",
      "2021-04-25 17:54:50,119 [INFO] Training: 4670/6852 -- loss: 2.4078285694122314\n",
      "2021-04-25 17:54:50,171 [INFO] Training: 4671/6852 -- loss: 1.5501141548156738\n",
      "2021-04-25 17:54:50,223 [INFO] Training: 4672/6852 -- loss: 2.1098458766937256\n",
      "2021-04-25 17:54:50,277 [INFO] Training: 4673/6852 -- loss: 2.4312076568603516\n",
      "2021-04-25 17:54:50,324 [INFO] Training: 4674/6852 -- loss: 1.9647351503372192\n",
      "2021-04-25 17:54:50,373 [INFO] Training: 4675/6852 -- loss: 1.1679800748825073\n",
      "2021-04-25 17:54:50,420 [INFO] Training: 4676/6852 -- loss: 2.0949630737304688\n",
      "2021-04-25 17:54:50,468 [INFO] Training: 4677/6852 -- loss: 2.3961873054504395\n",
      "2021-04-25 17:54:50,516 [INFO] Training: 4678/6852 -- loss: 1.2959240674972534\n",
      "2021-04-25 17:54:50,562 [INFO] Training: 4679/6852 -- loss: 1.8445062637329102\n",
      "2021-04-25 17:54:50,610 [INFO] Training: 4680/6852 -- loss: 1.9119300842285156\n",
      "2021-04-25 17:54:50,659 [INFO] Training: 4681/6852 -- loss: 1.6004748344421387\n",
      "2021-04-25 17:54:50,706 [INFO] Training: 4682/6852 -- loss: 1.3370673656463623\n",
      "2021-04-25 17:54:50,753 [INFO] Training: 4683/6852 -- loss: 2.220381259918213\n",
      "2021-04-25 17:54:50,801 [INFO] Training: 4684/6852 -- loss: 2.196218490600586\n",
      "2021-04-25 17:54:50,856 [INFO] Training: 4685/6852 -- loss: 1.5861681699752808\n",
      "2021-04-25 17:54:50,905 [INFO] Training: 4686/6852 -- loss: 1.8974226713180542\n",
      "2021-04-25 17:54:50,955 [INFO] Training: 4687/6852 -- loss: 1.925186038017273\n",
      "2021-04-25 17:54:51,007 [INFO] Training: 4688/6852 -- loss: 0.7837508916854858\n",
      "2021-04-25 17:54:51,061 [INFO] Training: 4689/6852 -- loss: 2.8385300636291504\n",
      "2021-04-25 17:54:51,111 [INFO] Training: 4690/6852 -- loss: 1.8317437171936035\n",
      "2021-04-25 17:54:51,161 [INFO] Training: 4691/6852 -- loss: 1.5520834922790527\n",
      "2021-04-25 17:54:51,208 [INFO] Training: 4692/6852 -- loss: 1.6287425756454468\n",
      "2021-04-25 17:54:51,262 [INFO] Training: 4693/6852 -- loss: 2.196237564086914\n",
      "2021-04-25 17:54:51,310 [INFO] Training: 4694/6852 -- loss: 2.568211555480957\n",
      "2021-04-25 17:54:51,360 [INFO] Training: 4695/6852 -- loss: 1.6752891540527344\n",
      "2021-04-25 17:54:51,412 [INFO] Training: 4696/6852 -- loss: 1.5573687553405762\n",
      "2021-04-25 17:54:51,461 [INFO] Training: 4697/6852 -- loss: 1.8610281944274902\n",
      "2021-04-25 17:54:51,510 [INFO] Training: 4698/6852 -- loss: 0.8973214626312256\n",
      "2021-04-25 17:54:51,557 [INFO] Training: 4699/6852 -- loss: 2.5613043308258057\n",
      "2021-04-25 17:54:51,607 [INFO] Training: 4700/6852 -- loss: 2.099963665008545\n",
      "2021-04-25 17:54:51,655 [INFO] Training: 4701/6852 -- loss: 1.3199628591537476\n",
      "2021-04-25 17:54:51,703 [INFO] Training: 4702/6852 -- loss: 1.6478205919265747\n",
      "2021-04-25 17:54:51,753 [INFO] Training: 4703/6852 -- loss: 1.493155837059021\n",
      "2021-04-25 17:54:51,801 [INFO] Training: 4704/6852 -- loss: 1.334769606590271\n",
      "2021-04-25 17:54:51,851 [INFO] Training: 4705/6852 -- loss: 0.9604395031929016\n",
      "2021-04-25 17:54:51,898 [INFO] Training: 4706/6852 -- loss: 2.475088596343994\n",
      "2021-04-25 17:54:51,949 [INFO] Training: 4707/6852 -- loss: 1.321487545967102\n",
      "2021-04-25 17:54:51,997 [INFO] Training: 4708/6852 -- loss: 2.185793399810791\n",
      "2021-04-25 17:54:52,045 [INFO] Training: 4709/6852 -- loss: 2.3905344009399414\n",
      "2021-04-25 17:54:52,095 [INFO] Training: 4710/6852 -- loss: 1.8088994026184082\n",
      "2021-04-25 17:54:52,144 [INFO] Training: 4711/6852 -- loss: 2.005531072616577\n",
      "2021-04-25 17:54:52,191 [INFO] Training: 4712/6852 -- loss: 2.814628839492798\n",
      "2021-04-25 17:54:52,243 [INFO] Training: 4713/6852 -- loss: 3.7057478427886963\n",
      "2021-04-25 17:54:52,296 [INFO] Training: 4714/6852 -- loss: 1.3277088403701782\n",
      "2021-04-25 17:54:52,344 [INFO] Training: 4715/6852 -- loss: 1.6511805057525635\n",
      "2021-04-25 17:54:52,392 [INFO] Training: 4716/6852 -- loss: 2.6662957668304443\n",
      "2021-04-25 17:54:52,444 [INFO] Training: 4717/6852 -- loss: 2.5356388092041016\n",
      "2021-04-25 17:54:52,490 [INFO] Training: 4718/6852 -- loss: 2.013904333114624\n",
      "2021-04-25 17:54:52,540 [INFO] Training: 4719/6852 -- loss: 2.6818132400512695\n",
      "2021-04-25 17:54:52,589 [INFO] Training: 4720/6852 -- loss: 2.230315685272217\n",
      "2021-04-25 17:54:52,640 [INFO] Training: 4721/6852 -- loss: 1.6853591203689575\n",
      "2021-04-25 17:54:52,690 [INFO] Training: 4722/6852 -- loss: 1.722661018371582\n",
      "2021-04-25 17:54:52,739 [INFO] Training: 4723/6852 -- loss: 2.547203779220581\n",
      "2021-04-25 17:54:52,790 [INFO] Training: 4724/6852 -- loss: 1.8019325733184814\n",
      "2021-04-25 17:54:52,842 [INFO] Training: 4725/6852 -- loss: 1.9239228963851929\n",
      "2021-04-25 17:54:52,892 [INFO] Training: 4726/6852 -- loss: 2.490748882293701\n",
      "2021-04-25 17:54:52,943 [INFO] Training: 4727/6852 -- loss: 1.945818543434143\n",
      "2021-04-25 17:54:52,992 [INFO] Training: 4728/6852 -- loss: 1.842446208000183\n",
      "2021-04-25 17:54:53,040 [INFO] Training: 4729/6852 -- loss: 1.9758025407791138\n",
      "2021-04-25 17:54:53,093 [INFO] Training: 4730/6852 -- loss: 2.1420793533325195\n",
      "2021-04-25 17:54:53,141 [INFO] Training: 4731/6852 -- loss: 2.3863630294799805\n",
      "2021-04-25 17:54:53,190 [INFO] Training: 4732/6852 -- loss: 2.589604616165161\n",
      "2021-04-25 17:54:53,241 [INFO] Training: 4733/6852 -- loss: 2.096108913421631\n",
      "2021-04-25 17:54:53,292 [INFO] Training: 4734/6852 -- loss: 2.8065953254699707\n",
      "2021-04-25 17:54:53,345 [INFO] Training: 4735/6852 -- loss: 1.9040778875350952\n",
      "2021-04-25 17:54:53,396 [INFO] Training: 4736/6852 -- loss: 1.3673721551895142\n",
      "2021-04-25 17:54:53,446 [INFO] Training: 4737/6852 -- loss: 1.060321569442749\n",
      "2021-04-25 17:54:53,497 [INFO] Training: 4738/6852 -- loss: 2.1243228912353516\n",
      "2021-04-25 17:54:53,548 [INFO] Training: 4739/6852 -- loss: 2.2445523738861084\n",
      "2021-04-25 17:54:53,601 [INFO] Training: 4740/6852 -- loss: 1.4465134143829346\n",
      "2021-04-25 17:54:53,653 [INFO] Training: 4741/6852 -- loss: 2.2290987968444824\n",
      "2021-04-25 17:54:53,705 [INFO] Training: 4742/6852 -- loss: 2.3461055755615234\n",
      "2021-04-25 17:54:53,754 [INFO] Training: 4743/6852 -- loss: 1.2933982610702515\n",
      "2021-04-25 17:54:53,804 [INFO] Training: 4744/6852 -- loss: 1.6774184703826904\n",
      "2021-04-25 17:54:53,853 [INFO] Training: 4745/6852 -- loss: 3.025825023651123\n",
      "2021-04-25 17:54:53,908 [INFO] Training: 4746/6852 -- loss: 0.9224300384521484\n",
      "2021-04-25 17:54:53,955 [INFO] Training: 4747/6852 -- loss: 2.1790804862976074\n",
      "2021-04-25 17:54:54,006 [INFO] Training: 4748/6852 -- loss: 1.7625175714492798\n",
      "2021-04-25 17:54:54,054 [INFO] Training: 4749/6852 -- loss: 2.007538080215454\n",
      "2021-04-25 17:54:54,103 [INFO] Training: 4750/6852 -- loss: 2.8760266304016113\n",
      "2021-04-25 17:54:54,152 [INFO] Training: 4751/6852 -- loss: 2.243389129638672\n",
      "2021-04-25 17:54:54,200 [INFO] Training: 4752/6852 -- loss: 2.5500564575195312\n",
      "2021-04-25 17:54:54,250 [INFO] Training: 4753/6852 -- loss: 1.8349359035491943\n",
      "2021-04-25 17:54:54,301 [INFO] Training: 4754/6852 -- loss: 2.794450521469116\n",
      "2021-04-25 17:54:54,350 [INFO] Training: 4755/6852 -- loss: 3.021243095397949\n",
      "2021-04-25 17:54:54,399 [INFO] Training: 4756/6852 -- loss: 1.5064500570297241\n",
      "2021-04-25 17:54:54,451 [INFO] Training: 4757/6852 -- loss: 1.0403006076812744\n",
      "2021-04-25 17:54:54,500 [INFO] Training: 4758/6852 -- loss: 1.661836862564087\n",
      "2021-04-25 17:54:54,549 [INFO] Training: 4759/6852 -- loss: 1.9622981548309326\n",
      "2021-04-25 17:54:54,602 [INFO] Training: 4760/6852 -- loss: 2.2542877197265625\n",
      "2021-04-25 17:54:54,651 [INFO] Training: 4761/6852 -- loss: 1.9945075511932373\n",
      "2021-04-25 17:54:54,700 [INFO] Training: 4762/6852 -- loss: 1.8470388650894165\n",
      "2021-04-25 17:54:54,749 [INFO] Training: 4763/6852 -- loss: 1.7978029251098633\n",
      "2021-04-25 17:54:54,798 [INFO] Training: 4764/6852 -- loss: 2.6216163635253906\n",
      "2021-04-25 17:54:54,849 [INFO] Training: 4765/6852 -- loss: 2.2920217514038086\n",
      "2021-04-25 17:54:54,901 [INFO] Training: 4766/6852 -- loss: 1.90925931930542\n",
      "2021-04-25 17:54:54,951 [INFO] Training: 4767/6852 -- loss: 2.027924060821533\n",
      "2021-04-25 17:54:55,002 [INFO] Training: 4768/6852 -- loss: 1.1854324340820312\n",
      "2021-04-25 17:54:55,051 [INFO] Training: 4769/6852 -- loss: 1.798060655593872\n",
      "2021-04-25 17:54:55,103 [INFO] Training: 4770/6852 -- loss: 1.026065468788147\n",
      "2021-04-25 17:54:55,152 [INFO] Training: 4771/6852 -- loss: 1.3145034313201904\n",
      "2021-04-25 17:54:55,206 [INFO] Training: 4772/6852 -- loss: 2.891634464263916\n",
      "2021-04-25 17:54:55,254 [INFO] Training: 4773/6852 -- loss: 1.3837194442749023\n",
      "2021-04-25 17:54:55,306 [INFO] Training: 4774/6852 -- loss: 1.8614894151687622\n",
      "2021-04-25 17:54:55,358 [INFO] Training: 4775/6852 -- loss: 1.8067121505737305\n",
      "2021-04-25 17:54:55,408 [INFO] Training: 4776/6852 -- loss: 1.8198915719985962\n",
      "2021-04-25 17:54:55,461 [INFO] Training: 4777/6852 -- loss: 2.4174106121063232\n",
      "2021-04-25 17:54:55,510 [INFO] Training: 4778/6852 -- loss: 1.7034857273101807\n",
      "2021-04-25 17:54:55,558 [INFO] Training: 4779/6852 -- loss: 1.7955965995788574\n",
      "2021-04-25 17:54:55,612 [INFO] Training: 4780/6852 -- loss: 2.4493138790130615\n",
      "2021-04-25 17:54:55,661 [INFO] Training: 4781/6852 -- loss: 2.199263095855713\n",
      "2021-04-25 17:54:55,714 [INFO] Training: 4782/6852 -- loss: 0.6657732725143433\n",
      "2021-04-25 17:54:55,760 [INFO] Training: 4783/6852 -- loss: 2.3245790004730225\n",
      "2021-04-25 17:54:55,812 [INFO] Training: 4784/6852 -- loss: 2.2600724697113037\n",
      "2021-04-25 17:54:55,861 [INFO] Training: 4785/6852 -- loss: 1.5064706802368164\n",
      "2021-04-25 17:54:55,914 [INFO] Training: 4786/6852 -- loss: 2.276935338973999\n",
      "2021-04-25 17:54:55,962 [INFO] Training: 4787/6852 -- loss: 2.1712255477905273\n",
      "2021-04-25 17:54:56,015 [INFO] Training: 4788/6852 -- loss: 1.7119088172912598\n",
      "2021-04-25 17:54:56,066 [INFO] Training: 4789/6852 -- loss: 1.7097711563110352\n",
      "2021-04-25 17:54:56,117 [INFO] Training: 4790/6852 -- loss: 1.9227123260498047\n",
      "2021-04-25 17:54:56,169 [INFO] Training: 4791/6852 -- loss: 1.677125096321106\n",
      "2021-04-25 17:54:56,217 [INFO] Training: 4792/6852 -- loss: 0.896168053150177\n",
      "2021-04-25 17:54:56,266 [INFO] Training: 4793/6852 -- loss: 1.4556517601013184\n",
      "2021-04-25 17:54:56,316 [INFO] Training: 4794/6852 -- loss: 2.457474708557129\n",
      "2021-04-25 17:54:56,374 [INFO] Training: 4795/6852 -- loss: 2.340606451034546\n",
      "2021-04-25 17:54:56,427 [INFO] Training: 4796/6852 -- loss: 2.269859790802002\n",
      "2021-04-25 17:54:56,476 [INFO] Training: 4797/6852 -- loss: 1.467348337173462\n",
      "2021-04-25 17:54:56,529 [INFO] Training: 4798/6852 -- loss: 1.4314475059509277\n",
      "2021-04-25 17:54:56,577 [INFO] Training: 4799/6852 -- loss: 1.8114144802093506\n",
      "2021-04-25 17:54:56,631 [INFO] Training: 4800/6852 -- loss: 1.945487380027771\n",
      "2021-04-25 17:54:59,491 [INFO] Training: iteration: 4800/6852 -- epoch: 8 --  train_loss: 1.926 -- train_accuracy: 0.50 valid_loss: 3.197 -- valid_accuracy: 0.31\n",
      "2021-04-25 17:54:59,535 [INFO] Training: 4801/6852 -- loss: 1.5498507022857666\n",
      "2021-04-25 17:54:59,581 [INFO] Training: 4802/6852 -- loss: 1.382794976234436\n",
      "2021-04-25 17:54:59,632 [INFO] Training: 4803/6852 -- loss: 2.426738977432251\n",
      "2021-04-25 17:54:59,685 [INFO] Training: 4804/6852 -- loss: 1.734877347946167\n",
      "2021-04-25 17:54:59,737 [INFO] Training: 4805/6852 -- loss: 3.4095911979675293\n",
      "2021-04-25 17:54:59,785 [INFO] Training: 4806/6852 -- loss: 3.478895425796509\n",
      "2021-04-25 17:54:59,836 [INFO] Training: 4807/6852 -- loss: 2.0621416568756104\n",
      "2021-04-25 17:54:59,884 [INFO] Training: 4808/6852 -- loss: 1.5994772911071777\n",
      "2021-04-25 17:54:59,934 [INFO] Training: 4809/6852 -- loss: 2.338031768798828\n",
      "2021-04-25 17:54:59,987 [INFO] Training: 4810/6852 -- loss: 1.0200830698013306\n",
      "2021-04-25 17:55:00,037 [INFO] Training: 4811/6852 -- loss: 1.706797480583191\n",
      "2021-04-25 17:55:00,088 [INFO] Training: 4812/6852 -- loss: 2.910249710083008\n",
      "2021-04-25 17:55:00,137 [INFO] Training: 4813/6852 -- loss: 1.927533507347107\n",
      "2021-04-25 17:55:00,189 [INFO] Training: 4814/6852 -- loss: 1.683326005935669\n",
      "2021-04-25 17:55:00,239 [INFO] Training: 4815/6852 -- loss: 1.6472465991973877\n",
      "2021-04-25 17:55:00,292 [INFO] Training: 4816/6852 -- loss: 2.8345422744750977\n",
      "2021-04-25 17:55:00,344 [INFO] Training: 4817/6852 -- loss: 1.3608808517456055\n",
      "2021-04-25 17:55:00,396 [INFO] Training: 4818/6852 -- loss: 2.977018356323242\n",
      "2021-04-25 17:55:00,445 [INFO] Training: 4819/6852 -- loss: 2.527622938156128\n",
      "2021-04-25 17:55:00,494 [INFO] Training: 4820/6852 -- loss: 1.4852845668792725\n",
      "2021-04-25 17:55:00,543 [INFO] Training: 4821/6852 -- loss: 1.558544397354126\n",
      "2021-04-25 17:55:00,596 [INFO] Training: 4822/6852 -- loss: 1.4604793787002563\n",
      "2021-04-25 17:55:00,644 [INFO] Training: 4823/6852 -- loss: 2.4426045417785645\n",
      "2021-04-25 17:55:00,693 [INFO] Training: 4824/6852 -- loss: 1.108277678489685\n",
      "2021-04-25 17:55:00,743 [INFO] Training: 4825/6852 -- loss: 2.2799692153930664\n",
      "2021-04-25 17:55:00,792 [INFO] Training: 4826/6852 -- loss: 1.0594466924667358\n",
      "2021-04-25 17:55:00,843 [INFO] Training: 4827/6852 -- loss: 2.175483226776123\n",
      "2021-04-25 17:55:00,894 [INFO] Training: 4828/6852 -- loss: 1.911003828048706\n",
      "2021-04-25 17:55:00,947 [INFO] Training: 4829/6852 -- loss: 2.5134851932525635\n",
      "2021-04-25 17:55:00,998 [INFO] Training: 4830/6852 -- loss: 2.4124717712402344\n",
      "2021-04-25 17:55:01,049 [INFO] Training: 4831/6852 -- loss: 1.555448293685913\n",
      "2021-04-25 17:55:01,098 [INFO] Training: 4832/6852 -- loss: 2.361501932144165\n",
      "2021-04-25 17:55:01,146 [INFO] Training: 4833/6852 -- loss: 2.5701260566711426\n",
      "2021-04-25 17:55:01,196 [INFO] Training: 4834/6852 -- loss: 2.1896164417266846\n",
      "2021-04-25 17:55:01,244 [INFO] Training: 4835/6852 -- loss: 1.8111846446990967\n",
      "2021-04-25 17:55:01,297 [INFO] Training: 4836/6852 -- loss: 1.9436396360397339\n",
      "2021-04-25 17:55:01,343 [INFO] Training: 4837/6852 -- loss: 3.3789570331573486\n",
      "2021-04-25 17:55:01,397 [INFO] Training: 4838/6852 -- loss: 2.9646072387695312\n",
      "2021-04-25 17:55:01,444 [INFO] Training: 4839/6852 -- loss: 2.689702272415161\n",
      "2021-04-25 17:55:01,493 [INFO] Training: 4840/6852 -- loss: 2.439418315887451\n",
      "2021-04-25 17:55:01,541 [INFO] Training: 4841/6852 -- loss: 1.587138056755066\n",
      "2021-04-25 17:55:01,592 [INFO] Training: 4842/6852 -- loss: 1.5999858379364014\n",
      "2021-04-25 17:55:01,643 [INFO] Training: 4843/6852 -- loss: 2.8873863220214844\n",
      "2021-04-25 17:55:01,693 [INFO] Training: 4844/6852 -- loss: 3.1906604766845703\n",
      "2021-04-25 17:55:01,742 [INFO] Training: 4845/6852 -- loss: 2.447354793548584\n",
      "2021-04-25 17:55:01,790 [INFO] Training: 4846/6852 -- loss: 2.3330986499786377\n",
      "2021-04-25 17:55:01,845 [INFO] Training: 4847/6852 -- loss: 1.561037540435791\n",
      "2021-04-25 17:55:01,892 [INFO] Training: 4848/6852 -- loss: 1.8230476379394531\n",
      "2021-04-25 17:55:01,940 [INFO] Training: 4849/6852 -- loss: 1.8685585260391235\n",
      "2021-04-25 17:55:01,989 [INFO] Training: 4850/6852 -- loss: 1.1876989603042603\n",
      "2021-04-25 17:55:02,037 [INFO] Training: 4851/6852 -- loss: 1.6432785987854004\n",
      "2021-04-25 17:55:02,090 [INFO] Training: 4852/6852 -- loss: 1.7084699869155884\n",
      "2021-04-25 17:55:02,137 [INFO] Training: 4853/6852 -- loss: 2.0622358322143555\n",
      "2021-04-25 17:55:02,188 [INFO] Training: 4854/6852 -- loss: 2.893649101257324\n",
      "2021-04-25 17:55:02,235 [INFO] Training: 4855/6852 -- loss: 2.2578957080841064\n",
      "2021-04-25 17:55:02,283 [INFO] Training: 4856/6852 -- loss: 1.9747002124786377\n",
      "2021-04-25 17:55:02,334 [INFO] Training: 4857/6852 -- loss: 2.120478391647339\n",
      "2021-04-25 17:55:02,383 [INFO] Training: 4858/6852 -- loss: 1.2921290397644043\n",
      "2021-04-25 17:55:02,433 [INFO] Training: 4859/6852 -- loss: 1.7413862943649292\n",
      "2021-04-25 17:55:02,481 [INFO] Training: 4860/6852 -- loss: 4.0128960609436035\n",
      "2021-04-25 17:55:02,531 [INFO] Training: 4861/6852 -- loss: 2.231659412384033\n",
      "2021-04-25 17:55:02,583 [INFO] Training: 4862/6852 -- loss: 1.7000635862350464\n",
      "2021-04-25 17:55:02,635 [INFO] Training: 4863/6852 -- loss: 1.7130939960479736\n",
      "2021-04-25 17:55:02,684 [INFO] Training: 4864/6852 -- loss: 2.8103580474853516\n",
      "2021-04-25 17:55:02,732 [INFO] Training: 4865/6852 -- loss: 1.6759181022644043\n",
      "2021-04-25 17:55:02,783 [INFO] Training: 4866/6852 -- loss: 2.906198263168335\n",
      "2021-04-25 17:55:02,832 [INFO] Training: 4867/6852 -- loss: 2.6717259883880615\n",
      "2021-04-25 17:55:02,880 [INFO] Training: 4868/6852 -- loss: 1.1957298517227173\n",
      "2021-04-25 17:55:02,932 [INFO] Training: 4869/6852 -- loss: 1.3494023084640503\n",
      "2021-04-25 17:55:02,982 [INFO] Training: 4870/6852 -- loss: 2.0538535118103027\n",
      "2021-04-25 17:55:03,031 [INFO] Training: 4871/6852 -- loss: 1.7475991249084473\n",
      "2021-04-25 17:55:03,080 [INFO] Training: 4872/6852 -- loss: 2.536236047744751\n",
      "2021-04-25 17:55:03,130 [INFO] Training: 4873/6852 -- loss: 1.6465787887573242\n",
      "2021-04-25 17:55:03,180 [INFO] Training: 4874/6852 -- loss: 1.4737576246261597\n",
      "2021-04-25 17:55:03,238 [INFO] Training: 4875/6852 -- loss: 1.7742809057235718\n",
      "2021-04-25 17:55:03,290 [INFO] Training: 4876/6852 -- loss: 1.7255682945251465\n",
      "2021-04-25 17:55:03,345 [INFO] Training: 4877/6852 -- loss: 2.567274570465088\n",
      "2021-04-25 17:55:03,393 [INFO] Training: 4878/6852 -- loss: 1.1446524858474731\n",
      "2021-04-25 17:55:03,447 [INFO] Training: 4879/6852 -- loss: 2.1057074069976807\n",
      "2021-04-25 17:55:03,501 [INFO] Training: 4880/6852 -- loss: 2.186915159225464\n",
      "2021-04-25 17:55:03,550 [INFO] Training: 4881/6852 -- loss: 2.5057618618011475\n",
      "2021-04-25 17:55:03,602 [INFO] Training: 4882/6852 -- loss: 0.9191681742668152\n",
      "2021-04-25 17:55:03,655 [INFO] Training: 4883/6852 -- loss: 2.6891252994537354\n",
      "2021-04-25 17:55:03,702 [INFO] Training: 4884/6852 -- loss: 1.693721890449524\n",
      "2021-04-25 17:55:03,752 [INFO] Training: 4885/6852 -- loss: 2.0644586086273193\n",
      "2021-04-25 17:55:03,801 [INFO] Training: 4886/6852 -- loss: 1.3864333629608154\n",
      "2021-04-25 17:55:03,854 [INFO] Training: 4887/6852 -- loss: 1.0612045526504517\n",
      "2021-04-25 17:55:03,904 [INFO] Training: 4888/6852 -- loss: 1.7630414962768555\n",
      "2021-04-25 17:55:03,955 [INFO] Training: 4889/6852 -- loss: 2.8419480323791504\n",
      "2021-04-25 17:55:04,010 [INFO] Training: 4890/6852 -- loss: 2.2706737518310547\n",
      "2021-04-25 17:55:04,057 [INFO] Training: 4891/6852 -- loss: 2.471125602722168\n",
      "2021-04-25 17:55:04,106 [INFO] Training: 4892/6852 -- loss: 1.0458489656448364\n",
      "2021-04-25 17:55:04,159 [INFO] Training: 4893/6852 -- loss: 2.3423993587493896\n",
      "2021-04-25 17:55:04,212 [INFO] Training: 4894/6852 -- loss: 2.0541064739227295\n",
      "2021-04-25 17:55:04,265 [INFO] Training: 4895/6852 -- loss: 0.9516886472702026\n",
      "2021-04-25 17:55:04,312 [INFO] Training: 4896/6852 -- loss: 2.2163028717041016\n",
      "2021-04-25 17:55:04,362 [INFO] Training: 4897/6852 -- loss: 2.6966166496276855\n",
      "2021-04-25 17:55:04,415 [INFO] Training: 4898/6852 -- loss: 1.6253420114517212\n",
      "2021-04-25 17:55:04,465 [INFO] Training: 4899/6852 -- loss: 2.609290361404419\n",
      "2021-04-25 17:55:04,519 [INFO] Training: 4900/6852 -- loss: 1.9952794313430786\n",
      "2021-04-25 17:55:04,571 [INFO] Training: 4901/6852 -- loss: 1.034852147102356\n",
      "2021-04-25 17:55:04,622 [INFO] Training: 4902/6852 -- loss: 2.1783454418182373\n",
      "2021-04-25 17:55:04,671 [INFO] Training: 4903/6852 -- loss: 2.462216854095459\n",
      "2021-04-25 17:55:04,721 [INFO] Training: 4904/6852 -- loss: 2.2539455890655518\n",
      "2021-04-25 17:55:04,768 [INFO] Training: 4905/6852 -- loss: 2.300870180130005\n",
      "2021-04-25 17:55:04,822 [INFO] Training: 4906/6852 -- loss: 3.2262520790100098\n",
      "2021-04-25 17:55:04,872 [INFO] Training: 4907/6852 -- loss: 1.9412598609924316\n",
      "2021-04-25 17:55:04,923 [INFO] Training: 4908/6852 -- loss: 2.617617607116699\n",
      "2021-04-25 17:55:04,974 [INFO] Training: 4909/6852 -- loss: 1.7746069431304932\n",
      "2021-04-25 17:55:05,022 [INFO] Training: 4910/6852 -- loss: 2.0494883060455322\n",
      "2021-04-25 17:55:05,072 [INFO] Training: 4911/6852 -- loss: 3.7020821571350098\n",
      "2021-04-25 17:55:05,120 [INFO] Training: 4912/6852 -- loss: 1.7946949005126953\n",
      "2021-04-25 17:55:05,169 [INFO] Training: 4913/6852 -- loss: 1.8436651229858398\n",
      "2021-04-25 17:55:05,218 [INFO] Training: 4914/6852 -- loss: 2.0537002086639404\n",
      "2021-04-25 17:55:05,269 [INFO] Training: 4915/6852 -- loss: 1.656355381011963\n",
      "2021-04-25 17:55:05,318 [INFO] Training: 4916/6852 -- loss: 2.0646719932556152\n",
      "2021-04-25 17:55:05,366 [INFO] Training: 4917/6852 -- loss: 1.9530013799667358\n",
      "2021-04-25 17:55:05,417 [INFO] Training: 4918/6852 -- loss: 1.9020482301712036\n",
      "2021-04-25 17:55:05,465 [INFO] Training: 4919/6852 -- loss: 2.3439114093780518\n",
      "2021-04-25 17:55:05,517 [INFO] Training: 4920/6852 -- loss: 2.097684860229492\n",
      "2021-04-25 17:55:05,564 [INFO] Training: 4921/6852 -- loss: 2.51883602142334\n",
      "2021-04-25 17:55:05,618 [INFO] Training: 4922/6852 -- loss: 2.21777081489563\n",
      "2021-04-25 17:55:05,667 [INFO] Training: 4923/6852 -- loss: 1.2889236211776733\n",
      "2021-04-25 17:55:05,715 [INFO] Training: 4924/6852 -- loss: 2.898623466491699\n",
      "2021-04-25 17:55:05,763 [INFO] Training: 4925/6852 -- loss: 1.6068192720413208\n",
      "2021-04-25 17:55:05,810 [INFO] Training: 4926/6852 -- loss: 2.5687031745910645\n",
      "2021-04-25 17:55:05,862 [INFO] Training: 4927/6852 -- loss: 1.4883334636688232\n",
      "2021-04-25 17:55:05,909 [INFO] Training: 4928/6852 -- loss: 2.135026454925537\n",
      "2021-04-25 17:55:05,958 [INFO] Training: 4929/6852 -- loss: 1.693758487701416\n",
      "2021-04-25 17:55:06,009 [INFO] Training: 4930/6852 -- loss: 2.4487829208374023\n",
      "2021-04-25 17:55:06,058 [INFO] Training: 4931/6852 -- loss: 3.1669063568115234\n",
      "2021-04-25 17:55:06,115 [INFO] Training: 4932/6852 -- loss: 1.604024887084961\n",
      "2021-04-25 17:55:06,164 [INFO] Training: 4933/6852 -- loss: 1.851114273071289\n",
      "2021-04-25 17:55:06,213 [INFO] Training: 4934/6852 -- loss: 1.5421411991119385\n",
      "2021-04-25 17:55:06,261 [INFO] Training: 4935/6852 -- loss: 2.0587515830993652\n",
      "2021-04-25 17:55:06,313 [INFO] Training: 4936/6852 -- loss: 2.1728241443634033\n",
      "2021-04-25 17:55:06,366 [INFO] Training: 4937/6852 -- loss: 1.167038083076477\n",
      "2021-04-25 17:55:06,415 [INFO] Training: 4938/6852 -- loss: 1.2839962244033813\n",
      "2021-04-25 17:55:06,463 [INFO] Training: 4939/6852 -- loss: 1.8716932535171509\n",
      "2021-04-25 17:55:06,518 [INFO] Training: 4940/6852 -- loss: 1.8360825777053833\n",
      "2021-04-25 17:55:06,566 [INFO] Training: 4941/6852 -- loss: 1.6960206031799316\n",
      "2021-04-25 17:55:06,618 [INFO] Training: 4942/6852 -- loss: 1.4090399742126465\n",
      "2021-04-25 17:55:06,671 [INFO] Training: 4943/6852 -- loss: 2.611858606338501\n",
      "2021-04-25 17:55:06,720 [INFO] Training: 4944/6852 -- loss: 1.1632846593856812\n",
      "2021-04-25 17:55:06,771 [INFO] Training: 4945/6852 -- loss: 1.350687861442566\n",
      "2021-04-25 17:55:06,821 [INFO] Training: 4946/6852 -- loss: 2.782588005065918\n",
      "2021-04-25 17:55:06,873 [INFO] Training: 4947/6852 -- loss: 2.4812445640563965\n",
      "2021-04-25 17:55:06,923 [INFO] Training: 4948/6852 -- loss: 2.445190668106079\n",
      "2021-04-25 17:55:06,971 [INFO] Training: 4949/6852 -- loss: 1.4396976232528687\n",
      "2021-04-25 17:55:07,022 [INFO] Training: 4950/6852 -- loss: 1.626489281654358\n",
      "2021-04-25 17:55:09,904 [INFO] Training: iteration: 4950/6852 -- epoch: 8 --  train_loss: 2.048 -- train_accuracy: 0.25 valid_loss: 3.191 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:55:09,941 [INFO] Training: 4951/6852 -- loss: 1.3903509378433228\n",
      "2021-04-25 17:55:09,999 [INFO] Training: 4952/6852 -- loss: 1.9284248352050781\n",
      "2021-04-25 17:55:10,051 [INFO] Training: 4953/6852 -- loss: 2.085439682006836\n",
      "2021-04-25 17:55:10,101 [INFO] Training: 4954/6852 -- loss: 2.016055107116699\n",
      "2021-04-25 17:55:10,158 [INFO] Training: 4955/6852 -- loss: 2.7000651359558105\n",
      "2021-04-25 17:55:10,206 [INFO] Training: 4956/6852 -- loss: 2.183568239212036\n",
      "2021-04-25 17:55:10,255 [INFO] Training: 4957/6852 -- loss: 1.2664761543273926\n",
      "2021-04-25 17:55:10,303 [INFO] Training: 4958/6852 -- loss: 1.7279682159423828\n",
      "2021-04-25 17:55:10,353 [INFO] Training: 4959/6852 -- loss: 1.8278915882110596\n",
      "2021-04-25 17:55:10,400 [INFO] Training: 4960/6852 -- loss: 3.079699754714966\n",
      "2021-04-25 17:55:10,448 [INFO] Training: 4961/6852 -- loss: 2.200961112976074\n",
      "2021-04-25 17:55:10,497 [INFO] Training: 4962/6852 -- loss: 2.184091329574585\n",
      "2021-04-25 17:55:10,546 [INFO] Training: 4963/6852 -- loss: 2.020714282989502\n",
      "2021-04-25 17:55:10,601 [INFO] Training: 4964/6852 -- loss: 1.8021595478057861\n",
      "2021-04-25 17:55:10,649 [INFO] Training: 4965/6852 -- loss: 2.6568875312805176\n",
      "2021-04-25 17:55:10,702 [INFO] Training: 4966/6852 -- loss: 1.2912553548812866\n",
      "2021-04-25 17:55:10,752 [INFO] Training: 4967/6852 -- loss: 3.0891566276550293\n",
      "2021-04-25 17:55:10,803 [INFO] Training: 4968/6852 -- loss: 1.3930132389068604\n",
      "2021-04-25 17:55:10,852 [INFO] Training: 4969/6852 -- loss: 2.496232032775879\n",
      "2021-04-25 17:55:10,902 [INFO] Training: 4970/6852 -- loss: 1.7915122509002686\n",
      "2021-04-25 17:55:10,951 [INFO] Training: 4971/6852 -- loss: 1.8333299160003662\n",
      "2021-04-25 17:55:10,999 [INFO] Training: 4972/6852 -- loss: 2.14532470703125\n",
      "2021-04-25 17:55:11,049 [INFO] Training: 4973/6852 -- loss: 2.1321475505828857\n",
      "2021-04-25 17:55:11,099 [INFO] Training: 4974/6852 -- loss: 2.188377618789673\n",
      "2021-04-25 17:55:11,148 [INFO] Training: 4975/6852 -- loss: 2.0835013389587402\n",
      "2021-04-25 17:55:11,196 [INFO] Training: 4976/6852 -- loss: 1.1031882762908936\n",
      "2021-04-25 17:55:11,246 [INFO] Training: 4977/6852 -- loss: 2.454355478286743\n",
      "2021-04-25 17:55:11,295 [INFO] Training: 4978/6852 -- loss: 1.0371767282485962\n",
      "2021-04-25 17:55:11,347 [INFO] Training: 4979/6852 -- loss: 2.388618230819702\n",
      "2021-04-25 17:55:11,395 [INFO] Training: 4980/6852 -- loss: 2.8369064331054688\n",
      "2021-04-25 17:55:11,447 [INFO] Training: 4981/6852 -- loss: 1.1498563289642334\n",
      "2021-04-25 17:55:11,502 [INFO] Training: 4982/6852 -- loss: 1.8750934600830078\n",
      "2021-04-25 17:55:11,553 [INFO] Training: 4983/6852 -- loss: 1.543375849723816\n",
      "2021-04-25 17:55:11,601 [INFO] Training: 4984/6852 -- loss: 2.6015818119049072\n",
      "2021-04-25 17:55:11,652 [INFO] Training: 4985/6852 -- loss: 3.170947790145874\n",
      "2021-04-25 17:55:11,706 [INFO] Training: 4986/6852 -- loss: 2.4472062587738037\n",
      "2021-04-25 17:55:11,754 [INFO] Training: 4987/6852 -- loss: 2.476518154144287\n",
      "2021-04-25 17:55:11,801 [INFO] Training: 4988/6852 -- loss: 1.38735830783844\n",
      "2021-04-25 17:55:11,856 [INFO] Training: 4989/6852 -- loss: 2.185863971710205\n",
      "2021-04-25 17:55:11,906 [INFO] Training: 4990/6852 -- loss: 1.8390450477600098\n",
      "2021-04-25 17:55:11,955 [INFO] Training: 4991/6852 -- loss: 2.7655105590820312\n",
      "2021-04-25 17:55:12,004 [INFO] Training: 4992/6852 -- loss: 2.043684244155884\n",
      "2021-04-25 17:55:12,052 [INFO] Training: 4993/6852 -- loss: 3.8645172119140625\n",
      "2021-04-25 17:55:12,105 [INFO] Training: 4994/6852 -- loss: 2.0596776008605957\n",
      "2021-04-25 17:55:12,153 [INFO] Training: 4995/6852 -- loss: 2.208740711212158\n",
      "2021-04-25 17:55:12,201 [INFO] Training: 4996/6852 -- loss: 1.6266989707946777\n",
      "2021-04-25 17:55:12,248 [INFO] Training: 4997/6852 -- loss: 1.8207042217254639\n",
      "2021-04-25 17:55:12,298 [INFO] Training: 4998/6852 -- loss: 2.9103546142578125\n",
      "2021-04-25 17:55:12,346 [INFO] Training: 4999/6852 -- loss: 1.9639291763305664\n",
      "2021-04-25 17:55:12,394 [INFO] Training: 5000/6852 -- loss: 2.350428342819214\n",
      "2021-04-25 17:55:12,447 [INFO] Training: 5001/6852 -- loss: 2.511918306350708\n",
      "2021-04-25 17:55:12,494 [INFO] Training: 5002/6852 -- loss: 2.646329164505005\n",
      "2021-04-25 17:55:12,544 [INFO] Training: 5003/6852 -- loss: 2.060514450073242\n",
      "2021-04-25 17:55:12,594 [INFO] Training: 5004/6852 -- loss: 1.2733373641967773\n",
      "2021-04-25 17:55:12,642 [INFO] Training: 5005/6852 -- loss: 2.1122803688049316\n",
      "2021-04-25 17:55:12,690 [INFO] Training: 5006/6852 -- loss: 1.0293076038360596\n",
      "2021-04-25 17:55:12,740 [INFO] Training: 5007/6852 -- loss: 2.5600457191467285\n",
      "2021-04-25 17:55:12,792 [INFO] Training: 5008/6852 -- loss: 2.1577465534210205\n",
      "2021-04-25 17:55:12,840 [INFO] Training: 5009/6852 -- loss: 3.8582630157470703\n",
      "2021-04-25 17:55:12,890 [INFO] Training: 5010/6852 -- loss: 2.1248831748962402\n",
      "2021-04-25 17:55:12,938 [INFO] Training: 5011/6852 -- loss: 2.342470645904541\n",
      "2021-04-25 17:55:12,987 [INFO] Training: 5012/6852 -- loss: 1.4653083086013794\n",
      "2021-04-25 17:55:13,036 [INFO] Training: 5013/6852 -- loss: 3.2124123573303223\n",
      "2021-04-25 17:55:13,084 [INFO] Training: 5014/6852 -- loss: 2.8375823497772217\n",
      "2021-04-25 17:55:13,133 [INFO] Training: 5015/6852 -- loss: 1.8087955713272095\n",
      "2021-04-25 17:55:13,184 [INFO] Training: 5016/6852 -- loss: 2.7403767108917236\n",
      "2021-04-25 17:55:13,234 [INFO] Training: 5017/6852 -- loss: 1.460105061531067\n",
      "2021-04-25 17:55:13,282 [INFO] Training: 5018/6852 -- loss: 1.5950220823287964\n",
      "2021-04-25 17:55:13,331 [INFO] Training: 5019/6852 -- loss: 2.0862696170806885\n",
      "2021-04-25 17:55:13,378 [INFO] Training: 5020/6852 -- loss: 1.7677956819534302\n",
      "2021-04-25 17:55:13,425 [INFO] Training: 5021/6852 -- loss: 1.9524645805358887\n",
      "2021-04-25 17:55:13,476 [INFO] Training: 5022/6852 -- loss: 1.6037778854370117\n",
      "2021-04-25 17:55:13,532 [INFO] Training: 5023/6852 -- loss: 2.199247360229492\n",
      "2021-04-25 17:55:13,587 [INFO] Training: 5024/6852 -- loss: 1.7018353939056396\n",
      "2021-04-25 17:55:13,634 [INFO] Training: 5025/6852 -- loss: 1.370916485786438\n",
      "2021-04-25 17:55:13,684 [INFO] Training: 5026/6852 -- loss: 1.2146642208099365\n",
      "2021-04-25 17:55:13,736 [INFO] Training: 5027/6852 -- loss: 2.5580203533172607\n",
      "2021-04-25 17:55:13,785 [INFO] Training: 5028/6852 -- loss: 1.341020941734314\n",
      "2021-04-25 17:55:13,832 [INFO] Training: 5029/6852 -- loss: 1.4058717489242554\n",
      "2021-04-25 17:55:13,880 [INFO] Training: 5030/6852 -- loss: 2.2901618480682373\n",
      "2021-04-25 17:55:13,928 [INFO] Training: 5031/6852 -- loss: 1.9302654266357422\n",
      "2021-04-25 17:55:13,978 [INFO] Training: 5032/6852 -- loss: 1.8548225164413452\n",
      "2021-04-25 17:55:14,029 [INFO] Training: 5033/6852 -- loss: 2.0976524353027344\n",
      "2021-04-25 17:55:14,078 [INFO] Training: 5034/6852 -- loss: 1.6641449928283691\n",
      "2021-04-25 17:55:14,128 [INFO] Training: 5035/6852 -- loss: 1.5960853099822998\n",
      "2021-04-25 17:55:14,180 [INFO] Training: 5036/6852 -- loss: 1.698930025100708\n",
      "2021-04-25 17:55:14,230 [INFO] Training: 5037/6852 -- loss: 1.2197935581207275\n",
      "2021-04-25 17:55:14,282 [INFO] Training: 5038/6852 -- loss: 2.331946849822998\n",
      "2021-04-25 17:55:14,331 [INFO] Training: 5039/6852 -- loss: 0.8192352652549744\n",
      "2021-04-25 17:55:14,382 [INFO] Training: 5040/6852 -- loss: 1.5604127645492554\n",
      "2021-04-25 17:55:14,434 [INFO] Training: 5041/6852 -- loss: 2.1815731525421143\n",
      "2021-04-25 17:55:14,483 [INFO] Training: 5042/6852 -- loss: 1.056657314300537\n",
      "2021-04-25 17:55:14,535 [INFO] Training: 5043/6852 -- loss: 3.222806453704834\n",
      "2021-04-25 17:55:14,583 [INFO] Training: 5044/6852 -- loss: 1.2694118022918701\n",
      "2021-04-25 17:55:14,635 [INFO] Training: 5045/6852 -- loss: 2.1567471027374268\n",
      "2021-04-25 17:55:14,687 [INFO] Training: 5046/6852 -- loss: 0.7873713970184326\n",
      "2021-04-25 17:55:14,740 [INFO] Training: 5047/6852 -- loss: 2.3980612754821777\n",
      "2021-04-25 17:55:14,786 [INFO] Training: 5048/6852 -- loss: 2.143585681915283\n",
      "2021-04-25 17:55:14,835 [INFO] Training: 5049/6852 -- loss: 2.1754348278045654\n",
      "2021-04-25 17:55:14,884 [INFO] Training: 5050/6852 -- loss: 2.0611672401428223\n",
      "2021-04-25 17:55:14,935 [INFO] Training: 5051/6852 -- loss: 1.724605679512024\n",
      "2021-04-25 17:55:14,987 [INFO] Training: 5052/6852 -- loss: 2.2223000526428223\n",
      "2021-04-25 17:55:15,035 [INFO] Training: 5053/6852 -- loss: 1.00210702419281\n",
      "2021-04-25 17:55:15,089 [INFO] Training: 5054/6852 -- loss: 1.948568344116211\n",
      "2021-04-25 17:55:15,142 [INFO] Training: 5055/6852 -- loss: 1.7460792064666748\n",
      "2021-04-25 17:55:15,195 [INFO] Training: 5056/6852 -- loss: 1.844001293182373\n",
      "2021-04-25 17:55:15,244 [INFO] Training: 5057/6852 -- loss: 2.45358943939209\n",
      "2021-04-25 17:55:15,292 [INFO] Training: 5058/6852 -- loss: 2.1781039237976074\n",
      "2021-04-25 17:55:15,343 [INFO] Training: 5059/6852 -- loss: 2.3652567863464355\n",
      "2021-04-25 17:55:15,391 [INFO] Training: 5060/6852 -- loss: 1.8407585620880127\n",
      "2021-04-25 17:55:15,438 [INFO] Training: 5061/6852 -- loss: 1.3784728050231934\n",
      "2021-04-25 17:55:15,492 [INFO] Training: 5062/6852 -- loss: 1.3512238264083862\n",
      "2021-04-25 17:55:15,542 [INFO] Training: 5063/6852 -- loss: 1.9598968029022217\n",
      "2021-04-25 17:55:15,591 [INFO] Training: 5064/6852 -- loss: 2.1442008018493652\n",
      "2021-04-25 17:55:15,641 [INFO] Training: 5065/6852 -- loss: 0.8595201373100281\n",
      "2021-04-25 17:55:15,693 [INFO] Training: 5066/6852 -- loss: 1.8916277885437012\n",
      "2021-04-25 17:55:15,741 [INFO] Training: 5067/6852 -- loss: 2.0891478061676025\n",
      "2021-04-25 17:55:15,795 [INFO] Training: 5068/6852 -- loss: 2.0895752906799316\n",
      "2021-04-25 17:55:15,843 [INFO] Training: 5069/6852 -- loss: 1.8705620765686035\n",
      "2021-04-25 17:55:15,890 [INFO] Training: 5070/6852 -- loss: 1.5637545585632324\n",
      "2021-04-25 17:55:15,939 [INFO] Training: 5071/6852 -- loss: 1.7831724882125854\n",
      "2021-04-25 17:55:15,987 [INFO] Training: 5072/6852 -- loss: 2.5321481227874756\n",
      "2021-04-25 17:55:16,035 [INFO] Training: 5073/6852 -- loss: 1.5213494300842285\n",
      "2021-04-25 17:55:16,086 [INFO] Training: 5074/6852 -- loss: 2.134023427963257\n",
      "2021-04-25 17:55:16,133 [INFO] Training: 5075/6852 -- loss: 1.2735176086425781\n",
      "2021-04-25 17:55:16,183 [INFO] Training: 5076/6852 -- loss: 1.6267389059066772\n",
      "2021-04-25 17:55:16,231 [INFO] Training: 5077/6852 -- loss: 2.248598098754883\n",
      "2021-04-25 17:55:16,281 [INFO] Training: 5078/6852 -- loss: 1.620671033859253\n",
      "2021-04-25 17:55:16,331 [INFO] Training: 5079/6852 -- loss: 2.316864252090454\n",
      "2021-04-25 17:55:16,386 [INFO] Training: 5080/6852 -- loss: 2.6344640254974365\n",
      "2021-04-25 17:55:16,437 [INFO] Training: 5081/6852 -- loss: 2.748901844024658\n",
      "2021-04-25 17:55:16,485 [INFO] Training: 5082/6852 -- loss: 1.6019541025161743\n",
      "2021-04-25 17:55:16,535 [INFO] Training: 5083/6852 -- loss: 1.9076756238937378\n",
      "2021-04-25 17:55:16,584 [INFO] Training: 5084/6852 -- loss: 1.8742120265960693\n",
      "2021-04-25 17:55:16,633 [INFO] Training: 5085/6852 -- loss: 2.1165778636932373\n",
      "2021-04-25 17:55:16,685 [INFO] Training: 5086/6852 -- loss: 2.6633553504943848\n",
      "2021-04-25 17:55:16,737 [INFO] Training: 5087/6852 -- loss: 1.4543921947479248\n",
      "2021-04-25 17:55:16,790 [INFO] Training: 5088/6852 -- loss: 2.581695318222046\n",
      "2021-04-25 17:55:16,841 [INFO] Training: 5089/6852 -- loss: 2.6837360858917236\n",
      "2021-04-25 17:55:16,892 [INFO] Training: 5090/6852 -- loss: 2.1435818672180176\n",
      "2021-04-25 17:55:16,938 [INFO] Training: 5091/6852 -- loss: 1.821000576019287\n",
      "2021-04-25 17:55:16,986 [INFO] Training: 5092/6852 -- loss: 3.0897178649902344\n",
      "2021-04-25 17:55:17,034 [INFO] Training: 5093/6852 -- loss: 2.088275909423828\n",
      "2021-04-25 17:55:17,081 [INFO] Training: 5094/6852 -- loss: 2.590196132659912\n",
      "2021-04-25 17:55:17,137 [INFO] Training: 5095/6852 -- loss: 2.2548842430114746\n",
      "2021-04-25 17:55:17,186 [INFO] Training: 5096/6852 -- loss: 2.0030739307403564\n",
      "2021-04-25 17:55:17,238 [INFO] Training: 5097/6852 -- loss: 2.4064383506774902\n",
      "2021-04-25 17:55:17,290 [INFO] Training: 5098/6852 -- loss: 2.21197509765625\n",
      "2021-04-25 17:55:17,339 [INFO] Training: 5099/6852 -- loss: 1.170996069908142\n",
      "2021-04-25 17:55:17,391 [INFO] Training: 5100/6852 -- loss: 1.281998872756958\n",
      "2021-04-25 17:55:20,259 [INFO] Training: iteration: 5100/6852 -- epoch: 8 --  train_loss: 2.014 -- train_accuracy: 0.75 valid_loss: 3.135 -- valid_accuracy: 0.30\n",
      "2021-04-25 17:55:20,305 [INFO] Training: 5101/6852 -- loss: 1.465144157409668\n",
      "2021-04-25 17:55:20,356 [INFO] Training: 5102/6852 -- loss: 1.3100227117538452\n",
      "2021-04-25 17:55:20,408 [INFO] Training: 5103/6852 -- loss: 2.022416830062866\n",
      "2021-04-25 17:55:20,458 [INFO] Training: 5104/6852 -- loss: 1.607932448387146\n",
      "2021-04-25 17:55:20,507 [INFO] Training: 5105/6852 -- loss: 1.6600327491760254\n",
      "2021-04-25 17:55:20,557 [INFO] Training: 5106/6852 -- loss: 1.3693819046020508\n",
      "2021-04-25 17:55:20,605 [INFO] Training: 5107/6852 -- loss: 0.925904393196106\n",
      "2021-04-25 17:55:20,652 [INFO] Training: 5108/6852 -- loss: 2.278191089630127\n",
      "2021-04-25 17:55:20,708 [INFO] Training: 5109/6852 -- loss: 2.0371012687683105\n",
      "2021-04-25 17:55:20,758 [INFO] Training: 5110/6852 -- loss: 2.4139113426208496\n",
      "2021-04-25 17:55:20,808 [INFO] Training: 5111/6852 -- loss: 2.6697514057159424\n",
      "2021-04-25 17:55:20,860 [INFO] Training: 5112/6852 -- loss: 1.2234675884246826\n",
      "2021-04-25 17:55:20,909 [INFO] Training: 5113/6852 -- loss: 2.254390001296997\n",
      "2021-04-25 17:55:20,957 [INFO] Training: 5114/6852 -- loss: 1.9493299722671509\n",
      "2021-04-25 17:55:21,005 [INFO] Training: 5115/6852 -- loss: 2.550354480743408\n",
      "2021-04-25 17:55:21,055 [INFO] Training: 5116/6852 -- loss: 3.2463369369506836\n",
      "2021-04-25 17:55:21,108 [INFO] Training: 5117/6852 -- loss: 2.185678005218506\n",
      "2021-04-25 17:55:21,159 [INFO] Training: 5118/6852 -- loss: 1.3384696245193481\n",
      "2021-04-25 17:55:21,207 [INFO] Training: 5119/6852 -- loss: 2.7491681575775146\n",
      "2021-04-25 17:55:21,257 [INFO] Training: 5120/6852 -- loss: 2.1027562618255615\n",
      "2021-04-25 17:55:21,305 [INFO] Training: 5121/6852 -- loss: 2.432343006134033\n",
      "2021-04-25 17:55:21,355 [INFO] Training: 5122/6852 -- loss: 1.2871763706207275\n",
      "2021-04-25 17:55:21,404 [INFO] Training: 5123/6852 -- loss: 1.5350325107574463\n",
      "2021-04-25 17:55:21,452 [INFO] Training: 5124/6852 -- loss: 1.8961926698684692\n",
      "2021-04-25 17:55:21,503 [INFO] Training: 5125/6852 -- loss: 1.3013079166412354\n",
      "2021-04-25 17:55:21,551 [INFO] Training: 5126/6852 -- loss: 3.2594070434570312\n",
      "2021-04-25 17:55:21,604 [INFO] Training: 5127/6852 -- loss: 1.2976425886154175\n",
      "2021-04-25 17:55:21,654 [INFO] Training: 5128/6852 -- loss: 1.3810216188430786\n",
      "2021-04-25 17:55:21,707 [INFO] Training: 5129/6852 -- loss: 2.010746955871582\n",
      "2021-04-25 17:55:21,762 [INFO] Training: 5130/6852 -- loss: 2.1464297771453857\n",
      "2021-04-25 17:55:21,817 [INFO] Training: 5131/6852 -- loss: 1.2690597772598267\n",
      "2021-04-25 17:55:21,868 [INFO] Training: 5132/6852 -- loss: 2.200066328048706\n",
      "2021-04-25 17:55:21,916 [INFO] Training: 5133/6852 -- loss: 2.0974247455596924\n",
      "2021-04-25 17:55:21,969 [INFO] Training: 5134/6852 -- loss: 3.0123672485351562\n",
      "2021-04-25 17:55:22,016 [INFO] Training: 5135/6852 -- loss: 2.0976457595825195\n",
      "2021-04-25 17:55:22,066 [INFO] Training: 5136/6852 -- loss: 3.1357851028442383\n",
      "2021-04-25 17:55:22,116 [INFO] Training: 5137/6852 -- loss: 1.6597356796264648\n",
      "2021-04-25 17:55:22,160 [INFO] Training: 5138/6852 -- loss: 1.9994468688964844\n",
      "2021-04-25 17:55:22,431 [INFO] Training: 5139/6852 -- loss: 1.5318760871887207\n",
      "2021-04-25 17:55:22,482 [INFO] Training: 5140/6852 -- loss: 1.397452473640442\n",
      "2021-04-25 17:55:22,533 [INFO] Training: 5141/6852 -- loss: 1.709799885749817\n",
      "2021-04-25 17:55:22,584 [INFO] Training: 5142/6852 -- loss: 1.593464732170105\n",
      "2021-04-25 17:55:22,637 [INFO] Training: 5143/6852 -- loss: 2.1919033527374268\n",
      "2021-04-25 17:55:22,685 [INFO] Training: 5144/6852 -- loss: 2.0211877822875977\n",
      "2021-04-25 17:55:22,735 [INFO] Training: 5145/6852 -- loss: 2.6521716117858887\n",
      "2021-04-25 17:55:22,784 [INFO] Training: 5146/6852 -- loss: 1.510236144065857\n",
      "2021-04-25 17:55:22,835 [INFO] Training: 5147/6852 -- loss: 2.3807997703552246\n",
      "2021-04-25 17:55:22,884 [INFO] Training: 5148/6852 -- loss: 1.2346826791763306\n",
      "2021-04-25 17:55:22,935 [INFO] Training: 5149/6852 -- loss: 2.4004416465759277\n",
      "2021-04-25 17:55:22,990 [INFO] Training: 5150/6852 -- loss: 1.3036396503448486\n",
      "2021-04-25 17:55:23,040 [INFO] Training: 5151/6852 -- loss: 1.4619348049163818\n",
      "2021-04-25 17:55:23,092 [INFO] Training: 5152/6852 -- loss: 1.7755675315856934\n",
      "2021-04-25 17:55:23,145 [INFO] Training: 5153/6852 -- loss: 1.8065534830093384\n",
      "2021-04-25 17:55:23,194 [INFO] Training: 5154/6852 -- loss: 1.7707808017730713\n",
      "2021-04-25 17:55:23,243 [INFO] Training: 5155/6852 -- loss: 1.8362951278686523\n",
      "2021-04-25 17:55:23,293 [INFO] Training: 5156/6852 -- loss: 1.4683598279953003\n",
      "2021-04-25 17:55:23,346 [INFO] Training: 5157/6852 -- loss: 1.4340596199035645\n",
      "2021-04-25 17:55:23,392 [INFO] Training: 5158/6852 -- loss: 1.4909297227859497\n",
      "2021-04-25 17:55:23,442 [INFO] Training: 5159/6852 -- loss: 1.9759750366210938\n",
      "2021-04-25 17:55:23,492 [INFO] Training: 5160/6852 -- loss: 2.677934408187866\n",
      "2021-04-25 17:55:23,543 [INFO] Training: 5161/6852 -- loss: 1.899479627609253\n",
      "2021-04-25 17:55:23,592 [INFO] Training: 5162/6852 -- loss: 1.558060884475708\n",
      "2021-04-25 17:55:23,644 [INFO] Training: 5163/6852 -- loss: 2.129363775253296\n",
      "2021-04-25 17:55:23,696 [INFO] Training: 5164/6852 -- loss: 2.695308208465576\n",
      "2021-04-25 17:55:23,745 [INFO] Training: 5165/6852 -- loss: 1.2180505990982056\n",
      "2021-04-25 17:55:23,798 [INFO] Training: 5166/6852 -- loss: 1.8384569883346558\n",
      "2021-04-25 17:55:23,848 [INFO] Training: 5167/6852 -- loss: 1.8598893880844116\n",
      "2021-04-25 17:55:23,901 [INFO] Training: 5168/6852 -- loss: 2.6578516960144043\n",
      "2021-04-25 17:55:23,948 [INFO] Training: 5169/6852 -- loss: 1.319374442100525\n",
      "2021-04-25 17:55:24,002 [INFO] Training: 5170/6852 -- loss: 2.508669376373291\n",
      "2021-04-25 17:55:24,052 [INFO] Training: 5171/6852 -- loss: 1.506212830543518\n",
      "2021-04-25 17:55:24,104 [INFO] Training: 5172/6852 -- loss: 1.7771376371383667\n",
      "2021-04-25 17:55:24,154 [INFO] Training: 5173/6852 -- loss: 1.4539260864257812\n",
      "2021-04-25 17:55:24,205 [INFO] Training: 5174/6852 -- loss: 2.0906262397766113\n",
      "2021-04-25 17:55:24,253 [INFO] Training: 5175/6852 -- loss: 1.5358299016952515\n",
      "2021-04-25 17:55:24,306 [INFO] Training: 5176/6852 -- loss: 1.9269706010818481\n",
      "2021-04-25 17:55:24,355 [INFO] Training: 5177/6852 -- loss: 3.421372652053833\n",
      "2021-04-25 17:55:24,407 [INFO] Training: 5178/6852 -- loss: 1.256401777267456\n",
      "2021-04-25 17:55:24,453 [INFO] Training: 5179/6852 -- loss: 1.4953349828720093\n",
      "2021-04-25 17:55:24,503 [INFO] Training: 5180/6852 -- loss: 1.6092572212219238\n",
      "2021-04-25 17:55:24,553 [INFO] Training: 5181/6852 -- loss: 1.403381586074829\n",
      "2021-04-25 17:55:24,606 [INFO] Training: 5182/6852 -- loss: 1.7755380868911743\n",
      "2021-04-25 17:55:24,653 [INFO] Training: 5183/6852 -- loss: 1.5078163146972656\n",
      "2021-04-25 17:55:24,704 [INFO] Training: 5184/6852 -- loss: 1.881165862083435\n",
      "2021-04-25 17:55:24,757 [INFO] Training: 5185/6852 -- loss: 1.8376660346984863\n",
      "2021-04-25 17:55:24,804 [INFO] Training: 5186/6852 -- loss: 1.0295345783233643\n",
      "2021-04-25 17:55:24,854 [INFO] Training: 5187/6852 -- loss: 1.9783097505569458\n",
      "2021-04-25 17:55:24,906 [INFO] Training: 5188/6852 -- loss: 1.7621890306472778\n",
      "2021-04-25 17:55:24,955 [INFO] Training: 5189/6852 -- loss: 1.6866449117660522\n",
      "2021-04-25 17:55:25,003 [INFO] Training: 5190/6852 -- loss: 2.212669849395752\n",
      "2021-04-25 17:55:25,054 [INFO] Training: 5191/6852 -- loss: 2.9484810829162598\n",
      "2021-04-25 17:55:25,103 [INFO] Training: 5192/6852 -- loss: 2.1539852619171143\n",
      "2021-04-25 17:55:25,157 [INFO] Training: 5193/6852 -- loss: 2.511164903640747\n",
      "2021-04-25 17:55:25,209 [INFO] Training: 5194/6852 -- loss: 2.007810115814209\n",
      "2021-04-25 17:55:25,261 [INFO] Training: 5195/6852 -- loss: 1.5857092142105103\n",
      "2021-04-25 17:55:25,307 [INFO] Training: 5196/6852 -- loss: 2.004035234451294\n",
      "2021-04-25 17:55:25,359 [INFO] Training: 5197/6852 -- loss: 1.7165136337280273\n",
      "2021-04-25 17:55:25,411 [INFO] Training: 5198/6852 -- loss: 1.1939364671707153\n",
      "2021-04-25 17:55:25,460 [INFO] Training: 5199/6852 -- loss: 1.8098472356796265\n",
      "2021-04-25 17:55:25,511 [INFO] Training: 5200/6852 -- loss: 2.9511780738830566\n",
      "2021-04-25 17:55:25,559 [INFO] Training: 5201/6852 -- loss: 2.4181504249572754\n",
      "2021-04-25 17:55:25,608 [INFO] Training: 5202/6852 -- loss: 2.092632532119751\n",
      "2021-04-25 17:55:25,660 [INFO] Training: 5203/6852 -- loss: 2.4356191158294678\n",
      "2021-04-25 17:55:25,709 [INFO] Training: 5204/6852 -- loss: 1.5181384086608887\n",
      "2021-04-25 17:55:25,757 [INFO] Training: 5205/6852 -- loss: 2.0200257301330566\n",
      "2021-04-25 17:55:25,810 [INFO] Training: 5206/6852 -- loss: 1.9130299091339111\n",
      "2021-04-25 17:55:25,858 [INFO] Training: 5207/6852 -- loss: 2.358246326446533\n",
      "2021-04-25 17:55:25,911 [INFO] Training: 5208/6852 -- loss: 1.58958101272583\n",
      "2021-04-25 17:55:25,958 [INFO] Training: 5209/6852 -- loss: 2.8053953647613525\n",
      "2021-04-25 17:55:26,010 [INFO] Training: 5210/6852 -- loss: 2.9948601722717285\n",
      "2021-04-25 17:55:26,058 [INFO] Training: 5211/6852 -- loss: 2.311612129211426\n",
      "2021-04-25 17:55:26,109 [INFO] Training: 5212/6852 -- loss: 2.5331966876983643\n",
      "2021-04-25 17:55:26,156 [INFO] Training: 5213/6852 -- loss: 1.450189232826233\n",
      "2021-04-25 17:55:26,210 [INFO] Training: 5214/6852 -- loss: 1.245026707649231\n",
      "2021-04-25 17:55:26,258 [INFO] Training: 5215/6852 -- loss: 2.07334041595459\n",
      "2021-04-25 17:55:26,305 [INFO] Training: 5216/6852 -- loss: 1.457373857498169\n",
      "2021-04-25 17:55:26,355 [INFO] Training: 5217/6852 -- loss: 1.4155091047286987\n",
      "2021-04-25 17:55:26,403 [INFO] Training: 5218/6852 -- loss: 2.0452425479888916\n",
      "2021-04-25 17:55:26,450 [INFO] Training: 5219/6852 -- loss: 1.0559560060501099\n",
      "2021-04-25 17:55:26,499 [INFO] Training: 5220/6852 -- loss: 1.2795181274414062\n",
      "2021-04-25 17:55:26,551 [INFO] Training: 5221/6852 -- loss: 1.7854161262512207\n",
      "2021-04-25 17:55:26,600 [INFO] Training: 5222/6852 -- loss: 1.1358978748321533\n",
      "2021-04-25 17:55:26,653 [INFO] Training: 5223/6852 -- loss: 2.8789725303649902\n",
      "2021-04-25 17:55:26,701 [INFO] Training: 5224/6852 -- loss: 2.9845564365386963\n",
      "2021-04-25 17:55:26,749 [INFO] Training: 5225/6852 -- loss: 1.9345128536224365\n",
      "2021-04-25 17:55:26,803 [INFO] Training: 5226/6852 -- loss: 0.8537492752075195\n",
      "2021-04-25 17:55:26,856 [INFO] Training: 5227/6852 -- loss: 1.2111053466796875\n",
      "2021-04-25 17:55:26,905 [INFO] Training: 5228/6852 -- loss: 1.505211353302002\n",
      "2021-04-25 17:55:26,960 [INFO] Training: 5229/6852 -- loss: 1.9684162139892578\n",
      "2021-04-25 17:55:27,014 [INFO] Training: 5230/6852 -- loss: 2.3836793899536133\n",
      "2021-04-25 17:55:27,063 [INFO] Training: 5231/6852 -- loss: 1.2546463012695312\n",
      "2021-04-25 17:55:27,114 [INFO] Training: 5232/6852 -- loss: 1.7561662197113037\n",
      "2021-04-25 17:55:27,169 [INFO] Training: 5233/6852 -- loss: 2.178600311279297\n",
      "2021-04-25 17:55:27,217 [INFO] Training: 5234/6852 -- loss: 1.6519062519073486\n",
      "2021-04-25 17:55:27,265 [INFO] Training: 5235/6852 -- loss: 1.162664532661438\n",
      "2021-04-25 17:55:27,315 [INFO] Training: 5236/6852 -- loss: 1.4968650341033936\n",
      "2021-04-25 17:55:27,368 [INFO] Training: 5237/6852 -- loss: 1.353994369506836\n",
      "2021-04-25 17:55:27,416 [INFO] Training: 5238/6852 -- loss: 1.439013957977295\n",
      "2021-04-25 17:55:27,468 [INFO] Training: 5239/6852 -- loss: 2.6218385696411133\n",
      "2021-04-25 17:55:27,519 [INFO] Training: 5240/6852 -- loss: 1.5011088848114014\n",
      "2021-04-25 17:55:27,572 [INFO] Training: 5241/6852 -- loss: 2.3457624912261963\n",
      "2021-04-25 17:55:27,619 [INFO] Training: 5242/6852 -- loss: 1.9431567192077637\n",
      "2021-04-25 17:55:27,666 [INFO] Training: 5243/6852 -- loss: 1.3473825454711914\n",
      "2021-04-25 17:55:27,717 [INFO] Training: 5244/6852 -- loss: 2.4356164932250977\n",
      "2021-04-25 17:55:27,764 [INFO] Training: 5245/6852 -- loss: 1.6724295616149902\n",
      "2021-04-25 17:55:27,812 [INFO] Training: 5246/6852 -- loss: 1.7020230293273926\n",
      "2021-04-25 17:55:27,865 [INFO] Training: 5247/6852 -- loss: 1.6168450117111206\n",
      "2021-04-25 17:55:27,914 [INFO] Training: 5248/6852 -- loss: 3.6479127407073975\n",
      "2021-04-25 17:55:27,962 [INFO] Training: 5249/6852 -- loss: 1.3254684209823608\n",
      "2021-04-25 17:55:28,012 [INFO] Training: 5250/6852 -- loss: 2.4962997436523438\n",
      "2021-04-25 17:55:30,884 [INFO] Training: iteration: 5250/6852 -- epoch: 9 --  train_loss: 1.902 -- train_accuracy: 0.12 valid_loss: 3.219 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:55:30,920 [INFO] Training: 5251/6852 -- loss: 2.042494297027588\n",
      "2021-04-25 17:55:30,972 [INFO] Training: 5252/6852 -- loss: 1.7242591381072998\n",
      "2021-04-25 17:55:31,022 [INFO] Training: 5253/6852 -- loss: 1.4174394607543945\n",
      "2021-04-25 17:55:31,072 [INFO] Training: 5254/6852 -- loss: 2.3884518146514893\n",
      "2021-04-25 17:55:31,123 [INFO] Training: 5255/6852 -- loss: 1.7431631088256836\n",
      "2021-04-25 17:55:31,177 [INFO] Training: 5256/6852 -- loss: 1.070284366607666\n",
      "2021-04-25 17:55:31,230 [INFO] Training: 5257/6852 -- loss: 2.0630500316619873\n",
      "2021-04-25 17:55:31,276 [INFO] Training: 5258/6852 -- loss: 1.335198163986206\n",
      "2021-04-25 17:55:31,329 [INFO] Training: 5259/6852 -- loss: 1.8792433738708496\n",
      "2021-04-25 17:55:31,375 [INFO] Training: 5260/6852 -- loss: 2.322929620742798\n",
      "2021-04-25 17:55:31,426 [INFO] Training: 5261/6852 -- loss: 1.3925060033798218\n",
      "2021-04-25 17:55:31,476 [INFO] Training: 5262/6852 -- loss: 2.010072708129883\n",
      "2021-04-25 17:55:31,522 [INFO] Training: 5263/6852 -- loss: 2.5710201263427734\n",
      "2021-04-25 17:55:31,571 [INFO] Training: 5264/6852 -- loss: 2.205749273300171\n",
      "2021-04-25 17:55:31,619 [INFO] Training: 5265/6852 -- loss: 1.7233693599700928\n",
      "2021-04-25 17:55:31,668 [INFO] Training: 5266/6852 -- loss: 1.2555650472640991\n",
      "2021-04-25 17:55:31,715 [INFO] Training: 5267/6852 -- loss: 2.113032341003418\n",
      "2021-04-25 17:55:31,764 [INFO] Training: 5268/6852 -- loss: 2.3976199626922607\n",
      "2021-04-25 17:55:31,814 [INFO] Training: 5269/6852 -- loss: 2.1293997764587402\n",
      "2021-04-25 17:55:31,868 [INFO] Training: 5270/6852 -- loss: 2.024010181427002\n",
      "2021-04-25 17:55:31,917 [INFO] Training: 5271/6852 -- loss: 1.5124928951263428\n",
      "2021-04-25 17:55:31,970 [INFO] Training: 5272/6852 -- loss: 1.5498930215835571\n",
      "2021-04-25 17:55:32,021 [INFO] Training: 5273/6852 -- loss: 1.333125114440918\n",
      "2021-04-25 17:55:32,074 [INFO] Training: 5274/6852 -- loss: 1.4019360542297363\n",
      "2021-04-25 17:55:32,126 [INFO] Training: 5275/6852 -- loss: 2.271446704864502\n",
      "2021-04-25 17:55:32,172 [INFO] Training: 5276/6852 -- loss: 2.247936248779297\n",
      "2021-04-25 17:55:32,224 [INFO] Training: 5277/6852 -- loss: 2.5014710426330566\n",
      "2021-04-25 17:55:32,277 [INFO] Training: 5278/6852 -- loss: 1.3895686864852905\n",
      "2021-04-25 17:55:32,327 [INFO] Training: 5279/6852 -- loss: 1.0803226232528687\n",
      "2021-04-25 17:55:32,378 [INFO] Training: 5280/6852 -- loss: 2.8354086875915527\n",
      "2021-04-25 17:55:32,426 [INFO] Training: 5281/6852 -- loss: 1.604880690574646\n",
      "2021-04-25 17:55:32,473 [INFO] Training: 5282/6852 -- loss: 2.0620932579040527\n",
      "2021-04-25 17:55:32,522 [INFO] Training: 5283/6852 -- loss: 1.889091968536377\n",
      "2021-04-25 17:55:32,571 [INFO] Training: 5284/6852 -- loss: 1.5549546480178833\n",
      "2021-04-25 17:55:32,622 [INFO] Training: 5285/6852 -- loss: 1.9565856456756592\n",
      "2021-04-25 17:55:32,673 [INFO] Training: 5286/6852 -- loss: 1.837141513824463\n",
      "2021-04-25 17:55:32,719 [INFO] Training: 5287/6852 -- loss: 1.911095142364502\n",
      "2021-04-25 17:55:32,771 [INFO] Training: 5288/6852 -- loss: 2.088099241256714\n",
      "2021-04-25 17:55:32,819 [INFO] Training: 5289/6852 -- loss: 2.2821621894836426\n",
      "2021-04-25 17:55:32,871 [INFO] Training: 5290/6852 -- loss: 1.9443402290344238\n",
      "2021-04-25 17:55:32,919 [INFO] Training: 5291/6852 -- loss: 1.278353214263916\n",
      "2021-04-25 17:55:32,966 [INFO] Training: 5292/6852 -- loss: 1.801364779472351\n",
      "2021-04-25 17:55:33,015 [INFO] Training: 5293/6852 -- loss: 1.9802839756011963\n",
      "2021-04-25 17:55:33,063 [INFO] Training: 5294/6852 -- loss: 1.5451664924621582\n",
      "2021-04-25 17:55:33,115 [INFO] Training: 5295/6852 -- loss: 1.6072601079940796\n",
      "2021-04-25 17:55:33,167 [INFO] Training: 5296/6852 -- loss: 1.244383454322815\n",
      "2021-04-25 17:55:33,219 [INFO] Training: 5297/6852 -- loss: 1.7831833362579346\n",
      "2021-04-25 17:55:33,270 [INFO] Training: 5298/6852 -- loss: 0.9209582209587097\n",
      "2021-04-25 17:55:33,321 [INFO] Training: 5299/6852 -- loss: 2.479635238647461\n",
      "2021-04-25 17:55:33,369 [INFO] Training: 5300/6852 -- loss: 1.9507806301116943\n",
      "2021-04-25 17:55:33,416 [INFO] Training: 5301/6852 -- loss: 2.9909932613372803\n",
      "2021-04-25 17:55:33,469 [INFO] Training: 5302/6852 -- loss: 1.7742931842803955\n",
      "2021-04-25 17:55:33,518 [INFO] Training: 5303/6852 -- loss: 1.9985309839248657\n",
      "2021-04-25 17:55:33,567 [INFO] Training: 5304/6852 -- loss: 2.345881462097168\n",
      "2021-04-25 17:55:33,623 [INFO] Training: 5305/6852 -- loss: 0.7233526706695557\n",
      "2021-04-25 17:55:33,671 [INFO] Training: 5306/6852 -- loss: 1.7734508514404297\n",
      "2021-04-25 17:55:33,722 [INFO] Training: 5307/6852 -- loss: 2.3075966835021973\n",
      "2021-04-25 17:55:33,769 [INFO] Training: 5308/6852 -- loss: 1.1757673025131226\n",
      "2021-04-25 17:55:33,820 [INFO] Training: 5309/6852 -- loss: 2.372267246246338\n",
      "2021-04-25 17:55:33,870 [INFO] Training: 5310/6852 -- loss: 1.863905429840088\n",
      "2021-04-25 17:55:33,922 [INFO] Training: 5311/6852 -- loss: 1.4423861503601074\n",
      "2021-04-25 17:55:33,973 [INFO] Training: 5312/6852 -- loss: 1.6387240886688232\n",
      "2021-04-25 17:55:34,025 [INFO] Training: 5313/6852 -- loss: 1.5932925939559937\n",
      "2021-04-25 17:55:34,072 [INFO] Training: 5314/6852 -- loss: 1.5321271419525146\n",
      "2021-04-25 17:55:34,121 [INFO] Training: 5315/6852 -- loss: 1.5867884159088135\n",
      "2021-04-25 17:55:34,171 [INFO] Training: 5316/6852 -- loss: 1.7071149349212646\n",
      "2021-04-25 17:55:34,221 [INFO] Training: 5317/6852 -- loss: 3.011213779449463\n",
      "2021-04-25 17:55:34,271 [INFO] Training: 5318/6852 -- loss: 1.7406020164489746\n",
      "2021-04-25 17:55:34,324 [INFO] Training: 5319/6852 -- loss: 2.9875402450561523\n",
      "2021-04-25 17:55:34,373 [INFO] Training: 5320/6852 -- loss: 1.4764742851257324\n",
      "2021-04-25 17:55:34,421 [INFO] Training: 5321/6852 -- loss: 2.2404944896698\n",
      "2021-04-25 17:55:34,475 [INFO] Training: 5322/6852 -- loss: 0.8072108030319214\n",
      "2021-04-25 17:55:34,526 [INFO] Training: 5323/6852 -- loss: 1.604025959968567\n",
      "2021-04-25 17:55:34,578 [INFO] Training: 5324/6852 -- loss: 1.2439384460449219\n",
      "2021-04-25 17:55:34,631 [INFO] Training: 5325/6852 -- loss: 1.3834035396575928\n",
      "2021-04-25 17:55:34,681 [INFO] Training: 5326/6852 -- loss: 3.2206926345825195\n",
      "2021-04-25 17:55:34,731 [INFO] Training: 5327/6852 -- loss: 2.1267457008361816\n",
      "2021-04-25 17:55:34,779 [INFO] Training: 5328/6852 -- loss: 2.1798579692840576\n",
      "2021-04-25 17:55:34,827 [INFO] Training: 5329/6852 -- loss: 3.116779088973999\n",
      "2021-04-25 17:55:34,877 [INFO] Training: 5330/6852 -- loss: 1.8319857120513916\n",
      "2021-04-25 17:55:34,926 [INFO] Training: 5331/6852 -- loss: 1.9059979915618896\n",
      "2021-04-25 17:55:34,974 [INFO] Training: 5332/6852 -- loss: 2.3430004119873047\n",
      "2021-04-25 17:55:35,022 [INFO] Training: 5333/6852 -- loss: 1.4685536623001099\n",
      "2021-04-25 17:55:35,073 [INFO] Training: 5334/6852 -- loss: 1.6157870292663574\n",
      "2021-04-25 17:55:35,126 [INFO] Training: 5335/6852 -- loss: 0.7785442471504211\n",
      "2021-04-25 17:55:35,175 [INFO] Training: 5336/6852 -- loss: 1.2451895475387573\n",
      "2021-04-25 17:55:35,228 [INFO] Training: 5337/6852 -- loss: 1.5497376918792725\n",
      "2021-04-25 17:55:35,274 [INFO] Training: 5338/6852 -- loss: 2.1249613761901855\n",
      "2021-04-25 17:55:35,328 [INFO] Training: 5339/6852 -- loss: 1.7344509363174438\n",
      "2021-04-25 17:55:35,378 [INFO] Training: 5340/6852 -- loss: 1.1605132818222046\n",
      "2021-04-25 17:55:35,426 [INFO] Training: 5341/6852 -- loss: 1.8396100997924805\n",
      "2021-04-25 17:55:35,475 [INFO] Training: 5342/6852 -- loss: 1.7173882722854614\n",
      "2021-04-25 17:55:35,521 [INFO] Training: 5343/6852 -- loss: 1.3618887662887573\n",
      "2021-04-25 17:55:35,572 [INFO] Training: 5344/6852 -- loss: 2.010308265686035\n",
      "2021-04-25 17:55:35,621 [INFO] Training: 5345/6852 -- loss: 2.975651502609253\n",
      "2021-04-25 17:55:35,673 [INFO] Training: 5346/6852 -- loss: 2.6195831298828125\n",
      "2021-04-25 17:55:35,723 [INFO] Training: 5347/6852 -- loss: 2.6391546726226807\n",
      "2021-04-25 17:55:35,775 [INFO] Training: 5348/6852 -- loss: 1.649163842201233\n",
      "2021-04-25 17:55:35,824 [INFO] Training: 5349/6852 -- loss: 1.044995665550232\n",
      "2021-04-25 17:55:35,872 [INFO] Training: 5350/6852 -- loss: 1.045335292816162\n",
      "2021-04-25 17:55:35,922 [INFO] Training: 5351/6852 -- loss: 2.053297519683838\n",
      "2021-04-25 17:55:35,970 [INFO] Training: 5352/6852 -- loss: 1.6678953170776367\n",
      "2021-04-25 17:55:36,021 [INFO] Training: 5353/6852 -- loss: 1.7275950908660889\n",
      "2021-04-25 17:55:36,078 [INFO] Training: 5354/6852 -- loss: 1.9355950355529785\n",
      "2021-04-25 17:55:36,128 [INFO] Training: 5355/6852 -- loss: 1.3267860412597656\n",
      "2021-04-25 17:55:36,179 [INFO] Training: 5356/6852 -- loss: 1.415405511856079\n",
      "2021-04-25 17:55:36,230 [INFO] Training: 5357/6852 -- loss: 1.5152934789657593\n",
      "2021-04-25 17:55:36,278 [INFO] Training: 5358/6852 -- loss: 1.666002631187439\n",
      "2021-04-25 17:55:36,328 [INFO] Training: 5359/6852 -- loss: 1.5922945737838745\n",
      "2021-04-25 17:55:36,376 [INFO] Training: 5360/6852 -- loss: 1.8230724334716797\n",
      "2021-04-25 17:55:36,426 [INFO] Training: 5361/6852 -- loss: 2.1403090953826904\n",
      "2021-04-25 17:55:36,475 [INFO] Training: 5362/6852 -- loss: 1.6456642150878906\n",
      "2021-04-25 17:55:36,521 [INFO] Training: 5363/6852 -- loss: 1.4354912042617798\n",
      "2021-04-25 17:55:36,571 [INFO] Training: 5364/6852 -- loss: 1.4040011167526245\n",
      "2021-04-25 17:55:36,622 [INFO] Training: 5365/6852 -- loss: 1.8405585289001465\n",
      "2021-04-25 17:55:36,670 [INFO] Training: 5366/6852 -- loss: 1.3667186498641968\n",
      "2021-04-25 17:55:36,719 [INFO] Training: 5367/6852 -- loss: 1.8745534420013428\n",
      "2021-04-25 17:55:36,767 [INFO] Training: 5368/6852 -- loss: 1.9189010858535767\n",
      "2021-04-25 17:55:36,820 [INFO] Training: 5369/6852 -- loss: 1.696571946144104\n",
      "2021-04-25 17:55:36,869 [INFO] Training: 5370/6852 -- loss: 1.8477308750152588\n",
      "2021-04-25 17:55:36,919 [INFO] Training: 5371/6852 -- loss: 2.5190610885620117\n",
      "2021-04-25 17:55:36,969 [INFO] Training: 5372/6852 -- loss: 1.5923982858657837\n",
      "2021-04-25 17:55:37,025 [INFO] Training: 5373/6852 -- loss: 1.5475584268569946\n",
      "2021-04-25 17:55:37,071 [INFO] Training: 5374/6852 -- loss: 1.1454397439956665\n",
      "2021-04-25 17:55:37,119 [INFO] Training: 5375/6852 -- loss: 1.8562803268432617\n",
      "2021-04-25 17:55:37,170 [INFO] Training: 5376/6852 -- loss: 2.4640564918518066\n",
      "2021-04-25 17:55:37,221 [INFO] Training: 5377/6852 -- loss: 1.2613813877105713\n",
      "2021-04-25 17:55:37,271 [INFO] Training: 5378/6852 -- loss: 1.9856584072113037\n",
      "2021-04-25 17:55:37,325 [INFO] Training: 5379/6852 -- loss: 3.2611072063446045\n",
      "2021-04-25 17:55:37,375 [INFO] Training: 5380/6852 -- loss: 1.3125576972961426\n",
      "2021-04-25 17:55:37,425 [INFO] Training: 5381/6852 -- loss: 3.062680721282959\n",
      "2021-04-25 17:55:37,476 [INFO] Training: 5382/6852 -- loss: 3.0589401721954346\n",
      "2021-04-25 17:55:37,526 [INFO] Training: 5383/6852 -- loss: 1.5077881813049316\n",
      "2021-04-25 17:55:37,578 [INFO] Training: 5384/6852 -- loss: 2.577134132385254\n",
      "2021-04-25 17:55:37,630 [INFO] Training: 5385/6852 -- loss: 1.9424370527267456\n",
      "2021-04-25 17:55:37,679 [INFO] Training: 5386/6852 -- loss: 2.7092502117156982\n",
      "2021-04-25 17:55:37,732 [INFO] Training: 5387/6852 -- loss: 1.3466063737869263\n",
      "2021-04-25 17:55:37,779 [INFO] Training: 5388/6852 -- loss: 2.6341092586517334\n",
      "2021-04-25 17:55:37,825 [INFO] Training: 5389/6852 -- loss: 2.7066991329193115\n",
      "2021-04-25 17:55:37,879 [INFO] Training: 5390/6852 -- loss: 2.3422904014587402\n",
      "2021-04-25 17:55:37,930 [INFO] Training: 5391/6852 -- loss: 1.5430189371109009\n",
      "2021-04-25 17:55:37,981 [INFO] Training: 5392/6852 -- loss: 1.8686422109603882\n",
      "2021-04-25 17:55:38,032 [INFO] Training: 5393/6852 -- loss: 2.126608371734619\n",
      "2021-04-25 17:55:38,081 [INFO] Training: 5394/6852 -- loss: 2.57102108001709\n",
      "2021-04-25 17:55:38,129 [INFO] Training: 5395/6852 -- loss: 1.9530595541000366\n",
      "2021-04-25 17:55:38,176 [INFO] Training: 5396/6852 -- loss: 2.132559299468994\n",
      "2021-04-25 17:55:38,227 [INFO] Training: 5397/6852 -- loss: 1.4900462627410889\n",
      "2021-04-25 17:55:38,280 [INFO] Training: 5398/6852 -- loss: 2.5604119300842285\n",
      "2021-04-25 17:55:38,328 [INFO] Training: 5399/6852 -- loss: 1.771554946899414\n",
      "2021-04-25 17:55:38,375 [INFO] Training: 5400/6852 -- loss: 2.0497403144836426\n",
      "2021-04-25 17:55:41,256 [INFO] Training: iteration: 5400/6852 -- epoch: 9 --  train_loss: 1.874 -- train_accuracy: 0.50 valid_loss: 3.190 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:55:41,299 [INFO] Training: 5401/6852 -- loss: 1.9738706350326538\n",
      "2021-04-25 17:55:41,347 [INFO] Training: 5402/6852 -- loss: 1.4793399572372437\n",
      "2021-04-25 17:55:41,397 [INFO] Training: 5403/6852 -- loss: 1.473087191581726\n",
      "2021-04-25 17:55:41,444 [INFO] Training: 5404/6852 -- loss: 3.633053779602051\n",
      "2021-04-25 17:55:41,492 [INFO] Training: 5405/6852 -- loss: 1.4024581909179688\n",
      "2021-04-25 17:55:41,540 [INFO] Training: 5406/6852 -- loss: 2.105835437774658\n",
      "2021-04-25 17:55:41,588 [INFO] Training: 5407/6852 -- loss: 2.606492042541504\n",
      "2021-04-25 17:55:41,636 [INFO] Training: 5408/6852 -- loss: 2.0906925201416016\n",
      "2021-04-25 17:55:41,686 [INFO] Training: 5409/6852 -- loss: 1.6809473037719727\n",
      "2021-04-25 17:55:41,734 [INFO] Training: 5410/6852 -- loss: 2.066371440887451\n",
      "2021-04-25 17:55:41,785 [INFO] Training: 5411/6852 -- loss: 1.7953884601593018\n",
      "2021-04-25 17:55:41,835 [INFO] Training: 5412/6852 -- loss: 2.24096417427063\n",
      "2021-04-25 17:55:41,886 [INFO] Training: 5413/6852 -- loss: 1.9711768627166748\n",
      "2021-04-25 17:55:41,940 [INFO] Training: 5414/6852 -- loss: 1.668166160583496\n",
      "2021-04-25 17:55:41,992 [INFO] Training: 5415/6852 -- loss: 1.9551743268966675\n",
      "2021-04-25 17:55:42,044 [INFO] Training: 5416/6852 -- loss: 2.553915500640869\n",
      "2021-04-25 17:55:42,092 [INFO] Training: 5417/6852 -- loss: 1.035624623298645\n",
      "2021-04-25 17:55:42,139 [INFO] Training: 5418/6852 -- loss: 0.8182417154312134\n",
      "2021-04-25 17:55:42,192 [INFO] Training: 5419/6852 -- loss: 1.4278111457824707\n",
      "2021-04-25 17:55:42,240 [INFO] Training: 5420/6852 -- loss: 2.5933144092559814\n",
      "2021-04-25 17:55:42,290 [INFO] Training: 5421/6852 -- loss: 1.3150545358657837\n",
      "2021-04-25 17:55:42,341 [INFO] Training: 5422/6852 -- loss: 1.5499299764633179\n",
      "2021-04-25 17:55:42,388 [INFO] Training: 5423/6852 -- loss: 1.4534368515014648\n",
      "2021-04-25 17:55:42,437 [INFO] Training: 5424/6852 -- loss: 1.6515424251556396\n",
      "2021-04-25 17:55:42,485 [INFO] Training: 5425/6852 -- loss: 1.533400535583496\n",
      "2021-04-25 17:55:42,535 [INFO] Training: 5426/6852 -- loss: 2.2825400829315186\n",
      "2021-04-25 17:55:42,583 [INFO] Training: 5427/6852 -- loss: 4.50831937789917\n",
      "2021-04-25 17:55:42,634 [INFO] Training: 5428/6852 -- loss: 1.050957441329956\n",
      "2021-04-25 17:55:42,685 [INFO] Training: 5429/6852 -- loss: 2.2680931091308594\n",
      "2021-04-25 17:55:42,732 [INFO] Training: 5430/6852 -- loss: 2.466948986053467\n",
      "2021-04-25 17:55:42,782 [INFO] Training: 5431/6852 -- loss: 1.2440122365951538\n",
      "2021-04-25 17:55:42,829 [INFO] Training: 5432/6852 -- loss: 2.0663771629333496\n",
      "2021-04-25 17:55:42,882 [INFO] Training: 5433/6852 -- loss: 1.9238090515136719\n",
      "2021-04-25 17:55:42,933 [INFO] Training: 5434/6852 -- loss: 2.0677177906036377\n",
      "2021-04-25 17:55:42,985 [INFO] Training: 5435/6852 -- loss: 1.4686070680618286\n",
      "2021-04-25 17:55:43,036 [INFO] Training: 5436/6852 -- loss: 1.3560717105865479\n",
      "2021-04-25 17:55:43,091 [INFO] Training: 5437/6852 -- loss: 1.6845842599868774\n",
      "2021-04-25 17:55:43,139 [INFO] Training: 5438/6852 -- loss: 1.598785638809204\n",
      "2021-04-25 17:55:43,191 [INFO] Training: 5439/6852 -- loss: 1.6783603429794312\n",
      "2021-04-25 17:55:43,243 [INFO] Training: 5440/6852 -- loss: 1.3277033567428589\n",
      "2021-04-25 17:55:43,295 [INFO] Training: 5441/6852 -- loss: 1.982177495956421\n",
      "2021-04-25 17:55:43,345 [INFO] Training: 5442/6852 -- loss: 1.4587671756744385\n",
      "2021-04-25 17:55:43,399 [INFO] Training: 5443/6852 -- loss: 2.530470132827759\n",
      "2021-04-25 17:55:43,447 [INFO] Training: 5444/6852 -- loss: 1.6808274984359741\n",
      "2021-04-25 17:55:43,496 [INFO] Training: 5445/6852 -- loss: 2.2435896396636963\n",
      "2021-04-25 17:55:43,545 [INFO] Training: 5446/6852 -- loss: 1.7064086198806763\n",
      "2021-04-25 17:55:43,596 [INFO] Training: 5447/6852 -- loss: 1.8902740478515625\n",
      "2021-04-25 17:55:43,643 [INFO] Training: 5448/6852 -- loss: 1.8486502170562744\n",
      "2021-04-25 17:55:43,696 [INFO] Training: 5449/6852 -- loss: 2.0471081733703613\n",
      "2021-04-25 17:55:43,750 [INFO] Training: 5450/6852 -- loss: 2.16013765335083\n",
      "2021-04-25 17:55:43,800 [INFO] Training: 5451/6852 -- loss: 1.4207987785339355\n",
      "2021-04-25 17:55:43,853 [INFO] Training: 5452/6852 -- loss: 2.6335911750793457\n",
      "2021-04-25 17:55:43,903 [INFO] Training: 5453/6852 -- loss: 2.1001992225646973\n",
      "2021-04-25 17:55:43,957 [INFO] Training: 5454/6852 -- loss: 2.119229316711426\n",
      "2021-04-25 17:55:44,010 [INFO] Training: 5455/6852 -- loss: 1.9561175107955933\n",
      "2021-04-25 17:55:44,061 [INFO] Training: 5456/6852 -- loss: 1.4554592370986938\n",
      "2021-04-25 17:55:44,112 [INFO] Training: 5457/6852 -- loss: 1.1441967487335205\n",
      "2021-04-25 17:55:44,162 [INFO] Training: 5458/6852 -- loss: 2.952338457107544\n",
      "2021-04-25 17:55:44,213 [INFO] Training: 5459/6852 -- loss: 1.4592809677124023\n",
      "2021-04-25 17:55:44,265 [INFO] Training: 5460/6852 -- loss: 1.4380300045013428\n",
      "2021-04-25 17:55:44,311 [INFO] Training: 5461/6852 -- loss: 1.6078232526779175\n",
      "2021-04-25 17:55:44,364 [INFO] Training: 5462/6852 -- loss: 1.473168134689331\n",
      "2021-04-25 17:55:44,412 [INFO] Training: 5463/6852 -- loss: 1.635733962059021\n",
      "2021-04-25 17:55:44,461 [INFO] Training: 5464/6852 -- loss: 0.9282535314559937\n",
      "2021-04-25 17:55:44,514 [INFO] Training: 5465/6852 -- loss: 2.2692060470581055\n",
      "2021-04-25 17:55:44,563 [INFO] Training: 5466/6852 -- loss: 2.1130564212799072\n",
      "2021-04-25 17:55:44,616 [INFO] Training: 5467/6852 -- loss: 2.7881293296813965\n",
      "2021-04-25 17:55:44,663 [INFO] Training: 5468/6852 -- loss: 1.5371925830841064\n",
      "2021-04-25 17:55:44,719 [INFO] Training: 5469/6852 -- loss: 1.2223267555236816\n",
      "2021-04-25 17:55:44,765 [INFO] Training: 5470/6852 -- loss: 2.038033962249756\n",
      "2021-04-25 17:55:44,817 [INFO] Training: 5471/6852 -- loss: 2.299381732940674\n",
      "2021-04-25 17:55:44,869 [INFO] Training: 5472/6852 -- loss: 1.9114556312561035\n",
      "2021-04-25 17:55:44,921 [INFO] Training: 5473/6852 -- loss: 1.636937141418457\n",
      "2021-04-25 17:55:44,968 [INFO] Training: 5474/6852 -- loss: 2.4023728370666504\n",
      "2021-04-25 17:55:45,023 [INFO] Training: 5475/6852 -- loss: 1.572054147720337\n",
      "2021-04-25 17:55:45,076 [INFO] Training: 5476/6852 -- loss: 2.444101572036743\n",
      "2021-04-25 17:55:45,127 [INFO] Training: 5477/6852 -- loss: 1.1071033477783203\n",
      "2021-04-25 17:55:45,173 [INFO] Training: 5478/6852 -- loss: 1.5358920097351074\n",
      "2021-04-25 17:55:45,226 [INFO] Training: 5479/6852 -- loss: 2.9417033195495605\n",
      "2021-04-25 17:55:45,275 [INFO] Training: 5480/6852 -- loss: 1.7225053310394287\n",
      "2021-04-25 17:55:45,329 [INFO] Training: 5481/6852 -- loss: 1.7179808616638184\n",
      "2021-04-25 17:55:45,375 [INFO] Training: 5482/6852 -- loss: 1.538804531097412\n",
      "2021-04-25 17:55:45,427 [INFO] Training: 5483/6852 -- loss: 1.8764086961746216\n",
      "2021-04-25 17:55:45,480 [INFO] Training: 5484/6852 -- loss: 1.3770099878311157\n",
      "2021-04-25 17:55:45,532 [INFO] Training: 5485/6852 -- loss: 0.8834465146064758\n",
      "2021-04-25 17:55:45,586 [INFO] Training: 5486/6852 -- loss: 1.2028613090515137\n",
      "2021-04-25 17:55:45,634 [INFO] Training: 5487/6852 -- loss: 1.8826396465301514\n",
      "2021-04-25 17:55:45,684 [INFO] Training: 5488/6852 -- loss: 2.3031389713287354\n",
      "2021-04-25 17:55:45,733 [INFO] Training: 5489/6852 -- loss: 2.7805891036987305\n",
      "2021-04-25 17:55:45,781 [INFO] Training: 5490/6852 -- loss: 2.0814871788024902\n",
      "2021-04-25 17:55:45,830 [INFO] Training: 5491/6852 -- loss: 2.1099045276641846\n",
      "2021-04-25 17:55:45,878 [INFO] Training: 5492/6852 -- loss: 1.3277273178100586\n",
      "2021-04-25 17:55:45,929 [INFO] Training: 5493/6852 -- loss: 1.2700731754302979\n",
      "2021-04-25 17:55:45,980 [INFO] Training: 5494/6852 -- loss: 1.3319836854934692\n",
      "2021-04-25 17:55:46,030 [INFO] Training: 5495/6852 -- loss: 1.5698513984680176\n",
      "2021-04-25 17:55:46,080 [INFO] Training: 5496/6852 -- loss: 2.2335896492004395\n",
      "2021-04-25 17:55:46,132 [INFO] Training: 5497/6852 -- loss: 2.063751697540283\n",
      "2021-04-25 17:55:46,181 [INFO] Training: 5498/6852 -- loss: 1.3939610719680786\n",
      "2021-04-25 17:55:46,229 [INFO] Training: 5499/6852 -- loss: 2.8168718814849854\n",
      "2021-04-25 17:55:46,279 [INFO] Training: 5500/6852 -- loss: 2.5005242824554443\n",
      "2021-04-25 17:55:46,335 [INFO] Training: 5501/6852 -- loss: 1.576877236366272\n",
      "2021-04-25 17:55:46,383 [INFO] Training: 5502/6852 -- loss: 3.3177013397216797\n",
      "2021-04-25 17:55:46,437 [INFO] Training: 5503/6852 -- loss: 1.0280996561050415\n",
      "2021-04-25 17:55:46,486 [INFO] Training: 5504/6852 -- loss: 1.2246253490447998\n",
      "2021-04-25 17:55:46,534 [INFO] Training: 5505/6852 -- loss: 1.827507495880127\n",
      "2021-04-25 17:55:46,586 [INFO] Training: 5506/6852 -- loss: 0.9669487476348877\n",
      "2021-04-25 17:55:46,636 [INFO] Training: 5507/6852 -- loss: 1.2274693250656128\n",
      "2021-04-25 17:55:46,687 [INFO] Training: 5508/6852 -- loss: 2.6664791107177734\n",
      "2021-04-25 17:55:46,734 [INFO] Training: 5509/6852 -- loss: 1.4744027853012085\n",
      "2021-04-25 17:55:46,781 [INFO] Training: 5510/6852 -- loss: 2.060253858566284\n",
      "2021-04-25 17:55:46,831 [INFO] Training: 5511/6852 -- loss: 2.1684861183166504\n",
      "2021-04-25 17:55:46,880 [INFO] Training: 5512/6852 -- loss: 3.583096742630005\n",
      "2021-04-25 17:55:46,932 [INFO] Training: 5513/6852 -- loss: 1.7299917936325073\n",
      "2021-04-25 17:55:46,978 [INFO] Training: 5514/6852 -- loss: 2.3908400535583496\n",
      "2021-04-25 17:55:47,026 [INFO] Training: 5515/6852 -- loss: 2.620151996612549\n",
      "2021-04-25 17:55:47,075 [INFO] Training: 5516/6852 -- loss: 1.7404927015304565\n",
      "2021-04-25 17:55:47,127 [INFO] Training: 5517/6852 -- loss: 1.9446793794631958\n",
      "2021-04-25 17:55:47,178 [INFO] Training: 5518/6852 -- loss: 2.0358927249908447\n",
      "2021-04-25 17:55:47,229 [INFO] Training: 5519/6852 -- loss: 1.8455064296722412\n",
      "2021-04-25 17:55:47,280 [INFO] Training: 5520/6852 -- loss: 2.8804945945739746\n",
      "2021-04-25 17:55:47,328 [INFO] Training: 5521/6852 -- loss: 1.868921160697937\n",
      "2021-04-25 17:55:47,379 [INFO] Training: 5522/6852 -- loss: 1.6917569637298584\n",
      "2021-04-25 17:55:47,432 [INFO] Training: 5523/6852 -- loss: 1.6264622211456299\n",
      "2021-04-25 17:55:47,488 [INFO] Training: 5524/6852 -- loss: 1.5731375217437744\n",
      "2021-04-25 17:55:47,537 [INFO] Training: 5525/6852 -- loss: 2.193904161453247\n",
      "2021-04-25 17:55:47,587 [INFO] Training: 5526/6852 -- loss: 1.2229729890823364\n",
      "2021-04-25 17:55:47,637 [INFO] Training: 5527/6852 -- loss: 2.8009157180786133\n",
      "2021-04-25 17:55:47,689 [INFO] Training: 5528/6852 -- loss: 2.109250545501709\n",
      "2021-04-25 17:55:47,737 [INFO] Training: 5529/6852 -- loss: 2.4929604530334473\n",
      "2021-04-25 17:55:47,787 [INFO] Training: 5530/6852 -- loss: 2.1612462997436523\n",
      "2021-04-25 17:55:47,834 [INFO] Training: 5531/6852 -- loss: 2.0973269939422607\n",
      "2021-04-25 17:55:47,882 [INFO] Training: 5532/6852 -- loss: 1.9691803455352783\n",
      "2021-04-25 17:55:47,932 [INFO] Training: 5533/6852 -- loss: 1.4187065362930298\n",
      "2021-04-25 17:55:47,981 [INFO] Training: 5534/6852 -- loss: 2.0121607780456543\n",
      "2021-04-25 17:55:48,032 [INFO] Training: 5535/6852 -- loss: 2.464301109313965\n",
      "2021-04-25 17:55:48,086 [INFO] Training: 5536/6852 -- loss: 1.7268754243850708\n",
      "2021-04-25 17:55:48,137 [INFO] Training: 5537/6852 -- loss: 2.540091037750244\n",
      "2021-04-25 17:55:48,186 [INFO] Training: 5538/6852 -- loss: 1.8325021266937256\n",
      "2021-04-25 17:55:48,236 [INFO] Training: 5539/6852 -- loss: 2.0081801414489746\n",
      "2021-04-25 17:55:48,284 [INFO] Training: 5540/6852 -- loss: 1.7227694988250732\n",
      "2021-04-25 17:55:48,337 [INFO] Training: 5541/6852 -- loss: 2.0216312408447266\n",
      "2021-04-25 17:55:48,386 [INFO] Training: 5542/6852 -- loss: 1.3874056339263916\n",
      "2021-04-25 17:55:48,437 [INFO] Training: 5543/6852 -- loss: 1.9083728790283203\n",
      "2021-04-25 17:55:48,489 [INFO] Training: 5544/6852 -- loss: 2.5555453300476074\n",
      "2021-04-25 17:55:48,540 [INFO] Training: 5545/6852 -- loss: 1.3760089874267578\n",
      "2021-04-25 17:55:48,587 [INFO] Training: 5546/6852 -- loss: 1.811395525932312\n",
      "2021-04-25 17:55:48,635 [INFO] Training: 5547/6852 -- loss: 1.1916162967681885\n",
      "2021-04-25 17:55:48,688 [INFO] Training: 5548/6852 -- loss: 1.8486528396606445\n",
      "2021-04-25 17:55:48,734 [INFO] Training: 5549/6852 -- loss: 1.8064221143722534\n",
      "2021-04-25 17:55:48,785 [INFO] Training: 5550/6852 -- loss: 1.2336392402648926\n",
      "2021-04-25 17:55:51,631 [INFO] Training: iteration: 5550/6852 -- epoch: 9 --  train_loss: 1.892 -- train_accuracy: 0.62 valid_loss: 3.180 -- valid_accuracy: 0.30\n",
      "2021-04-25 17:55:51,680 [INFO] Training: 5551/6852 -- loss: 1.1807109117507935\n",
      "2021-04-25 17:55:51,728 [INFO] Training: 5552/6852 -- loss: 1.9514700174331665\n",
      "2021-04-25 17:55:51,781 [INFO] Training: 5553/6852 -- loss: 1.6364773511886597\n",
      "2021-04-25 17:55:51,836 [INFO] Training: 5554/6852 -- loss: 2.511751890182495\n",
      "2021-04-25 17:55:51,885 [INFO] Training: 5555/6852 -- loss: 1.73448646068573\n",
      "2021-04-25 17:55:51,932 [INFO] Training: 5556/6852 -- loss: 1.5938985347747803\n",
      "2021-04-25 17:55:51,983 [INFO] Training: 5557/6852 -- loss: 1.7038524150848389\n",
      "2021-04-25 17:55:52,029 [INFO] Training: 5558/6852 -- loss: 2.8710567951202393\n",
      "2021-04-25 17:55:52,077 [INFO] Training: 5559/6852 -- loss: 1.773667812347412\n",
      "2021-04-25 17:55:52,128 [INFO] Training: 5560/6852 -- loss: 2.761302947998047\n",
      "2021-04-25 17:55:52,178 [INFO] Training: 5561/6852 -- loss: 1.8227007389068604\n",
      "2021-04-25 17:55:52,232 [INFO] Training: 5562/6852 -- loss: 1.650560736656189\n",
      "2021-04-25 17:55:52,280 [INFO] Training: 5563/6852 -- loss: 2.27675461769104\n",
      "2021-04-25 17:55:52,328 [INFO] Training: 5564/6852 -- loss: 1.5494098663330078\n",
      "2021-04-25 17:55:52,375 [INFO] Training: 5565/6852 -- loss: 2.452162742614746\n",
      "2021-04-25 17:55:52,428 [INFO] Training: 5566/6852 -- loss: 2.0082058906555176\n",
      "2021-04-25 17:55:52,476 [INFO] Training: 5567/6852 -- loss: 1.764631986618042\n",
      "2021-04-25 17:55:52,527 [INFO] Training: 5568/6852 -- loss: 1.9427531957626343\n",
      "2021-04-25 17:55:52,579 [INFO] Training: 5569/6852 -- loss: 2.266195297241211\n",
      "2021-04-25 17:55:52,629 [INFO] Training: 5570/6852 -- loss: 2.090745449066162\n",
      "2021-04-25 17:55:52,678 [INFO] Training: 5571/6852 -- loss: 1.881872534751892\n",
      "2021-04-25 17:55:52,728 [INFO] Training: 5572/6852 -- loss: 1.60781729221344\n",
      "2021-04-25 17:55:52,776 [INFO] Training: 5573/6852 -- loss: 1.3072350025177002\n",
      "2021-04-25 17:55:52,826 [INFO] Training: 5574/6852 -- loss: 1.0625697374343872\n",
      "2021-04-25 17:55:52,877 [INFO] Training: 5575/6852 -- loss: 1.262032151222229\n",
      "2021-04-25 17:55:52,929 [INFO] Training: 5576/6852 -- loss: 2.1677796840667725\n",
      "2021-04-25 17:55:52,981 [INFO] Training: 5577/6852 -- loss: 1.762831449508667\n",
      "2021-04-25 17:55:53,035 [INFO] Training: 5578/6852 -- loss: 1.2495328187942505\n",
      "2021-04-25 17:55:53,082 [INFO] Training: 5579/6852 -- loss: 1.8539811372756958\n",
      "2021-04-25 17:55:53,135 [INFO] Training: 5580/6852 -- loss: 2.1485884189605713\n",
      "2021-04-25 17:55:53,181 [INFO] Training: 5581/6852 -- loss: 2.0121917724609375\n",
      "2021-04-25 17:55:53,239 [INFO] Training: 5582/6852 -- loss: 2.9957315921783447\n",
      "2021-04-25 17:55:53,287 [INFO] Training: 5583/6852 -- loss: 2.4450080394744873\n",
      "2021-04-25 17:55:53,340 [INFO] Training: 5584/6852 -- loss: 1.412721872329712\n",
      "2021-04-25 17:55:53,386 [INFO] Training: 5585/6852 -- loss: 1.5443754196166992\n",
      "2021-04-25 17:55:53,435 [INFO] Training: 5586/6852 -- loss: 1.7171845436096191\n",
      "2021-04-25 17:55:53,483 [INFO] Training: 5587/6852 -- loss: 2.980569839477539\n",
      "2021-04-25 17:55:53,530 [INFO] Training: 5588/6852 -- loss: 1.9219979047775269\n",
      "2021-04-25 17:55:53,580 [INFO] Training: 5589/6852 -- loss: 1.720657229423523\n",
      "2021-04-25 17:55:53,628 [INFO] Training: 5590/6852 -- loss: 1.315392017364502\n",
      "2021-04-25 17:55:53,676 [INFO] Training: 5591/6852 -- loss: 2.7881340980529785\n",
      "2021-04-25 17:55:53,728 [INFO] Training: 5592/6852 -- loss: 2.061295986175537\n",
      "2021-04-25 17:55:53,775 [INFO] Training: 5593/6852 -- loss: 1.677013874053955\n",
      "2021-04-25 17:55:53,824 [INFO] Training: 5594/6852 -- loss: 2.006089687347412\n",
      "2021-04-25 17:55:53,871 [INFO] Training: 5595/6852 -- loss: 1.7775235176086426\n",
      "2021-04-25 17:55:53,918 [INFO] Training: 5596/6852 -- loss: 1.1851530075073242\n",
      "2021-04-25 17:55:53,968 [INFO] Training: 5597/6852 -- loss: 1.0379409790039062\n",
      "2021-04-25 17:55:54,019 [INFO] Training: 5598/6852 -- loss: 1.2157745361328125\n",
      "2021-04-25 17:55:54,070 [INFO] Training: 5599/6852 -- loss: 2.2401468753814697\n",
      "2021-04-25 17:55:54,124 [INFO] Training: 5600/6852 -- loss: 1.7805860042572021\n",
      "2021-04-25 17:55:54,171 [INFO] Training: 5601/6852 -- loss: 1.4604183435440063\n",
      "2021-04-25 17:55:54,221 [INFO] Training: 5602/6852 -- loss: 1.276424527168274\n",
      "2021-04-25 17:55:54,271 [INFO] Training: 5603/6852 -- loss: 1.7733373641967773\n",
      "2021-04-25 17:55:54,320 [INFO] Training: 5604/6852 -- loss: 1.0463472604751587\n",
      "2021-04-25 17:55:54,369 [INFO] Training: 5605/6852 -- loss: 1.4124361276626587\n",
      "2021-04-25 17:55:54,421 [INFO] Training: 5606/6852 -- loss: 2.5920188426971436\n",
      "2021-04-25 17:55:54,469 [INFO] Training: 5607/6852 -- loss: 1.7248015403747559\n",
      "2021-04-25 17:55:54,525 [INFO] Training: 5608/6852 -- loss: 0.870743989944458\n",
      "2021-04-25 17:55:54,574 [INFO] Training: 5609/6852 -- loss: 1.5341880321502686\n",
      "2021-04-25 17:55:54,625 [INFO] Training: 5610/6852 -- loss: 1.6057486534118652\n",
      "2021-04-25 17:55:54,675 [INFO] Training: 5611/6852 -- loss: 2.6156396865844727\n",
      "2021-04-25 17:55:54,727 [INFO] Training: 5612/6852 -- loss: 1.100958228111267\n",
      "2021-04-25 17:55:54,777 [INFO] Training: 5613/6852 -- loss: 1.8114259243011475\n",
      "2021-04-25 17:55:54,827 [INFO] Training: 5614/6852 -- loss: 1.2778760194778442\n",
      "2021-04-25 17:55:54,874 [INFO] Training: 5615/6852 -- loss: 1.786617636680603\n",
      "2021-04-25 17:55:54,923 [INFO] Training: 5616/6852 -- loss: 1.7754791975021362\n",
      "2021-04-25 17:55:54,974 [INFO] Training: 5617/6852 -- loss: 2.5482962131500244\n",
      "2021-04-25 17:55:55,027 [INFO] Training: 5618/6852 -- loss: 2.7730939388275146\n",
      "2021-04-25 17:55:55,076 [INFO] Training: 5619/6852 -- loss: 1.4298993349075317\n",
      "2021-04-25 17:55:55,126 [INFO] Training: 5620/6852 -- loss: 2.25704288482666\n",
      "2021-04-25 17:55:55,179 [INFO] Training: 5621/6852 -- loss: 1.718350887298584\n",
      "2021-04-25 17:55:55,233 [INFO] Training: 5622/6852 -- loss: 2.7387259006500244\n",
      "2021-04-25 17:55:55,283 [INFO] Training: 5623/6852 -- loss: 1.3392348289489746\n",
      "2021-04-25 17:55:55,331 [INFO] Training: 5624/6852 -- loss: 2.7801384925842285\n",
      "2021-04-25 17:55:55,383 [INFO] Training: 5625/6852 -- loss: 1.9378910064697266\n",
      "2021-04-25 17:55:55,436 [INFO] Training: 5626/6852 -- loss: 1.9306752681732178\n",
      "2021-04-25 17:55:55,484 [INFO] Training: 5627/6852 -- loss: 1.526132583618164\n",
      "2021-04-25 17:55:55,537 [INFO] Training: 5628/6852 -- loss: 2.2107644081115723\n",
      "2021-04-25 17:55:55,589 [INFO] Training: 5629/6852 -- loss: 2.902189254760742\n",
      "2021-04-25 17:55:55,640 [INFO] Training: 5630/6852 -- loss: 1.6280254125595093\n",
      "2021-04-25 17:55:55,692 [INFO] Training: 5631/6852 -- loss: 2.0340099334716797\n",
      "2021-04-25 17:55:55,739 [INFO] Training: 5632/6852 -- loss: 1.7384103536605835\n",
      "2021-04-25 17:55:55,787 [INFO] Training: 5633/6852 -- loss: 3.4381747245788574\n",
      "2021-04-25 17:55:55,837 [INFO] Training: 5634/6852 -- loss: 1.8641222715377808\n",
      "2021-04-25 17:55:55,894 [INFO] Training: 5635/6852 -- loss: 2.060358762741089\n",
      "2021-04-25 17:55:55,944 [INFO] Training: 5636/6852 -- loss: 1.9540002346038818\n",
      "2021-04-25 17:55:55,992 [INFO] Training: 5637/6852 -- loss: 1.427590250968933\n",
      "2021-04-25 17:55:56,042 [INFO] Training: 5638/6852 -- loss: 1.4309624433517456\n",
      "2021-04-25 17:55:56,092 [INFO] Training: 5639/6852 -- loss: 1.8123736381530762\n",
      "2021-04-25 17:55:56,140 [INFO] Training: 5640/6852 -- loss: 1.6305842399597168\n",
      "2021-04-25 17:55:56,188 [INFO] Training: 5641/6852 -- loss: 2.4541969299316406\n",
      "2021-04-25 17:55:56,237 [INFO] Training: 5642/6852 -- loss: 0.8995400667190552\n",
      "2021-04-25 17:55:56,295 [INFO] Training: 5643/6852 -- loss: 2.308452844619751\n",
      "2021-04-25 17:55:56,345 [INFO] Training: 5644/6852 -- loss: 1.6736385822296143\n",
      "2021-04-25 17:55:56,398 [INFO] Training: 5645/6852 -- loss: 2.816848039627075\n",
      "2021-04-25 17:55:56,448 [INFO] Training: 5646/6852 -- loss: 1.7457430362701416\n",
      "2021-04-25 17:55:56,501 [INFO] Training: 5647/6852 -- loss: 1.4788810014724731\n",
      "2021-04-25 17:55:56,548 [INFO] Training: 5648/6852 -- loss: 1.0065462589263916\n",
      "2021-04-25 17:55:56,596 [INFO] Training: 5649/6852 -- loss: 1.425134539604187\n",
      "2021-04-25 17:55:56,648 [INFO] Training: 5650/6852 -- loss: 2.7809181213378906\n",
      "2021-04-25 17:55:56,697 [INFO] Training: 5651/6852 -- loss: 1.591518759727478\n",
      "2021-04-25 17:55:56,749 [INFO] Training: 5652/6852 -- loss: 2.060495376586914\n",
      "2021-04-25 17:55:56,796 [INFO] Training: 5653/6852 -- loss: 1.5549941062927246\n",
      "2021-04-25 17:55:56,846 [INFO] Training: 5654/6852 -- loss: 2.510727882385254\n",
      "2021-04-25 17:55:56,894 [INFO] Training: 5655/6852 -- loss: 1.2561612129211426\n",
      "2021-04-25 17:55:56,942 [INFO] Training: 5656/6852 -- loss: 2.136281728744507\n",
      "2021-04-25 17:55:56,993 [INFO] Training: 5657/6852 -- loss: 1.9189567565917969\n",
      "2021-04-25 17:55:57,042 [INFO] Training: 5658/6852 -- loss: 0.7310806512832642\n",
      "2021-04-25 17:55:57,090 [INFO] Training: 5659/6852 -- loss: 2.034069776535034\n",
      "2021-04-25 17:55:57,139 [INFO] Training: 5660/6852 -- loss: 3.3153605461120605\n",
      "2021-04-25 17:55:57,189 [INFO] Training: 5661/6852 -- loss: 1.9668713808059692\n",
      "2021-04-25 17:55:57,237 [INFO] Training: 5662/6852 -- loss: 2.340655565261841\n",
      "2021-04-25 17:55:57,286 [INFO] Training: 5663/6852 -- loss: 2.4559710025787354\n",
      "2021-04-25 17:55:57,336 [INFO] Training: 5664/6852 -- loss: 2.4953105449676514\n",
      "2021-04-25 17:55:57,384 [INFO] Training: 5665/6852 -- loss: 1.7594133615493774\n",
      "2021-04-25 17:55:57,434 [INFO] Training: 5666/6852 -- loss: 1.6954598426818848\n",
      "2021-04-25 17:55:57,482 [INFO] Training: 5667/6852 -- loss: 1.508913516998291\n",
      "2021-04-25 17:55:57,528 [INFO] Training: 5668/6852 -- loss: 1.6243973970413208\n",
      "2021-04-25 17:55:57,579 [INFO] Training: 5669/6852 -- loss: 1.7626869678497314\n",
      "2021-04-25 17:55:57,626 [INFO] Training: 5670/6852 -- loss: 1.875411033630371\n",
      "2021-04-25 17:55:57,675 [INFO] Training: 5671/6852 -- loss: 1.5293515920639038\n",
      "2021-04-25 17:55:57,723 [INFO] Training: 5672/6852 -- loss: 1.712910532951355\n",
      "2021-04-25 17:55:57,778 [INFO] Training: 5673/6852 -- loss: 1.897483468055725\n",
      "2021-04-25 17:55:57,825 [INFO] Training: 5674/6852 -- loss: 2.194894790649414\n",
      "2021-04-25 17:55:57,873 [INFO] Training: 5675/6852 -- loss: 1.3202505111694336\n",
      "2021-04-25 17:55:57,922 [INFO] Training: 5676/6852 -- loss: 2.089954376220703\n",
      "2021-04-25 17:55:57,974 [INFO] Training: 5677/6852 -- loss: 1.380911946296692\n",
      "2021-04-25 17:55:58,024 [INFO] Training: 5678/6852 -- loss: 2.5224030017852783\n",
      "2021-04-25 17:55:58,075 [INFO] Training: 5679/6852 -- loss: 1.4672099351882935\n",
      "2021-04-25 17:55:58,123 [INFO] Training: 5680/6852 -- loss: 1.2679829597473145\n",
      "2021-04-25 17:55:58,172 [INFO] Training: 5681/6852 -- loss: 1.5560734272003174\n",
      "2021-04-25 17:55:58,221 [INFO] Training: 5682/6852 -- loss: 2.5830419063568115\n",
      "2021-04-25 17:55:58,270 [INFO] Training: 5683/6852 -- loss: 2.0010182857513428\n",
      "2021-04-25 17:55:58,323 [INFO] Training: 5684/6852 -- loss: 2.587332248687744\n",
      "2021-04-25 17:55:58,374 [INFO] Training: 5685/6852 -- loss: 1.104868769645691\n",
      "2021-04-25 17:55:58,426 [INFO] Training: 5686/6852 -- loss: 1.7346549034118652\n",
      "2021-04-25 17:55:58,474 [INFO] Training: 5687/6852 -- loss: 1.1227245330810547\n",
      "2021-04-25 17:55:58,523 [INFO] Training: 5688/6852 -- loss: 2.5579588413238525\n",
      "2021-04-25 17:55:58,572 [INFO] Training: 5689/6852 -- loss: 2.478764295578003\n",
      "2021-04-25 17:55:58,620 [INFO] Training: 5690/6852 -- loss: 1.7334105968475342\n",
      "2021-04-25 17:55:58,667 [INFO] Training: 5691/6852 -- loss: 1.6324200630187988\n",
      "2021-04-25 17:55:58,717 [INFO] Training: 5692/6852 -- loss: 2.025261640548706\n",
      "2021-04-25 17:55:58,764 [INFO] Training: 5693/6852 -- loss: 1.3634790182113647\n",
      "2021-04-25 17:55:58,822 [INFO] Training: 5694/6852 -- loss: 2.3007030487060547\n",
      "2021-04-25 17:55:58,870 [INFO] Training: 5695/6852 -- loss: 2.0224926471710205\n",
      "2021-04-25 17:55:58,921 [INFO] Training: 5696/6852 -- loss: 2.4050798416137695\n",
      "2021-04-25 17:55:58,972 [INFO] Training: 5697/6852 -- loss: 2.487588882446289\n",
      "2021-04-25 17:55:59,022 [INFO] Training: 5698/6852 -- loss: 2.103215217590332\n",
      "2021-04-25 17:55:59,075 [INFO] Training: 5699/6852 -- loss: 1.1424133777618408\n",
      "2021-04-25 17:55:59,126 [INFO] Training: 5700/6852 -- loss: 1.0722465515136719\n",
      "2021-04-25 17:56:02,014 [INFO] Training: iteration: 5700/6852 -- epoch: 9 --  train_loss: 1.874 -- train_accuracy: 0.62 valid_loss: 3.185 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:56:02,054 [INFO] Training: 5701/6852 -- loss: 1.8997485637664795\n",
      "2021-04-25 17:56:02,105 [INFO] Training: 5702/6852 -- loss: 1.2617237567901611\n",
      "2021-04-25 17:56:02,155 [INFO] Training: 5703/6852 -- loss: 1.9566547870635986\n",
      "2021-04-25 17:56:02,203 [INFO] Training: 5704/6852 -- loss: 1.6593748331069946\n",
      "2021-04-25 17:56:02,252 [INFO] Training: 5705/6852 -- loss: 2.2031409740448\n",
      "2021-04-25 17:56:02,300 [INFO] Training: 5706/6852 -- loss: 1.860422134399414\n",
      "2021-04-25 17:56:02,347 [INFO] Training: 5707/6852 -- loss: 1.6736115217208862\n",
      "2021-04-25 17:56:02,396 [INFO] Training: 5708/6852 -- loss: 1.3486075401306152\n",
      "2021-04-25 17:56:02,441 [INFO] Training: 5709/6852 -- loss: 3.036430835723877\n",
      "2021-04-25 17:56:02,823 [INFO] Training: model saved to: ./models/model_10_epochs_train.pt\n",
      "2021-04-25 17:56:02,838 [INFO] Training: results saved to: ./results/resutls_10_epochs_train.pkl\n",
      "2021-04-25 17:56:03,074 [INFO] Training: 5710/6852 -- loss: 2.5552682876586914\n",
      "2021-04-25 17:56:03,127 [INFO] Training: 5711/6852 -- loss: 1.8814367055892944\n",
      "2021-04-25 17:56:03,180 [INFO] Training: 5712/6852 -- loss: 1.7028156518936157\n",
      "2021-04-25 17:56:03,233 [INFO] Training: 5713/6852 -- loss: 2.0104713439941406\n",
      "2021-04-25 17:56:03,282 [INFO] Training: 5714/6852 -- loss: 2.0798017978668213\n",
      "2021-04-25 17:56:03,336 [INFO] Training: 5715/6852 -- loss: 2.0033364295959473\n",
      "2021-04-25 17:56:03,393 [INFO] Training: 5716/6852 -- loss: 0.49580007791519165\n",
      "2021-04-25 17:56:03,444 [INFO] Training: 5717/6852 -- loss: 1.5168930292129517\n",
      "2021-04-25 17:56:03,492 [INFO] Training: 5718/6852 -- loss: 3.476372480392456\n",
      "2021-04-25 17:56:03,540 [INFO] Training: 5719/6852 -- loss: 1.9591758251190186\n",
      "2021-04-25 17:56:03,590 [INFO] Training: 5720/6852 -- loss: 1.9866124391555786\n",
      "2021-04-25 17:56:03,637 [INFO] Training: 5721/6852 -- loss: 2.3128738403320312\n",
      "2021-04-25 17:56:03,688 [INFO] Training: 5722/6852 -- loss: 1.8636854887008667\n",
      "2021-04-25 17:56:03,737 [INFO] Training: 5723/6852 -- loss: 2.0219407081604004\n",
      "2021-04-25 17:56:03,789 [INFO] Training: 5724/6852 -- loss: 1.5170066356658936\n",
      "2021-04-25 17:56:03,840 [INFO] Training: 5725/6852 -- loss: 1.3355069160461426\n",
      "2021-04-25 17:56:03,888 [INFO] Training: 5726/6852 -- loss: 1.685551404953003\n",
      "2021-04-25 17:56:03,940 [INFO] Training: 5727/6852 -- loss: 1.0288647413253784\n",
      "2021-04-25 17:56:03,990 [INFO] Training: 5728/6852 -- loss: 1.4516147375106812\n",
      "2021-04-25 17:56:04,045 [INFO] Training: 5729/6852 -- loss: 1.6509971618652344\n",
      "2021-04-25 17:56:04,098 [INFO] Training: 5730/6852 -- loss: 1.578859806060791\n",
      "2021-04-25 17:56:04,150 [INFO] Training: 5731/6852 -- loss: 2.4460136890411377\n",
      "2021-04-25 17:56:04,201 [INFO] Training: 5732/6852 -- loss: 1.9881237745285034\n",
      "2021-04-25 17:56:04,252 [INFO] Training: 5733/6852 -- loss: 1.2572036981582642\n",
      "2021-04-25 17:56:04,305 [INFO] Training: 5734/6852 -- loss: 2.1527767181396484\n",
      "2021-04-25 17:56:04,356 [INFO] Training: 5735/6852 -- loss: 1.5025873184204102\n",
      "2021-04-25 17:56:04,408 [INFO] Training: 5736/6852 -- loss: 1.4809784889221191\n",
      "2021-04-25 17:56:04,456 [INFO] Training: 5737/6852 -- loss: 2.23298978805542\n",
      "2021-04-25 17:56:04,504 [INFO] Training: 5738/6852 -- loss: 0.76503586769104\n",
      "2021-04-25 17:56:04,555 [INFO] Training: 5739/6852 -- loss: 1.599890947341919\n",
      "2021-04-25 17:56:04,605 [INFO] Training: 5740/6852 -- loss: 1.336777687072754\n",
      "2021-04-25 17:56:04,654 [INFO] Training: 5741/6852 -- loss: 2.2580721378326416\n",
      "2021-04-25 17:56:04,703 [INFO] Training: 5742/6852 -- loss: 1.5001914501190186\n",
      "2021-04-25 17:56:04,758 [INFO] Training: 5743/6852 -- loss: 2.1672935485839844\n",
      "2021-04-25 17:56:04,807 [INFO] Training: 5744/6852 -- loss: 2.065206289291382\n",
      "2021-04-25 17:56:04,858 [INFO] Training: 5745/6852 -- loss: 3.273855209350586\n",
      "2021-04-25 17:56:04,907 [INFO] Training: 5746/6852 -- loss: 1.1112587451934814\n",
      "2021-04-25 17:56:04,961 [INFO] Training: 5747/6852 -- loss: 1.8190373182296753\n",
      "2021-04-25 17:56:05,012 [INFO] Training: 5748/6852 -- loss: 2.5473275184631348\n",
      "2021-04-25 17:56:05,061 [INFO] Training: 5749/6852 -- loss: 1.527666687965393\n",
      "2021-04-25 17:56:05,112 [INFO] Training: 5750/6852 -- loss: 1.9068353176116943\n",
      "2021-04-25 17:56:05,167 [INFO] Training: 5751/6852 -- loss: 1.065115213394165\n",
      "2021-04-25 17:56:05,216 [INFO] Training: 5752/6852 -- loss: 1.0239951610565186\n",
      "2021-04-25 17:56:05,265 [INFO] Training: 5753/6852 -- loss: 1.5750540494918823\n",
      "2021-04-25 17:56:05,314 [INFO] Training: 5754/6852 -- loss: 1.4213343858718872\n",
      "2021-04-25 17:56:05,368 [INFO] Training: 5755/6852 -- loss: 1.404273509979248\n",
      "2021-04-25 17:56:05,424 [INFO] Training: 5756/6852 -- loss: 2.038463830947876\n",
      "2021-04-25 17:56:05,478 [INFO] Training: 5757/6852 -- loss: 1.4945259094238281\n",
      "2021-04-25 17:56:05,526 [INFO] Training: 5758/6852 -- loss: 2.263293743133545\n",
      "2021-04-25 17:56:05,575 [INFO] Training: 5759/6852 -- loss: 1.73966383934021\n",
      "2021-04-25 17:56:05,622 [INFO] Training: 5760/6852 -- loss: 2.1829445362091064\n",
      "2021-04-25 17:56:05,674 [INFO] Training: 5761/6852 -- loss: 1.6360180377960205\n",
      "2021-04-25 17:56:05,722 [INFO] Training: 5762/6852 -- loss: 2.012568473815918\n",
      "2021-04-25 17:56:05,771 [INFO] Training: 5763/6852 -- loss: 2.3901515007019043\n",
      "2021-04-25 17:56:05,819 [INFO] Training: 5764/6852 -- loss: 2.163651704788208\n",
      "2021-04-25 17:56:05,869 [INFO] Training: 5765/6852 -- loss: 1.864941954612732\n",
      "2021-04-25 17:56:05,916 [INFO] Training: 5766/6852 -- loss: 1.8407704830169678\n",
      "2021-04-25 17:56:05,971 [INFO] Training: 5767/6852 -- loss: 1.8678820133209229\n",
      "2021-04-25 17:56:06,021 [INFO] Training: 5768/6852 -- loss: 1.2854559421539307\n",
      "2021-04-25 17:56:06,075 [INFO] Training: 5769/6852 -- loss: 2.881772756576538\n",
      "2021-04-25 17:56:06,128 [INFO] Training: 5770/6852 -- loss: 1.4249544143676758\n",
      "2021-04-25 17:56:06,175 [INFO] Training: 5771/6852 -- loss: 1.7499226331710815\n",
      "2021-04-25 17:56:06,223 [INFO] Training: 5772/6852 -- loss: 1.7801518440246582\n",
      "2021-04-25 17:56:06,272 [INFO] Training: 5773/6852 -- loss: 1.6658638715744019\n",
      "2021-04-25 17:56:06,319 [INFO] Training: 5774/6852 -- loss: 1.170987606048584\n",
      "2021-04-25 17:56:06,367 [INFO] Training: 5775/6852 -- loss: 1.8809936046600342\n",
      "2021-04-25 17:56:06,415 [INFO] Training: 5776/6852 -- loss: 2.450161933898926\n",
      "2021-04-25 17:56:06,464 [INFO] Training: 5777/6852 -- loss: 1.563124656677246\n",
      "2021-04-25 17:56:06,513 [INFO] Training: 5778/6852 -- loss: 1.8021756410598755\n",
      "2021-04-25 17:56:06,566 [INFO] Training: 5779/6852 -- loss: 1.4935318231582642\n",
      "2021-04-25 17:56:06,617 [INFO] Training: 5780/6852 -- loss: 0.8337797522544861\n",
      "2021-04-25 17:56:06,666 [INFO] Training: 5781/6852 -- loss: 3.260927677154541\n",
      "2021-04-25 17:56:06,714 [INFO] Training: 5782/6852 -- loss: 1.921579360961914\n",
      "2021-04-25 17:56:06,764 [INFO] Training: 5783/6852 -- loss: 1.4635405540466309\n",
      "2021-04-25 17:56:06,812 [INFO] Training: 5784/6852 -- loss: 2.0197813510894775\n",
      "2021-04-25 17:56:06,864 [INFO] Training: 5785/6852 -- loss: 2.087221145629883\n",
      "2021-04-25 17:56:06,910 [INFO] Training: 5786/6852 -- loss: 0.5383514165878296\n",
      "2021-04-25 17:56:06,959 [INFO] Training: 5787/6852 -- loss: 1.3353760242462158\n",
      "2021-04-25 17:56:07,007 [INFO] Training: 5788/6852 -- loss: 1.7961336374282837\n",
      "2021-04-25 17:56:07,060 [INFO] Training: 5789/6852 -- loss: 1.4902260303497314\n",
      "2021-04-25 17:56:07,115 [INFO] Training: 5790/6852 -- loss: 2.2938175201416016\n",
      "2021-04-25 17:56:07,166 [INFO] Training: 5791/6852 -- loss: 2.06719970703125\n",
      "2021-04-25 17:56:07,214 [INFO] Training: 5792/6852 -- loss: 1.4068315029144287\n",
      "2021-04-25 17:56:07,269 [INFO] Training: 5793/6852 -- loss: 2.262514114379883\n",
      "2021-04-25 17:56:07,316 [INFO] Training: 5794/6852 -- loss: 1.4919108152389526\n",
      "2021-04-25 17:56:07,364 [INFO] Training: 5795/6852 -- loss: 1.3278675079345703\n",
      "2021-04-25 17:56:07,413 [INFO] Training: 5796/6852 -- loss: 2.0466442108154297\n",
      "2021-04-25 17:56:07,460 [INFO] Training: 5797/6852 -- loss: 1.4931689500808716\n",
      "2021-04-25 17:56:07,510 [INFO] Training: 5798/6852 -- loss: 1.5228840112686157\n",
      "2021-04-25 17:56:07,557 [INFO] Training: 5799/6852 -- loss: 1.820533275604248\n",
      "2021-04-25 17:56:07,604 [INFO] Training: 5800/6852 -- loss: 1.8790706396102905\n",
      "2021-04-25 17:56:07,653 [INFO] Training: 5801/6852 -- loss: 1.5493934154510498\n",
      "2021-04-25 17:56:07,702 [INFO] Training: 5802/6852 -- loss: 2.050605297088623\n",
      "2021-04-25 17:56:07,752 [INFO] Training: 5803/6852 -- loss: 1.1425764560699463\n",
      "2021-04-25 17:56:07,804 [INFO] Training: 5804/6852 -- loss: 0.9157551527023315\n",
      "2021-04-25 17:56:07,853 [INFO] Training: 5805/6852 -- loss: 0.9378279447555542\n",
      "2021-04-25 17:56:07,906 [INFO] Training: 5806/6852 -- loss: 1.1754896640777588\n",
      "2021-04-25 17:56:07,957 [INFO] Training: 5807/6852 -- loss: 1.0074130296707153\n",
      "2021-04-25 17:56:08,008 [INFO] Training: 5808/6852 -- loss: 1.215111255645752\n",
      "2021-04-25 17:56:08,060 [INFO] Training: 5809/6852 -- loss: 1.8286184072494507\n",
      "2021-04-25 17:56:08,108 [INFO] Training: 5810/6852 -- loss: 2.415426254272461\n",
      "2021-04-25 17:56:08,162 [INFO] Training: 5811/6852 -- loss: 1.4150422811508179\n",
      "2021-04-25 17:56:08,214 [INFO] Training: 5812/6852 -- loss: 2.704658269882202\n",
      "2021-04-25 17:56:08,265 [INFO] Training: 5813/6852 -- loss: 2.2733986377716064\n",
      "2021-04-25 17:56:08,313 [INFO] Training: 5814/6852 -- loss: 1.5773608684539795\n",
      "2021-04-25 17:56:08,365 [INFO] Training: 5815/6852 -- loss: 1.2074241638183594\n",
      "2021-04-25 17:56:08,416 [INFO] Training: 5816/6852 -- loss: 1.5617200136184692\n",
      "2021-04-25 17:56:08,469 [INFO] Training: 5817/6852 -- loss: 1.5715428590774536\n",
      "2021-04-25 17:56:08,520 [INFO] Training: 5818/6852 -- loss: 1.016180157661438\n",
      "2021-04-25 17:56:08,573 [INFO] Training: 5819/6852 -- loss: 1.8573946952819824\n",
      "2021-04-25 17:56:08,619 [INFO] Training: 5820/6852 -- loss: 1.8442714214324951\n",
      "2021-04-25 17:56:08,671 [INFO] Training: 5821/6852 -- loss: 2.964879035949707\n",
      "2021-04-25 17:56:08,724 [INFO] Training: 5822/6852 -- loss: 2.3685877323150635\n",
      "2021-04-25 17:56:08,773 [INFO] Training: 5823/6852 -- loss: 1.8669555187225342\n",
      "2021-04-25 17:56:08,819 [INFO] Training: 5824/6852 -- loss: 1.973525047302246\n",
      "2021-04-25 17:56:08,872 [INFO] Training: 5825/6852 -- loss: 1.7648546695709229\n",
      "2021-04-25 17:56:08,920 [INFO] Training: 5826/6852 -- loss: 1.2796825170516968\n",
      "2021-04-25 17:56:08,969 [INFO] Training: 5827/6852 -- loss: 1.4362870454788208\n",
      "2021-04-25 17:56:09,018 [INFO] Training: 5828/6852 -- loss: 2.599656820297241\n",
      "2021-04-25 17:56:09,071 [INFO] Training: 5829/6852 -- loss: 1.0889497995376587\n",
      "2021-04-25 17:56:09,121 [INFO] Training: 5830/6852 -- loss: 1.977868676185608\n",
      "2021-04-25 17:56:09,175 [INFO] Training: 5831/6852 -- loss: 1.5662223100662231\n",
      "2021-04-25 17:56:09,223 [INFO] Training: 5832/6852 -- loss: 1.5380985736846924\n",
      "2021-04-25 17:56:09,274 [INFO] Training: 5833/6852 -- loss: 1.1332613229751587\n",
      "2021-04-25 17:56:09,322 [INFO] Training: 5834/6852 -- loss: 1.80713951587677\n",
      "2021-04-25 17:56:09,370 [INFO] Training: 5835/6852 -- loss: 1.2797528505325317\n",
      "2021-04-25 17:56:09,424 [INFO] Training: 5836/6852 -- loss: 2.7375495433807373\n",
      "2021-04-25 17:56:09,482 [INFO] Training: 5837/6852 -- loss: 1.3110864162445068\n",
      "2021-04-25 17:56:09,530 [INFO] Training: 5838/6852 -- loss: 1.323781132698059\n",
      "2021-04-25 17:56:09,581 [INFO] Training: 5839/6852 -- loss: 1.5618903636932373\n",
      "2021-04-25 17:56:09,632 [INFO] Training: 5840/6852 -- loss: 1.734540343284607\n",
      "2021-04-25 17:56:09,680 [INFO] Training: 5841/6852 -- loss: 1.5687649250030518\n",
      "2021-04-25 17:56:09,733 [INFO] Training: 5842/6852 -- loss: 2.339700222015381\n",
      "2021-04-25 17:56:09,782 [INFO] Training: 5843/6852 -- loss: 1.7414875030517578\n",
      "2021-04-25 17:56:09,831 [INFO] Training: 5844/6852 -- loss: 2.273937463760376\n",
      "2021-04-25 17:56:09,882 [INFO] Training: 5845/6852 -- loss: 0.9353254437446594\n",
      "2021-04-25 17:56:09,932 [INFO] Training: 5846/6852 -- loss: 1.1346135139465332\n",
      "2021-04-25 17:56:09,978 [INFO] Training: 5847/6852 -- loss: 1.4101824760437012\n",
      "2021-04-25 17:56:10,033 [INFO] Training: 5848/6852 -- loss: 1.419762134552002\n",
      "2021-04-25 17:56:10,083 [INFO] Training: 5849/6852 -- loss: 1.3326281309127808\n",
      "2021-04-25 17:56:10,135 [INFO] Training: 5850/6852 -- loss: 1.9696860313415527\n",
      "2021-04-25 17:56:13,013 [INFO] Training: iteration: 5850/6852 -- epoch: 10 --  train_loss: 1.748 -- train_accuracy: 0.25 valid_loss: 3.249 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:56:13,054 [INFO] Training: 5851/6852 -- loss: 2.224982500076294\n",
      "2021-04-25 17:56:13,108 [INFO] Training: 5852/6852 -- loss: 1.7747431993484497\n",
      "2021-04-25 17:56:13,161 [INFO] Training: 5853/6852 -- loss: 1.5837527513504028\n",
      "2021-04-25 17:56:13,212 [INFO] Training: 5854/6852 -- loss: 2.0692195892333984\n",
      "2021-04-25 17:56:13,262 [INFO] Training: 5855/6852 -- loss: 1.6790772676467896\n",
      "2021-04-25 17:56:13,309 [INFO] Training: 5856/6852 -- loss: 0.8775166869163513\n",
      "2021-04-25 17:56:13,362 [INFO] Training: 5857/6852 -- loss: 2.2557449340820312\n",
      "2021-04-25 17:56:13,411 [INFO] Training: 5858/6852 -- loss: 1.319541096687317\n",
      "2021-04-25 17:56:13,464 [INFO] Training: 5859/6852 -- loss: 1.9262490272521973\n",
      "2021-04-25 17:56:13,516 [INFO] Training: 5860/6852 -- loss: 1.2359645366668701\n",
      "2021-04-25 17:56:13,565 [INFO] Training: 5861/6852 -- loss: 2.677734136581421\n",
      "2021-04-25 17:56:13,617 [INFO] Training: 5862/6852 -- loss: 1.5239313840866089\n",
      "2021-04-25 17:56:13,666 [INFO] Training: 5863/6852 -- loss: 2.0875372886657715\n",
      "2021-04-25 17:56:13,717 [INFO] Training: 5864/6852 -- loss: 2.4390170574188232\n",
      "2021-04-25 17:56:13,771 [INFO] Training: 5865/6852 -- loss: 1.6855521202087402\n",
      "2021-04-25 17:56:13,823 [INFO] Training: 5866/6852 -- loss: 1.566128134727478\n",
      "2021-04-25 17:56:13,871 [INFO] Training: 5867/6852 -- loss: 2.7089571952819824\n",
      "2021-04-25 17:56:13,923 [INFO] Training: 5868/6852 -- loss: 1.6798627376556396\n",
      "2021-04-25 17:56:13,972 [INFO] Training: 5869/6852 -- loss: 0.9357618093490601\n",
      "2021-04-25 17:56:14,022 [INFO] Training: 5870/6852 -- loss: 2.2210278511047363\n",
      "2021-04-25 17:56:14,072 [INFO] Training: 5871/6852 -- loss: 1.2199627161026\n",
      "2021-04-25 17:56:14,121 [INFO] Training: 5872/6852 -- loss: 1.8635458946228027\n",
      "2021-04-25 17:56:14,174 [INFO] Training: 5873/6852 -- loss: 2.2136454582214355\n",
      "2021-04-25 17:56:14,220 [INFO] Training: 5874/6852 -- loss: 1.832135558128357\n",
      "2021-04-25 17:56:14,270 [INFO] Training: 5875/6852 -- loss: 3.0656211376190186\n",
      "2021-04-25 17:56:14,319 [INFO] Training: 5876/6852 -- loss: 2.612283706665039\n",
      "2021-04-25 17:56:14,367 [INFO] Training: 5877/6852 -- loss: 1.402836561203003\n",
      "2021-04-25 17:56:14,416 [INFO] Training: 5878/6852 -- loss: 1.8605951070785522\n",
      "2021-04-25 17:56:14,467 [INFO] Training: 5879/6852 -- loss: 2.0084846019744873\n",
      "2021-04-25 17:56:14,518 [INFO] Training: 5880/6852 -- loss: 1.1755669116973877\n",
      "2021-04-25 17:56:14,565 [INFO] Training: 5881/6852 -- loss: 3.931925058364868\n",
      "2021-04-25 17:56:14,617 [INFO] Training: 5882/6852 -- loss: 1.2993519306182861\n",
      "2021-04-25 17:56:14,666 [INFO] Training: 5883/6852 -- loss: 1.402820110321045\n",
      "2021-04-25 17:56:14,718 [INFO] Training: 5884/6852 -- loss: 1.3807111978530884\n",
      "2021-04-25 17:56:14,766 [INFO] Training: 5885/6852 -- loss: 1.0495693683624268\n",
      "2021-04-25 17:56:14,818 [INFO] Training: 5886/6852 -- loss: 1.7065891027450562\n",
      "2021-04-25 17:56:14,870 [INFO] Training: 5887/6852 -- loss: 1.8442186117172241\n",
      "2021-04-25 17:56:14,920 [INFO] Training: 5888/6852 -- loss: 1.4169607162475586\n",
      "2021-04-25 17:56:14,971 [INFO] Training: 5889/6852 -- loss: 2.121750831604004\n",
      "2021-04-25 17:56:15,020 [INFO] Training: 5890/6852 -- loss: 2.1624913215637207\n",
      "2021-04-25 17:56:15,068 [INFO] Training: 5891/6852 -- loss: 2.5844247341156006\n",
      "2021-04-25 17:56:15,115 [INFO] Training: 5892/6852 -- loss: 3.080518960952759\n",
      "2021-04-25 17:56:15,165 [INFO] Training: 5893/6852 -- loss: 0.9682115316390991\n",
      "2021-04-25 17:56:15,214 [INFO] Training: 5894/6852 -- loss: 1.1890430450439453\n",
      "2021-04-25 17:56:15,263 [INFO] Training: 5895/6852 -- loss: 2.3408756256103516\n",
      "2021-04-25 17:56:15,312 [INFO] Training: 5896/6852 -- loss: 0.5868867635726929\n",
      "2021-04-25 17:56:15,359 [INFO] Training: 5897/6852 -- loss: 2.215874195098877\n",
      "2021-04-25 17:56:15,409 [INFO] Training: 5898/6852 -- loss: 1.6661962270736694\n",
      "2021-04-25 17:56:15,457 [INFO] Training: 5899/6852 -- loss: 0.9573341012001038\n",
      "2021-04-25 17:56:15,504 [INFO] Training: 5900/6852 -- loss: 2.225870370864868\n",
      "2021-04-25 17:56:15,552 [INFO] Training: 5901/6852 -- loss: 0.9631009697914124\n",
      "2021-04-25 17:56:15,601 [INFO] Training: 5902/6852 -- loss: 2.8614912033081055\n",
      "2021-04-25 17:56:15,655 [INFO] Training: 5903/6852 -- loss: 1.820227861404419\n",
      "2021-04-25 17:56:15,702 [INFO] Training: 5904/6852 -- loss: 1.042372226715088\n",
      "2021-04-25 17:56:15,754 [INFO] Training: 5905/6852 -- loss: 1.2764467000961304\n",
      "2021-04-25 17:56:15,802 [INFO] Training: 5906/6852 -- loss: 2.316938638687134\n",
      "2021-04-25 17:56:15,852 [INFO] Training: 5907/6852 -- loss: 1.4746654033660889\n",
      "2021-04-25 17:56:15,909 [INFO] Training: 5908/6852 -- loss: 1.9188083410263062\n",
      "2021-04-25 17:56:15,962 [INFO] Training: 5909/6852 -- loss: 1.6044366359710693\n",
      "2021-04-25 17:56:16,009 [INFO] Training: 5910/6852 -- loss: 2.0244858264923096\n",
      "2021-04-25 17:56:16,059 [INFO] Training: 5911/6852 -- loss: 1.781427264213562\n",
      "2021-04-25 17:56:16,106 [INFO] Training: 5912/6852 -- loss: 1.4978419542312622\n",
      "2021-04-25 17:56:16,161 [INFO] Training: 5913/6852 -- loss: 2.7577481269836426\n",
      "2021-04-25 17:56:16,209 [INFO] Training: 5914/6852 -- loss: 1.3108253479003906\n",
      "2021-04-25 17:56:16,258 [INFO] Training: 5915/6852 -- loss: 1.2063976526260376\n",
      "2021-04-25 17:56:16,307 [INFO] Training: 5916/6852 -- loss: 1.724173903465271\n",
      "2021-04-25 17:56:16,354 [INFO] Training: 5917/6852 -- loss: 2.5292842388153076\n",
      "2021-04-25 17:56:16,405 [INFO] Training: 5918/6852 -- loss: 2.579665184020996\n",
      "2021-04-25 17:56:16,451 [INFO] Training: 5919/6852 -- loss: 1.6786478757858276\n",
      "2021-04-25 17:56:16,501 [INFO] Training: 5920/6852 -- loss: 0.9804987907409668\n",
      "2021-04-25 17:56:16,548 [INFO] Training: 5921/6852 -- loss: 2.1370606422424316\n",
      "2021-04-25 17:56:16,601 [INFO] Training: 5922/6852 -- loss: 1.3997751474380493\n",
      "2021-04-25 17:56:16,650 [INFO] Training: 5923/6852 -- loss: 1.9980895519256592\n",
      "2021-04-25 17:56:16,699 [INFO] Training: 5924/6852 -- loss: 1.949713110923767\n",
      "2021-04-25 17:56:16,750 [INFO] Training: 5925/6852 -- loss: 1.828739047050476\n",
      "2021-04-25 17:56:16,798 [INFO] Training: 5926/6852 -- loss: 1.9143366813659668\n",
      "2021-04-25 17:56:16,847 [INFO] Training: 5927/6852 -- loss: 2.0051426887512207\n",
      "2021-04-25 17:56:16,896 [INFO] Training: 5928/6852 -- loss: 0.9491136074066162\n",
      "2021-04-25 17:56:16,946 [INFO] Training: 5929/6852 -- loss: 1.1354678869247437\n",
      "2021-04-25 17:56:16,998 [INFO] Training: 5930/6852 -- loss: 1.806821584701538\n",
      "2021-04-25 17:56:17,047 [INFO] Training: 5931/6852 -- loss: 1.7892355918884277\n",
      "2021-04-25 17:56:17,099 [INFO] Training: 5932/6852 -- loss: 2.4449377059936523\n",
      "2021-04-25 17:56:17,147 [INFO] Training: 5933/6852 -- loss: 1.8763387203216553\n",
      "2021-04-25 17:56:17,198 [INFO] Training: 5934/6852 -- loss: 1.1238818168640137\n",
      "2021-04-25 17:56:17,244 [INFO] Training: 5935/6852 -- loss: 1.9371768236160278\n",
      "2021-04-25 17:56:17,296 [INFO] Training: 5936/6852 -- loss: 1.3129831552505493\n",
      "2021-04-25 17:56:17,348 [INFO] Training: 5937/6852 -- loss: 1.2131147384643555\n",
      "2021-04-25 17:56:17,400 [INFO] Training: 5938/6852 -- loss: 2.5220675468444824\n",
      "2021-04-25 17:56:17,448 [INFO] Training: 5939/6852 -- loss: 1.809455394744873\n",
      "2021-04-25 17:56:17,500 [INFO] Training: 5940/6852 -- loss: 1.956945538520813\n",
      "2021-04-25 17:56:17,550 [INFO] Training: 5941/6852 -- loss: 1.8843951225280762\n",
      "2021-04-25 17:56:17,604 [INFO] Training: 5942/6852 -- loss: 1.5744779109954834\n",
      "2021-04-25 17:56:17,651 [INFO] Training: 5943/6852 -- loss: 1.0842432975769043\n",
      "2021-04-25 17:56:17,699 [INFO] Training: 5944/6852 -- loss: 1.0215320587158203\n",
      "2021-04-25 17:56:17,750 [INFO] Training: 5945/6852 -- loss: 2.830432415008545\n",
      "2021-04-25 17:56:17,800 [INFO] Training: 5946/6852 -- loss: 1.0544604063034058\n",
      "2021-04-25 17:56:17,853 [INFO] Training: 5947/6852 -- loss: 1.5205880403518677\n",
      "2021-04-25 17:56:17,900 [INFO] Training: 5948/6852 -- loss: 1.778924822807312\n",
      "2021-04-25 17:56:17,951 [INFO] Training: 5949/6852 -- loss: 1.291130542755127\n",
      "2021-04-25 17:56:18,005 [INFO] Training: 5950/6852 -- loss: 1.4531036615371704\n",
      "2021-04-25 17:56:18,053 [INFO] Training: 5951/6852 -- loss: 1.1802780628204346\n",
      "2021-04-25 17:56:18,105 [INFO] Training: 5952/6852 -- loss: 2.417898178100586\n",
      "2021-04-25 17:56:18,153 [INFO] Training: 5953/6852 -- loss: 1.8922313451766968\n",
      "2021-04-25 17:56:18,206 [INFO] Training: 5954/6852 -- loss: 1.6341127157211304\n",
      "2021-04-25 17:56:18,254 [INFO] Training: 5955/6852 -- loss: 1.1941660642623901\n",
      "2021-04-25 17:56:18,304 [INFO] Training: 5956/6852 -- loss: 1.845048427581787\n",
      "2021-04-25 17:56:18,354 [INFO] Training: 5957/6852 -- loss: 2.724120855331421\n",
      "2021-04-25 17:56:18,402 [INFO] Training: 5958/6852 -- loss: 0.9838141202926636\n",
      "2021-04-25 17:56:18,453 [INFO] Training: 5959/6852 -- loss: 0.9653618335723877\n",
      "2021-04-25 17:56:18,502 [INFO] Training: 5960/6852 -- loss: 1.644568920135498\n",
      "2021-04-25 17:56:18,550 [INFO] Training: 5961/6852 -- loss: 2.077003240585327\n",
      "2021-04-25 17:56:18,602 [INFO] Training: 5962/6852 -- loss: 1.2484757900238037\n",
      "2021-04-25 17:56:18,655 [INFO] Training: 5963/6852 -- loss: 1.7857128381729126\n",
      "2021-04-25 17:56:18,704 [INFO] Training: 5964/6852 -- loss: 1.4755219221115112\n",
      "2021-04-25 17:56:18,750 [INFO] Training: 5965/6852 -- loss: 1.5758781433105469\n",
      "2021-04-25 17:56:18,804 [INFO] Training: 5966/6852 -- loss: 1.4674184322357178\n",
      "2021-04-25 17:56:18,851 [INFO] Training: 5967/6852 -- loss: 0.9878959059715271\n",
      "2021-04-25 17:56:18,905 [INFO] Training: 5968/6852 -- loss: 1.3009721040725708\n",
      "2021-04-25 17:56:18,952 [INFO] Training: 5969/6852 -- loss: 1.5378402471542358\n",
      "2021-04-25 17:56:19,004 [INFO] Training: 5970/6852 -- loss: 0.7102649807929993\n",
      "2021-04-25 17:56:19,051 [INFO] Training: 5971/6852 -- loss: 2.162306070327759\n",
      "2021-04-25 17:56:19,105 [INFO] Training: 5972/6852 -- loss: 1.783853530883789\n",
      "2021-04-25 17:56:19,154 [INFO] Training: 5973/6852 -- loss: 2.0039284229278564\n",
      "2021-04-25 17:56:19,206 [INFO] Training: 5974/6852 -- loss: 2.1165077686309814\n",
      "2021-04-25 17:56:19,252 [INFO] Training: 5975/6852 -- loss: 2.2721877098083496\n",
      "2021-04-25 17:56:19,305 [INFO] Training: 5976/6852 -- loss: 2.6216416358947754\n",
      "2021-04-25 17:56:19,354 [INFO] Training: 5977/6852 -- loss: 0.825977087020874\n",
      "2021-04-25 17:56:19,402 [INFO] Training: 5978/6852 -- loss: 1.113952398300171\n",
      "2021-04-25 17:56:19,455 [INFO] Training: 5979/6852 -- loss: 1.921271800994873\n",
      "2021-04-25 17:56:19,506 [INFO] Training: 5980/6852 -- loss: 1.5024809837341309\n",
      "2021-04-25 17:56:19,559 [INFO] Training: 5981/6852 -- loss: 2.337682008743286\n",
      "2021-04-25 17:56:19,608 [INFO] Training: 5982/6852 -- loss: 2.0676846504211426\n",
      "2021-04-25 17:56:19,662 [INFO] Training: 5983/6852 -- loss: 1.7468323707580566\n",
      "2021-04-25 17:56:19,711 [INFO] Training: 5984/6852 -- loss: 1.2292299270629883\n",
      "2021-04-25 17:56:19,761 [INFO] Training: 5985/6852 -- loss: 2.0174002647399902\n",
      "2021-04-25 17:56:19,809 [INFO] Training: 5986/6852 -- loss: 1.0796490907669067\n",
      "2021-04-25 17:56:19,862 [INFO] Training: 5987/6852 -- loss: 1.438391923904419\n",
      "2021-04-25 17:56:19,913 [INFO] Training: 5988/6852 -- loss: 1.678515076637268\n",
      "2021-04-25 17:56:19,963 [INFO] Training: 5989/6852 -- loss: 1.7208635807037354\n",
      "2021-04-25 17:56:20,009 [INFO] Training: 5990/6852 -- loss: 1.2478264570236206\n",
      "2021-04-25 17:56:20,068 [INFO] Training: 5991/6852 -- loss: 1.5430160760879517\n",
      "2021-04-25 17:56:20,121 [INFO] Training: 5992/6852 -- loss: 1.6142219305038452\n",
      "2021-04-25 17:56:20,170 [INFO] Training: 5993/6852 -- loss: 2.362323522567749\n",
      "2021-04-25 17:56:20,223 [INFO] Training: 5994/6852 -- loss: 2.224961042404175\n",
      "2021-04-25 17:56:20,270 [INFO] Training: 5995/6852 -- loss: 2.3070967197418213\n",
      "2021-04-25 17:56:20,317 [INFO] Training: 5996/6852 -- loss: 1.8937103748321533\n",
      "2021-04-25 17:56:20,370 [INFO] Training: 5997/6852 -- loss: 2.3906614780426025\n",
      "2021-04-25 17:56:20,419 [INFO] Training: 5998/6852 -- loss: 1.378145694732666\n",
      "2021-04-25 17:56:20,468 [INFO] Training: 5999/6852 -- loss: 1.740225076675415\n",
      "2021-04-25 17:56:20,516 [INFO] Training: 6000/6852 -- loss: 1.8740673065185547\n",
      "2021-04-25 17:56:23,374 [INFO] Training: iteration: 6000/6852 -- epoch: 10 --  train_loss: 1.751 -- train_accuracy: 0.62 valid_loss: 3.247 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:56:23,416 [INFO] Training: 6001/6852 -- loss: 0.9273225665092468\n",
      "2021-04-25 17:56:23,468 [INFO] Training: 6002/6852 -- loss: 2.24491548538208\n",
      "2021-04-25 17:56:23,520 [INFO] Training: 6003/6852 -- loss: 1.8619846105575562\n",
      "2021-04-25 17:56:23,567 [INFO] Training: 6004/6852 -- loss: 2.983328104019165\n",
      "2021-04-25 17:56:23,618 [INFO] Training: 6005/6852 -- loss: 0.7721522450447083\n",
      "2021-04-25 17:56:23,666 [INFO] Training: 6006/6852 -- loss: 2.2380809783935547\n",
      "2021-04-25 17:56:23,714 [INFO] Training: 6007/6852 -- loss: 2.4676785469055176\n",
      "2021-04-25 17:56:23,765 [INFO] Training: 6008/6852 -- loss: 2.13100528717041\n",
      "2021-04-25 17:56:23,814 [INFO] Training: 6009/6852 -- loss: 1.3699934482574463\n",
      "2021-04-25 17:56:23,862 [INFO] Training: 6010/6852 -- loss: 1.9210684299468994\n",
      "2021-04-25 17:56:23,909 [INFO] Training: 6011/6852 -- loss: 1.6129448413848877\n",
      "2021-04-25 17:56:23,957 [INFO] Training: 6012/6852 -- loss: 2.5638961791992188\n",
      "2021-04-25 17:56:24,009 [INFO] Training: 6013/6852 -- loss: 1.808056116104126\n",
      "2021-04-25 17:56:24,055 [INFO] Training: 6014/6852 -- loss: 1.546669840812683\n",
      "2021-04-25 17:56:24,104 [INFO] Training: 6015/6852 -- loss: 2.095402240753174\n",
      "2021-04-25 17:56:24,156 [INFO] Training: 6016/6852 -- loss: 2.043212652206421\n",
      "2021-04-25 17:56:24,204 [INFO] Training: 6017/6852 -- loss: 0.5158963203430176\n",
      "2021-04-25 17:56:24,255 [INFO] Training: 6018/6852 -- loss: 2.3681740760803223\n",
      "2021-04-25 17:56:24,305 [INFO] Training: 6019/6852 -- loss: 1.8406341075897217\n",
      "2021-04-25 17:56:24,354 [INFO] Training: 6020/6852 -- loss: 0.9998884797096252\n",
      "2021-04-25 17:56:24,400 [INFO] Training: 6021/6852 -- loss: 1.8728792667388916\n",
      "2021-04-25 17:56:24,453 [INFO] Training: 6022/6852 -- loss: 1.1256999969482422\n",
      "2021-04-25 17:56:24,503 [INFO] Training: 6023/6852 -- loss: 1.3783351182937622\n",
      "2021-04-25 17:56:24,550 [INFO] Training: 6024/6852 -- loss: 1.8045198917388916\n",
      "2021-04-25 17:56:24,598 [INFO] Training: 6025/6852 -- loss: 1.86604905128479\n",
      "2021-04-25 17:56:24,652 [INFO] Training: 6026/6852 -- loss: 2.7667574882507324\n",
      "2021-04-25 17:56:24,698 [INFO] Training: 6027/6852 -- loss: 1.5272130966186523\n",
      "2021-04-25 17:56:24,749 [INFO] Training: 6028/6852 -- loss: 1.834075927734375\n",
      "2021-04-25 17:56:24,799 [INFO] Training: 6029/6852 -- loss: 1.8425740003585815\n",
      "2021-04-25 17:56:24,851 [INFO] Training: 6030/6852 -- loss: 1.6918950080871582\n",
      "2021-04-25 17:56:24,900 [INFO] Training: 6031/6852 -- loss: 2.2736382484436035\n",
      "2021-04-25 17:56:24,947 [INFO] Training: 6032/6852 -- loss: 1.56751549243927\n",
      "2021-04-25 17:56:25,002 [INFO] Training: 6033/6852 -- loss: 1.1166490316390991\n",
      "2021-04-25 17:56:25,051 [INFO] Training: 6034/6852 -- loss: 1.4069128036499023\n",
      "2021-04-25 17:56:25,103 [INFO] Training: 6035/6852 -- loss: 2.241920232772827\n",
      "2021-04-25 17:56:25,150 [INFO] Training: 6036/6852 -- loss: 1.3152247667312622\n",
      "2021-04-25 17:56:25,199 [INFO] Training: 6037/6852 -- loss: 1.4057424068450928\n",
      "2021-04-25 17:56:25,246 [INFO] Training: 6038/6852 -- loss: 1.7416256666183472\n",
      "2021-04-25 17:56:25,299 [INFO] Training: 6039/6852 -- loss: 2.198981523513794\n",
      "2021-04-25 17:56:25,348 [INFO] Training: 6040/6852 -- loss: 1.5986735820770264\n",
      "2021-04-25 17:56:25,396 [INFO] Training: 6041/6852 -- loss: 1.2674921751022339\n",
      "2021-04-25 17:56:25,449 [INFO] Training: 6042/6852 -- loss: 2.0199952125549316\n",
      "2021-04-25 17:56:25,496 [INFO] Training: 6043/6852 -- loss: 2.2536864280700684\n",
      "2021-04-25 17:56:25,551 [INFO] Training: 6044/6852 -- loss: 2.4752306938171387\n",
      "2021-04-25 17:56:25,599 [INFO] Training: 6045/6852 -- loss: 1.1430364847183228\n",
      "2021-04-25 17:56:25,649 [INFO] Training: 6046/6852 -- loss: 1.7234914302825928\n",
      "2021-04-25 17:56:25,702 [INFO] Training: 6047/6852 -- loss: 1.8027374744415283\n",
      "2021-04-25 17:56:25,750 [INFO] Training: 6048/6852 -- loss: 2.267904758453369\n",
      "2021-04-25 17:56:25,799 [INFO] Training: 6049/6852 -- loss: 1.4807028770446777\n",
      "2021-04-25 17:56:25,849 [INFO] Training: 6050/6852 -- loss: 1.6377149820327759\n",
      "2021-04-25 17:56:25,898 [INFO] Training: 6051/6852 -- loss: 2.897446393966675\n",
      "2021-04-25 17:56:25,947 [INFO] Training: 6052/6852 -- loss: 1.5641568899154663\n",
      "2021-04-25 17:56:25,995 [INFO] Training: 6053/6852 -- loss: 1.444008469581604\n",
      "2021-04-25 17:56:26,041 [INFO] Training: 6054/6852 -- loss: 2.427927255630493\n",
      "2021-04-25 17:56:26,088 [INFO] Training: 6055/6852 -- loss: 2.7175517082214355\n",
      "2021-04-25 17:56:26,144 [INFO] Training: 6056/6852 -- loss: 2.3018293380737305\n",
      "2021-04-25 17:56:26,193 [INFO] Training: 6057/6852 -- loss: 1.5340666770935059\n",
      "2021-04-25 17:56:26,241 [INFO] Training: 6058/6852 -- loss: 2.3705248832702637\n",
      "2021-04-25 17:56:26,294 [INFO] Training: 6059/6852 -- loss: 1.9861677885055542\n",
      "2021-04-25 17:56:26,342 [INFO] Training: 6060/6852 -- loss: 1.9789841175079346\n",
      "2021-04-25 17:56:26,393 [INFO] Training: 6061/6852 -- loss: 2.015902519226074\n",
      "2021-04-25 17:56:26,441 [INFO] Training: 6062/6852 -- loss: 1.2720541954040527\n",
      "2021-04-25 17:56:26,493 [INFO] Training: 6063/6852 -- loss: 1.7462300062179565\n",
      "2021-04-25 17:56:26,543 [INFO] Training: 6064/6852 -- loss: 2.459275960922241\n",
      "2021-04-25 17:56:26,594 [INFO] Training: 6065/6852 -- loss: 2.0395193099975586\n",
      "2021-04-25 17:56:26,642 [INFO] Training: 6066/6852 -- loss: 1.4060273170471191\n",
      "2021-04-25 17:56:26,689 [INFO] Training: 6067/6852 -- loss: 2.2485690116882324\n",
      "2021-04-25 17:56:26,745 [INFO] Training: 6068/6852 -- loss: 2.997406482696533\n",
      "2021-04-25 17:56:26,796 [INFO] Training: 6069/6852 -- loss: 2.007233142852783\n",
      "2021-04-25 17:56:26,849 [INFO] Training: 6070/6852 -- loss: 1.725814938545227\n",
      "2021-04-25 17:56:26,898 [INFO] Training: 6071/6852 -- loss: 1.2402021884918213\n",
      "2021-04-25 17:56:26,948 [INFO] Training: 6072/6852 -- loss: 2.7012276649475098\n",
      "2021-04-25 17:56:26,996 [INFO] Training: 6073/6852 -- loss: 1.1256871223449707\n",
      "2021-04-25 17:56:27,044 [INFO] Training: 6074/6852 -- loss: 1.5588109493255615\n",
      "2021-04-25 17:56:27,092 [INFO] Training: 6075/6852 -- loss: 1.4894969463348389\n",
      "2021-04-25 17:56:27,140 [INFO] Training: 6076/6852 -- loss: 2.2291259765625\n",
      "2021-04-25 17:56:27,193 [INFO] Training: 6077/6852 -- loss: 1.1266272068023682\n",
      "2021-04-25 17:56:27,244 [INFO] Training: 6078/6852 -- loss: 1.7608270645141602\n",
      "2021-04-25 17:56:27,295 [INFO] Training: 6079/6852 -- loss: 2.4596261978149414\n",
      "2021-04-25 17:56:27,346 [INFO] Training: 6080/6852 -- loss: 2.442425489425659\n",
      "2021-04-25 17:56:27,395 [INFO] Training: 6081/6852 -- loss: 2.2823610305786133\n",
      "2021-04-25 17:56:27,443 [INFO] Training: 6082/6852 -- loss: 2.4102656841278076\n",
      "2021-04-25 17:56:27,494 [INFO] Training: 6083/6852 -- loss: 1.661813497543335\n",
      "2021-04-25 17:56:27,546 [INFO] Training: 6084/6852 -- loss: 1.7401093244552612\n",
      "2021-04-25 17:56:27,598 [INFO] Training: 6085/6852 -- loss: 1.4300823211669922\n",
      "2021-04-25 17:56:27,646 [INFO] Training: 6086/6852 -- loss: 1.4844328165054321\n",
      "2021-04-25 17:56:27,698 [INFO] Training: 6087/6852 -- loss: 1.5590261220932007\n",
      "2021-04-25 17:56:27,750 [INFO] Training: 6088/6852 -- loss: 1.6061615943908691\n",
      "2021-04-25 17:56:27,800 [INFO] Training: 6089/6852 -- loss: 2.0394749641418457\n",
      "2021-04-25 17:56:27,852 [INFO] Training: 6090/6852 -- loss: 1.5484881401062012\n",
      "2021-04-25 17:56:27,905 [INFO] Training: 6091/6852 -- loss: 2.840761661529541\n",
      "2021-04-25 17:56:27,955 [INFO] Training: 6092/6852 -- loss: 0.8511199951171875\n",
      "2021-04-25 17:56:28,006 [INFO] Training: 6093/6852 -- loss: 1.9531466960906982\n",
      "2021-04-25 17:56:28,057 [INFO] Training: 6094/6852 -- loss: 1.9256192445755005\n",
      "2021-04-25 17:56:28,107 [INFO] Training: 6095/6852 -- loss: 2.662036657333374\n",
      "2021-04-25 17:56:28,160 [INFO] Training: 6096/6852 -- loss: 2.0500285625457764\n",
      "2021-04-25 17:56:28,210 [INFO] Training: 6097/6852 -- loss: 2.1438772678375244\n",
      "2021-04-25 17:56:28,263 [INFO] Training: 6098/6852 -- loss: 1.0851125717163086\n",
      "2021-04-25 17:56:28,314 [INFO] Training: 6099/6852 -- loss: 2.1719017028808594\n",
      "2021-04-25 17:56:28,365 [INFO] Training: 6100/6852 -- loss: 1.5252578258514404\n",
      "2021-04-25 17:56:28,414 [INFO] Training: 6101/6852 -- loss: 1.9010683298110962\n",
      "2021-04-25 17:56:28,467 [INFO] Training: 6102/6852 -- loss: 2.705437660217285\n",
      "2021-04-25 17:56:28,513 [INFO] Training: 6103/6852 -- loss: 0.8199924230575562\n",
      "2021-04-25 17:56:28,563 [INFO] Training: 6104/6852 -- loss: 2.566657304763794\n",
      "2021-04-25 17:56:28,611 [INFO] Training: 6105/6852 -- loss: 0.9896209239959717\n",
      "2021-04-25 17:56:28,662 [INFO] Training: 6106/6852 -- loss: 1.5374540090560913\n",
      "2021-04-25 17:56:28,711 [INFO] Training: 6107/6852 -- loss: 1.6396172046661377\n",
      "2021-04-25 17:56:28,759 [INFO] Training: 6108/6852 -- loss: 1.1724770069122314\n",
      "2021-04-25 17:56:28,813 [INFO] Training: 6109/6852 -- loss: 1.6600788831710815\n",
      "2021-04-25 17:56:28,863 [INFO] Training: 6110/6852 -- loss: 1.3522851467132568\n",
      "2021-04-25 17:56:28,911 [INFO] Training: 6111/6852 -- loss: 1.9292093515396118\n",
      "2021-04-25 17:56:28,964 [INFO] Training: 6112/6852 -- loss: 1.681836485862732\n",
      "2021-04-25 17:56:29,018 [INFO] Training: 6113/6852 -- loss: 2.4108264446258545\n",
      "2021-04-25 17:56:29,069 [INFO] Training: 6114/6852 -- loss: 1.5724425315856934\n",
      "2021-04-25 17:56:29,123 [INFO] Training: 6115/6852 -- loss: 1.5251283645629883\n",
      "2021-04-25 17:56:29,172 [INFO] Training: 6116/6852 -- loss: 1.9291307926177979\n",
      "2021-04-25 17:56:29,224 [INFO] Training: 6117/6852 -- loss: 2.7464301586151123\n",
      "2021-04-25 17:56:29,277 [INFO] Training: 6118/6852 -- loss: 2.9294912815093994\n",
      "2021-04-25 17:56:29,329 [INFO] Training: 6119/6852 -- loss: 2.0554146766662598\n",
      "2021-04-25 17:56:29,382 [INFO] Training: 6120/6852 -- loss: 2.1205341815948486\n",
      "2021-04-25 17:56:29,429 [INFO] Training: 6121/6852 -- loss: 2.6548571586608887\n",
      "2021-04-25 17:56:29,475 [INFO] Training: 6122/6852 -- loss: 1.280720829963684\n",
      "2021-04-25 17:56:29,525 [INFO] Training: 6123/6852 -- loss: 1.190659761428833\n",
      "2021-04-25 17:56:29,575 [INFO] Training: 6124/6852 -- loss: 1.845799207687378\n",
      "2021-04-25 17:56:29,624 [INFO] Training: 6125/6852 -- loss: 0.8483836650848389\n",
      "2021-04-25 17:56:29,672 [INFO] Training: 6126/6852 -- loss: 1.4441789388656616\n",
      "2021-04-25 17:56:29,720 [INFO] Training: 6127/6852 -- loss: 1.5112247467041016\n",
      "2021-04-25 17:56:29,772 [INFO] Training: 6128/6852 -- loss: 2.4547204971313477\n",
      "2021-04-25 17:56:29,818 [INFO] Training: 6129/6852 -- loss: 0.6183229684829712\n",
      "2021-04-25 17:56:29,867 [INFO] Training: 6130/6852 -- loss: 2.0448386669158936\n",
      "2021-04-25 17:56:29,915 [INFO] Training: 6131/6852 -- loss: 1.8567993640899658\n",
      "2021-04-25 17:56:29,968 [INFO] Training: 6132/6852 -- loss: 2.0854082107543945\n",
      "2021-04-25 17:56:30,017 [INFO] Training: 6133/6852 -- loss: 1.428850769996643\n",
      "2021-04-25 17:56:30,066 [INFO] Training: 6134/6852 -- loss: 1.3634600639343262\n",
      "2021-04-25 17:56:30,118 [INFO] Training: 6135/6852 -- loss: 1.9808437824249268\n",
      "2021-04-25 17:56:30,165 [INFO] Training: 6136/6852 -- loss: 2.339409828186035\n",
      "2021-04-25 17:56:30,218 [INFO] Training: 6137/6852 -- loss: 1.3951393365859985\n",
      "2021-04-25 17:56:30,267 [INFO] Training: 6138/6852 -- loss: 0.8659536838531494\n",
      "2021-04-25 17:56:30,320 [INFO] Training: 6139/6852 -- loss: 1.8879696130752563\n",
      "2021-04-25 17:56:30,369 [INFO] Training: 6140/6852 -- loss: 2.3218300342559814\n",
      "2021-04-25 17:56:30,421 [INFO] Training: 6141/6852 -- loss: 1.0091772079467773\n",
      "2021-04-25 17:56:30,473 [INFO] Training: 6142/6852 -- loss: 0.8915260434150696\n",
      "2021-04-25 17:56:30,524 [INFO] Training: 6143/6852 -- loss: 2.6680908203125\n",
      "2021-04-25 17:56:30,573 [INFO] Training: 6144/6852 -- loss: 2.4499454498291016\n",
      "2021-04-25 17:56:30,625 [INFO] Training: 6145/6852 -- loss: 1.8940064907073975\n",
      "2021-04-25 17:56:30,679 [INFO] Training: 6146/6852 -- loss: 1.4954112768173218\n",
      "2021-04-25 17:56:30,728 [INFO] Training: 6147/6852 -- loss: 2.0281598567962646\n",
      "2021-04-25 17:56:30,776 [INFO] Training: 6148/6852 -- loss: 2.181567430496216\n",
      "2021-04-25 17:56:30,829 [INFO] Training: 6149/6852 -- loss: 2.007685661315918\n",
      "2021-04-25 17:56:30,880 [INFO] Training: 6150/6852 -- loss: 1.669967770576477\n",
      "2021-04-25 17:56:33,732 [INFO] Training: iteration: 6150/6852 -- epoch: 10 --  train_loss: 1.828 -- train_accuracy: 0.38 valid_loss: 3.230 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:56:33,774 [INFO] Training: 6151/6852 -- loss: 2.007199287414551\n",
      "2021-04-25 17:56:33,826 [INFO] Training: 6152/6852 -- loss: 2.34153151512146\n",
      "2021-04-25 17:56:33,876 [INFO] Training: 6153/6852 -- loss: 2.418492555618286\n",
      "2021-04-25 17:56:33,923 [INFO] Training: 6154/6852 -- loss: 2.7664947509765625\n",
      "2021-04-25 17:56:33,974 [INFO] Training: 6155/6852 -- loss: 2.1545045375823975\n",
      "2021-04-25 17:56:34,025 [INFO] Training: 6156/6852 -- loss: 2.403985023498535\n",
      "2021-04-25 17:56:34,075 [INFO] Training: 6157/6852 -- loss: 1.5283443927764893\n",
      "2021-04-25 17:56:34,127 [INFO] Training: 6158/6852 -- loss: 1.9958864450454712\n",
      "2021-04-25 17:56:34,176 [INFO] Training: 6159/6852 -- loss: 1.7772397994995117\n",
      "2021-04-25 17:56:34,223 [INFO] Training: 6160/6852 -- loss: 1.6948564052581787\n",
      "2021-04-25 17:56:34,278 [INFO] Training: 6161/6852 -- loss: 1.7265229225158691\n",
      "2021-04-25 17:56:34,324 [INFO] Training: 6162/6852 -- loss: 1.172607660293579\n",
      "2021-04-25 17:56:34,372 [INFO] Training: 6163/6852 -- loss: 2.4879770278930664\n",
      "2021-04-25 17:56:34,420 [INFO] Training: 6164/6852 -- loss: 0.934019923210144\n",
      "2021-04-25 17:56:34,468 [INFO] Training: 6165/6852 -- loss: 2.0595717430114746\n",
      "2021-04-25 17:56:34,515 [INFO] Training: 6166/6852 -- loss: 2.3691153526306152\n",
      "2021-04-25 17:56:34,565 [INFO] Training: 6167/6852 -- loss: 1.4063842296600342\n",
      "2021-04-25 17:56:34,617 [INFO] Training: 6168/6852 -- loss: 2.030064344406128\n",
      "2021-04-25 17:56:34,666 [INFO] Training: 6169/6852 -- loss: 1.7695364952087402\n",
      "2021-04-25 17:56:34,714 [INFO] Training: 6170/6852 -- loss: 2.2601263523101807\n",
      "2021-04-25 17:56:34,762 [INFO] Training: 6171/6852 -- loss: 2.0620877742767334\n",
      "2021-04-25 17:56:34,810 [INFO] Training: 6172/6852 -- loss: 2.4051671028137207\n",
      "2021-04-25 17:56:34,861 [INFO] Training: 6173/6852 -- loss: 2.5068538188934326\n",
      "2021-04-25 17:56:34,914 [INFO] Training: 6174/6852 -- loss: 1.666030764579773\n",
      "2021-04-25 17:56:34,965 [INFO] Training: 6175/6852 -- loss: 2.5487723350524902\n",
      "2021-04-25 17:56:35,015 [INFO] Training: 6176/6852 -- loss: 1.467983365058899\n",
      "2021-04-25 17:56:35,063 [INFO] Training: 6177/6852 -- loss: 0.9169207811355591\n",
      "2021-04-25 17:56:35,113 [INFO] Training: 6178/6852 -- loss: 2.378904342651367\n",
      "2021-04-25 17:56:35,166 [INFO] Training: 6179/6852 -- loss: 2.008333921432495\n",
      "2021-04-25 17:56:35,216 [INFO] Training: 6180/6852 -- loss: 2.35585880279541\n",
      "2021-04-25 17:56:35,263 [INFO] Training: 6181/6852 -- loss: 1.4195969104766846\n",
      "2021-04-25 17:56:35,314 [INFO] Training: 6182/6852 -- loss: 1.8185725212097168\n",
      "2021-04-25 17:56:35,362 [INFO] Training: 6183/6852 -- loss: 1.58809494972229\n",
      "2021-04-25 17:56:35,411 [INFO] Training: 6184/6852 -- loss: 1.3481308221817017\n",
      "2021-04-25 17:56:35,462 [INFO] Training: 6185/6852 -- loss: 1.2643370628356934\n",
      "2021-04-25 17:56:35,515 [INFO] Training: 6186/6852 -- loss: 3.2916719913482666\n",
      "2021-04-25 17:56:35,566 [INFO] Training: 6187/6852 -- loss: 1.637498140335083\n",
      "2021-04-25 17:56:35,615 [INFO] Training: 6188/6852 -- loss: 2.175415277481079\n",
      "2021-04-25 17:56:35,667 [INFO] Training: 6189/6852 -- loss: 1.515376091003418\n",
      "2021-04-25 17:56:35,719 [INFO] Training: 6190/6852 -- loss: 1.6156162023544312\n",
      "2021-04-25 17:56:35,772 [INFO] Training: 6191/6852 -- loss: 3.8517606258392334\n",
      "2021-04-25 17:56:35,822 [INFO] Training: 6192/6852 -- loss: 1.4753549098968506\n",
      "2021-04-25 17:56:35,876 [INFO] Training: 6193/6852 -- loss: 1.6934263706207275\n",
      "2021-04-25 17:56:35,925 [INFO] Training: 6194/6852 -- loss: 2.18499755859375\n",
      "2021-04-25 17:56:35,972 [INFO] Training: 6195/6852 -- loss: 2.821866035461426\n",
      "2021-04-25 17:56:36,025 [INFO] Training: 6196/6852 -- loss: 0.9909499287605286\n",
      "2021-04-25 17:56:36,073 [INFO] Training: 6197/6852 -- loss: 2.229893684387207\n",
      "2021-04-25 17:56:36,123 [INFO] Training: 6198/6852 -- loss: 2.0147790908813477\n",
      "2021-04-25 17:56:36,170 [INFO] Training: 6199/6852 -- loss: 2.090528726577759\n",
      "2021-04-25 17:56:36,218 [INFO] Training: 6200/6852 -- loss: 1.488330602645874\n",
      "2021-04-25 17:56:36,272 [INFO] Training: 6201/6852 -- loss: 1.8987352848052979\n",
      "2021-04-25 17:56:36,323 [INFO] Training: 6202/6852 -- loss: 2.627112865447998\n",
      "2021-04-25 17:56:36,371 [INFO] Training: 6203/6852 -- loss: 1.974791407585144\n",
      "2021-04-25 17:56:36,420 [INFO] Training: 6204/6852 -- loss: 2.2768993377685547\n",
      "2021-04-25 17:56:36,469 [INFO] Training: 6205/6852 -- loss: 1.1322523355484009\n",
      "2021-04-25 17:56:36,517 [INFO] Training: 6206/6852 -- loss: 1.7635936737060547\n",
      "2021-04-25 17:56:36,569 [INFO] Training: 6207/6852 -- loss: 1.5704370737075806\n",
      "2021-04-25 17:56:36,619 [INFO] Training: 6208/6852 -- loss: 2.43497371673584\n",
      "2021-04-25 17:56:36,665 [INFO] Training: 6209/6852 -- loss: 1.8536653518676758\n",
      "2021-04-25 17:56:36,715 [INFO] Training: 6210/6852 -- loss: 2.19252872467041\n",
      "2021-04-25 17:56:36,764 [INFO] Training: 6211/6852 -- loss: 1.4145562648773193\n",
      "2021-04-25 17:56:36,814 [INFO] Training: 6212/6852 -- loss: 1.9378200769424438\n",
      "2021-04-25 17:56:36,865 [INFO] Training: 6213/6852 -- loss: 1.2710423469543457\n",
      "2021-04-25 17:56:36,914 [INFO] Training: 6214/6852 -- loss: 1.1565970182418823\n",
      "2021-04-25 17:56:36,963 [INFO] Training: 6215/6852 -- loss: 2.2442076206207275\n",
      "2021-04-25 17:56:37,012 [INFO] Training: 6216/6852 -- loss: 2.0469605922698975\n",
      "2021-04-25 17:56:37,061 [INFO] Training: 6217/6852 -- loss: 2.5542144775390625\n",
      "2021-04-25 17:56:37,115 [INFO] Training: 6218/6852 -- loss: 1.8142688274383545\n",
      "2021-04-25 17:56:37,162 [INFO] Training: 6219/6852 -- loss: 2.2793984413146973\n",
      "2021-04-25 17:56:37,210 [INFO] Training: 6220/6852 -- loss: 1.2346508502960205\n",
      "2021-04-25 17:56:37,260 [INFO] Training: 6221/6852 -- loss: 0.9500511288642883\n",
      "2021-04-25 17:56:37,309 [INFO] Training: 6222/6852 -- loss: 2.168487548828125\n",
      "2021-04-25 17:56:37,357 [INFO] Training: 6223/6852 -- loss: 1.6580166816711426\n",
      "2021-04-25 17:56:37,410 [INFO] Training: 6224/6852 -- loss: 2.2156929969787598\n",
      "2021-04-25 17:56:37,456 [INFO] Training: 6225/6852 -- loss: 1.0101412534713745\n",
      "2021-04-25 17:56:37,505 [INFO] Training: 6226/6852 -- loss: 1.5777592658996582\n",
      "2021-04-25 17:56:37,558 [INFO] Training: 6227/6852 -- loss: 2.1649169921875\n",
      "2021-04-25 17:56:37,610 [INFO] Training: 6228/6852 -- loss: 1.6444224119186401\n",
      "2021-04-25 17:56:37,657 [INFO] Training: 6229/6852 -- loss: 2.507702350616455\n",
      "2021-04-25 17:56:37,706 [INFO] Training: 6230/6852 -- loss: 2.4328274726867676\n",
      "2021-04-25 17:56:37,756 [INFO] Training: 6231/6852 -- loss: 1.8896422386169434\n",
      "2021-04-25 17:56:37,803 [INFO] Training: 6232/6852 -- loss: 1.8406418561935425\n",
      "2021-04-25 17:56:37,854 [INFO] Training: 6233/6852 -- loss: 1.2008620500564575\n",
      "2021-04-25 17:56:37,902 [INFO] Training: 6234/6852 -- loss: 1.144777774810791\n",
      "2021-04-25 17:56:37,957 [INFO] Training: 6235/6852 -- loss: 1.8442699909210205\n",
      "2021-04-25 17:56:38,007 [INFO] Training: 6236/6852 -- loss: 0.9663704633712769\n",
      "2021-04-25 17:56:38,058 [INFO] Training: 6237/6852 -- loss: 2.0470328330993652\n",
      "2021-04-25 17:56:38,106 [INFO] Training: 6238/6852 -- loss: 2.800072431564331\n",
      "2021-04-25 17:56:38,156 [INFO] Training: 6239/6852 -- loss: 1.0112441778182983\n",
      "2021-04-25 17:56:38,209 [INFO] Training: 6240/6852 -- loss: 2.25215482711792\n",
      "2021-04-25 17:56:38,261 [INFO] Training: 6241/6852 -- loss: 1.2823841571807861\n",
      "2021-04-25 17:56:38,314 [INFO] Training: 6242/6852 -- loss: 1.884714126586914\n",
      "2021-04-25 17:56:38,363 [INFO] Training: 6243/6852 -- loss: 1.8623466491699219\n",
      "2021-04-25 17:56:38,414 [INFO] Training: 6244/6852 -- loss: 2.4458234310150146\n",
      "2021-04-25 17:56:38,466 [INFO] Training: 6245/6852 -- loss: 1.9737128019332886\n",
      "2021-04-25 17:56:38,514 [INFO] Training: 6246/6852 -- loss: 1.0083496570587158\n",
      "2021-04-25 17:56:38,569 [INFO] Training: 6247/6852 -- loss: 1.5198227167129517\n",
      "2021-04-25 17:56:38,619 [INFO] Training: 6248/6852 -- loss: 2.2172558307647705\n",
      "2021-04-25 17:56:38,667 [INFO] Training: 6249/6852 -- loss: 1.1514283418655396\n",
      "2021-04-25 17:56:38,714 [INFO] Training: 6250/6852 -- loss: 1.3007702827453613\n",
      "2021-04-25 17:56:38,764 [INFO] Training: 6251/6852 -- loss: 1.2854087352752686\n",
      "2021-04-25 17:56:38,813 [INFO] Training: 6252/6852 -- loss: 1.0279443264007568\n",
      "2021-04-25 17:56:38,864 [INFO] Training: 6253/6852 -- loss: 2.1779532432556152\n",
      "2021-04-25 17:56:38,913 [INFO] Training: 6254/6852 -- loss: 1.4998013973236084\n",
      "2021-04-25 17:56:38,967 [INFO] Training: 6255/6852 -- loss: 1.7683809995651245\n",
      "2021-04-25 17:56:39,018 [INFO] Training: 6256/6852 -- loss: 1.457355260848999\n",
      "2021-04-25 17:56:39,070 [INFO] Training: 6257/6852 -- loss: 1.9921348094940186\n",
      "2021-04-25 17:56:39,117 [INFO] Training: 6258/6852 -- loss: 3.708620309829712\n",
      "2021-04-25 17:56:39,169 [INFO] Training: 6259/6852 -- loss: 0.8709263801574707\n",
      "2021-04-25 17:56:39,220 [INFO] Training: 6260/6852 -- loss: 1.75587797164917\n",
      "2021-04-25 17:56:39,270 [INFO] Training: 6261/6852 -- loss: 2.1862292289733887\n",
      "2021-04-25 17:56:39,319 [INFO] Training: 6262/6852 -- loss: 1.9208269119262695\n",
      "2021-04-25 17:56:39,369 [INFO] Training: 6263/6852 -- loss: 2.103649616241455\n",
      "2021-04-25 17:56:39,425 [INFO] Training: 6264/6852 -- loss: 0.9528400301933289\n",
      "2021-04-25 17:56:39,476 [INFO] Training: 6265/6852 -- loss: 1.20145845413208\n",
      "2021-04-25 17:56:39,525 [INFO] Training: 6266/6852 -- loss: 1.6724764108657837\n",
      "2021-04-25 17:56:39,578 [INFO] Training: 6267/6852 -- loss: 1.939331293106079\n",
      "2021-04-25 17:56:39,631 [INFO] Training: 6268/6852 -- loss: 2.0474541187286377\n",
      "2021-04-25 17:56:39,681 [INFO] Training: 6269/6852 -- loss: 2.078216791152954\n",
      "2021-04-25 17:56:39,729 [INFO] Training: 6270/6852 -- loss: 1.7147549390792847\n",
      "2021-04-25 17:56:39,776 [INFO] Training: 6271/6852 -- loss: 2.1549646854400635\n",
      "2021-04-25 17:56:39,826 [INFO] Training: 6272/6852 -- loss: 2.0758614540100098\n",
      "2021-04-25 17:56:39,873 [INFO] Training: 6273/6852 -- loss: 1.1998357772827148\n",
      "2021-04-25 17:56:39,923 [INFO] Training: 6274/6852 -- loss: 1.4023982286453247\n",
      "2021-04-25 17:56:39,979 [INFO] Training: 6275/6852 -- loss: 1.0833494663238525\n",
      "2021-04-25 17:56:40,030 [INFO] Training: 6276/6852 -- loss: 1.3880360126495361\n",
      "2021-04-25 17:56:40,077 [INFO] Training: 6277/6852 -- loss: 1.0762888193130493\n",
      "2021-04-25 17:56:40,125 [INFO] Training: 6278/6852 -- loss: 1.067308783531189\n",
      "2021-04-25 17:56:40,172 [INFO] Training: 6279/6852 -- loss: 1.4166172742843628\n",
      "2021-04-25 17:56:40,216 [INFO] Training: 6280/6852 -- loss: 1.7035390138626099\n",
      "2021-04-25 17:56:40,491 [INFO] Training: 6281/6852 -- loss: 1.6809401512145996\n",
      "2021-04-25 17:56:40,547 [INFO] Training: 6282/6852 -- loss: 0.8691684603691101\n",
      "2021-04-25 17:56:40,602 [INFO] Training: 6283/6852 -- loss: 1.7469521760940552\n",
      "2021-04-25 17:56:40,651 [INFO] Training: 6284/6852 -- loss: 1.9049761295318604\n",
      "2021-04-25 17:56:40,699 [INFO] Training: 6285/6852 -- loss: 1.2019248008728027\n",
      "2021-04-25 17:56:40,749 [INFO] Training: 6286/6852 -- loss: 1.3589329719543457\n",
      "2021-04-25 17:56:40,799 [INFO] Training: 6287/6852 -- loss: 1.7449768781661987\n",
      "2021-04-25 17:56:40,851 [INFO] Training: 6288/6852 -- loss: 0.9321509599685669\n",
      "2021-04-25 17:56:40,900 [INFO] Training: 6289/6852 -- loss: 2.356762170791626\n",
      "2021-04-25 17:56:40,952 [INFO] Training: 6290/6852 -- loss: 1.3533742427825928\n",
      "2021-04-25 17:56:41,003 [INFO] Training: 6291/6852 -- loss: 1.3410518169403076\n",
      "2021-04-25 17:56:41,050 [INFO] Training: 6292/6852 -- loss: 2.874272108078003\n",
      "2021-04-25 17:56:41,100 [INFO] Training: 6293/6852 -- loss: 1.594995379447937\n",
      "2021-04-25 17:56:41,151 [INFO] Training: 6294/6852 -- loss: 1.674581527709961\n",
      "2021-04-25 17:56:41,199 [INFO] Training: 6295/6852 -- loss: 1.6161277294158936\n",
      "2021-04-25 17:56:41,252 [INFO] Training: 6296/6852 -- loss: 1.6005955934524536\n",
      "2021-04-25 17:56:41,305 [INFO] Training: 6297/6852 -- loss: 1.0632998943328857\n",
      "2021-04-25 17:56:41,359 [INFO] Training: 6298/6852 -- loss: 0.9639822840690613\n",
      "2021-04-25 17:56:41,409 [INFO] Training: 6299/6852 -- loss: 1.5890566110610962\n",
      "2021-04-25 17:56:41,456 [INFO] Training: 6300/6852 -- loss: 1.135028600692749\n",
      "2021-04-25 17:56:44,356 [INFO] Training: iteration: 6300/6852 -- epoch: 11 --  train_loss: 1.789 -- train_accuracy: 0.75 valid_loss: 3.292 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:56:44,393 [INFO] Training: 6301/6852 -- loss: 0.8490413427352905\n",
      "2021-04-25 17:56:44,441 [INFO] Training: 6302/6852 -- loss: 1.849888801574707\n",
      "2021-04-25 17:56:44,488 [INFO] Training: 6303/6852 -- loss: 2.640061616897583\n",
      "2021-04-25 17:56:44,540 [INFO] Training: 6304/6852 -- loss: 2.1149606704711914\n",
      "2021-04-25 17:56:44,587 [INFO] Training: 6305/6852 -- loss: 1.511378288269043\n",
      "2021-04-25 17:56:44,638 [INFO] Training: 6306/6852 -- loss: 1.115128993988037\n",
      "2021-04-25 17:56:44,688 [INFO] Training: 6307/6852 -- loss: 0.6537969708442688\n",
      "2021-04-25 17:56:44,741 [INFO] Training: 6308/6852 -- loss: 1.916298747062683\n",
      "2021-04-25 17:56:44,791 [INFO] Training: 6309/6852 -- loss: 1.9502815008163452\n",
      "2021-04-25 17:56:44,843 [INFO] Training: 6310/6852 -- loss: 1.9500229358673096\n",
      "2021-04-25 17:56:44,892 [INFO] Training: 6311/6852 -- loss: 1.6747890710830688\n",
      "2021-04-25 17:56:44,945 [INFO] Training: 6312/6852 -- loss: 1.9837180376052856\n",
      "2021-04-25 17:56:44,993 [INFO] Training: 6313/6852 -- loss: 2.015519380569458\n",
      "2021-04-25 17:56:45,045 [INFO] Training: 6314/6852 -- loss: 1.4499504566192627\n",
      "2021-04-25 17:56:45,095 [INFO] Training: 6315/6852 -- loss: 1.802559733390808\n",
      "2021-04-25 17:56:45,147 [INFO] Training: 6316/6852 -- loss: 1.6418511867523193\n",
      "2021-04-25 17:56:45,194 [INFO] Training: 6317/6852 -- loss: 1.5157803297042847\n",
      "2021-04-25 17:56:45,244 [INFO] Training: 6318/6852 -- loss: 2.0442206859588623\n",
      "2021-04-25 17:56:45,296 [INFO] Training: 6319/6852 -- loss: 1.3731149435043335\n",
      "2021-04-25 17:56:45,347 [INFO] Training: 6320/6852 -- loss: 2.828213691711426\n",
      "2021-04-25 17:56:45,398 [INFO] Training: 6321/6852 -- loss: 1.620223045349121\n",
      "2021-04-25 17:56:45,447 [INFO] Training: 6322/6852 -- loss: 1.2667229175567627\n",
      "2021-04-25 17:56:45,502 [INFO] Training: 6323/6852 -- loss: 0.545635461807251\n",
      "2021-04-25 17:56:45,548 [INFO] Training: 6324/6852 -- loss: 2.4454336166381836\n",
      "2021-04-25 17:56:45,597 [INFO] Training: 6325/6852 -- loss: 1.9092026948928833\n",
      "2021-04-25 17:56:45,649 [INFO] Training: 6326/6852 -- loss: 1.1963847875595093\n",
      "2021-04-25 17:56:45,700 [INFO] Training: 6327/6852 -- loss: 1.6683638095855713\n",
      "2021-04-25 17:56:45,751 [INFO] Training: 6328/6852 -- loss: 1.852035403251648\n",
      "2021-04-25 17:56:45,801 [INFO] Training: 6329/6852 -- loss: 1.2335253953933716\n",
      "2021-04-25 17:56:45,849 [INFO] Training: 6330/6852 -- loss: 2.252523899078369\n",
      "2021-04-25 17:56:45,898 [INFO] Training: 6331/6852 -- loss: 1.994051218032837\n",
      "2021-04-25 17:56:45,949 [INFO] Training: 6332/6852 -- loss: 0.836729884147644\n",
      "2021-04-25 17:56:45,997 [INFO] Training: 6333/6852 -- loss: 2.037233352661133\n",
      "2021-04-25 17:56:46,049 [INFO] Training: 6334/6852 -- loss: 2.229839324951172\n",
      "2021-04-25 17:56:46,096 [INFO] Training: 6335/6852 -- loss: 1.2669461965560913\n",
      "2021-04-25 17:56:46,148 [INFO] Training: 6336/6852 -- loss: 1.0293176174163818\n",
      "2021-04-25 17:56:46,198 [INFO] Training: 6337/6852 -- loss: 2.3039968013763428\n",
      "2021-04-25 17:56:46,248 [INFO] Training: 6338/6852 -- loss: 1.5955908298492432\n",
      "2021-04-25 17:56:46,300 [INFO] Training: 6339/6852 -- loss: 1.150895595550537\n",
      "2021-04-25 17:56:46,347 [INFO] Training: 6340/6852 -- loss: 2.7167248725891113\n",
      "2021-04-25 17:56:46,396 [INFO] Training: 6341/6852 -- loss: 2.103710174560547\n",
      "2021-04-25 17:56:46,444 [INFO] Training: 6342/6852 -- loss: 1.6070778369903564\n",
      "2021-04-25 17:56:46,495 [INFO] Training: 6343/6852 -- loss: 2.107146978378296\n",
      "2021-04-25 17:56:46,544 [INFO] Training: 6344/6852 -- loss: 2.3517608642578125\n",
      "2021-04-25 17:56:46,592 [INFO] Training: 6345/6852 -- loss: 2.0369255542755127\n",
      "2021-04-25 17:56:46,641 [INFO] Training: 6346/6852 -- loss: 2.2191824913024902\n",
      "2021-04-25 17:56:46,689 [INFO] Training: 6347/6852 -- loss: 1.4325964450836182\n",
      "2021-04-25 17:56:46,741 [INFO] Training: 6348/6852 -- loss: 2.411142349243164\n",
      "2021-04-25 17:56:46,791 [INFO] Training: 6349/6852 -- loss: 2.0229618549346924\n",
      "2021-04-25 17:56:46,842 [INFO] Training: 6350/6852 -- loss: 1.4378095865249634\n",
      "2021-04-25 17:56:46,891 [INFO] Training: 6351/6852 -- loss: 1.3500298261642456\n",
      "2021-04-25 17:56:46,943 [INFO] Training: 6352/6852 -- loss: 1.9004921913146973\n",
      "2021-04-25 17:56:46,995 [INFO] Training: 6353/6852 -- loss: 2.276441812515259\n",
      "2021-04-25 17:56:47,047 [INFO] Training: 6354/6852 -- loss: 1.9298906326293945\n",
      "2021-04-25 17:56:47,100 [INFO] Training: 6355/6852 -- loss: 1.149714469909668\n",
      "2021-04-25 17:56:47,148 [INFO] Training: 6356/6852 -- loss: 1.5434237718582153\n",
      "2021-04-25 17:56:47,197 [INFO] Training: 6357/6852 -- loss: 1.3579754829406738\n",
      "2021-04-25 17:56:47,245 [INFO] Training: 6358/6852 -- loss: 1.5638399124145508\n",
      "2021-04-25 17:56:47,297 [INFO] Training: 6359/6852 -- loss: 2.439127206802368\n",
      "2021-04-25 17:56:47,347 [INFO] Training: 6360/6852 -- loss: 2.9940080642700195\n",
      "2021-04-25 17:56:47,396 [INFO] Training: 6361/6852 -- loss: 0.5590195059776306\n",
      "2021-04-25 17:56:47,444 [INFO] Training: 6362/6852 -- loss: 1.537245512008667\n",
      "2021-04-25 17:56:47,495 [INFO] Training: 6363/6852 -- loss: 1.312028408050537\n",
      "2021-04-25 17:56:47,545 [INFO] Training: 6364/6852 -- loss: 2.802307367324829\n",
      "2021-04-25 17:56:47,594 [INFO] Training: 6365/6852 -- loss: 1.6980618238449097\n",
      "2021-04-25 17:56:47,641 [INFO] Training: 6366/6852 -- loss: 1.7690317630767822\n",
      "2021-04-25 17:56:47,691 [INFO] Training: 6367/6852 -- loss: 2.0815858840942383\n",
      "2021-04-25 17:56:47,739 [INFO] Training: 6368/6852 -- loss: 1.7959299087524414\n",
      "2021-04-25 17:56:47,793 [INFO] Training: 6369/6852 -- loss: 1.5970492362976074\n",
      "2021-04-25 17:56:47,843 [INFO] Training: 6370/6852 -- loss: 0.6485782265663147\n",
      "2021-04-25 17:56:47,896 [INFO] Training: 6371/6852 -- loss: 1.6673712730407715\n",
      "2021-04-25 17:56:47,947 [INFO] Training: 6372/6852 -- loss: 1.2445199489593506\n",
      "2021-04-25 17:56:47,997 [INFO] Training: 6373/6852 -- loss: 2.4465694427490234\n",
      "2021-04-25 17:56:48,050 [INFO] Training: 6374/6852 -- loss: 2.38435435295105\n",
      "2021-04-25 17:56:48,103 [INFO] Training: 6375/6852 -- loss: 1.149338960647583\n",
      "2021-04-25 17:56:48,153 [INFO] Training: 6376/6852 -- loss: 1.692183494567871\n",
      "2021-04-25 17:56:48,202 [INFO] Training: 6377/6852 -- loss: 1.362507700920105\n",
      "2021-04-25 17:56:48,249 [INFO] Training: 6378/6852 -- loss: 2.0908846855163574\n",
      "2021-04-25 17:56:48,301 [INFO] Training: 6379/6852 -- loss: 2.1291418075561523\n",
      "2021-04-25 17:56:48,351 [INFO] Training: 6380/6852 -- loss: 1.7044172286987305\n",
      "2021-04-25 17:56:48,403 [INFO] Training: 6381/6852 -- loss: 1.5536471605300903\n",
      "2021-04-25 17:56:48,450 [INFO] Training: 6382/6852 -- loss: 1.861931324005127\n",
      "2021-04-25 17:56:48,497 [INFO] Training: 6383/6852 -- loss: 1.0597518682479858\n",
      "2021-04-25 17:56:48,549 [INFO] Training: 6384/6852 -- loss: 1.7091045379638672\n",
      "2021-04-25 17:56:48,600 [INFO] Training: 6385/6852 -- loss: 2.19968843460083\n",
      "2021-04-25 17:56:48,649 [INFO] Training: 6386/6852 -- loss: 2.3290464878082275\n",
      "2021-04-25 17:56:48,699 [INFO] Training: 6387/6852 -- loss: 1.51448655128479\n",
      "2021-04-25 17:56:48,751 [INFO] Training: 6388/6852 -- loss: 0.8322882652282715\n",
      "2021-04-25 17:56:48,799 [INFO] Training: 6389/6852 -- loss: 1.0304818153381348\n",
      "2021-04-25 17:56:48,848 [INFO] Training: 6390/6852 -- loss: 1.2797455787658691\n",
      "2021-04-25 17:56:48,896 [INFO] Training: 6391/6852 -- loss: 1.9459458589553833\n",
      "2021-04-25 17:56:48,943 [INFO] Training: 6392/6852 -- loss: 1.318259596824646\n",
      "2021-04-25 17:56:48,995 [INFO] Training: 6393/6852 -- loss: 1.7756376266479492\n",
      "2021-04-25 17:56:49,045 [INFO] Training: 6394/6852 -- loss: 0.8271409273147583\n",
      "2021-04-25 17:56:49,096 [INFO] Training: 6395/6852 -- loss: 1.0663976669311523\n",
      "2021-04-25 17:56:49,148 [INFO] Training: 6396/6852 -- loss: 1.6932079792022705\n",
      "2021-04-25 17:56:49,198 [INFO] Training: 6397/6852 -- loss: 1.371406078338623\n",
      "2021-04-25 17:56:49,246 [INFO] Training: 6398/6852 -- loss: 0.8645905256271362\n",
      "2021-04-25 17:56:49,297 [INFO] Training: 6399/6852 -- loss: 1.1546157598495483\n",
      "2021-04-25 17:56:49,349 [INFO] Training: 6400/6852 -- loss: 2.184943914413452\n",
      "2021-04-25 17:56:49,397 [INFO] Training: 6401/6852 -- loss: 2.3084216117858887\n",
      "2021-04-25 17:56:49,445 [INFO] Training: 6402/6852 -- loss: 1.5276312828063965\n",
      "2021-04-25 17:56:49,496 [INFO] Training: 6403/6852 -- loss: 2.4909284114837646\n",
      "2021-04-25 17:56:49,549 [INFO] Training: 6404/6852 -- loss: 1.7501345872879028\n",
      "2021-04-25 17:56:49,598 [INFO] Training: 6405/6852 -- loss: 1.0665292739868164\n",
      "2021-04-25 17:56:49,646 [INFO] Training: 6406/6852 -- loss: 1.4612325429916382\n",
      "2021-04-25 17:56:49,695 [INFO] Training: 6407/6852 -- loss: 1.5957006216049194\n",
      "2021-04-25 17:56:49,747 [INFO] Training: 6408/6852 -- loss: 2.2359066009521484\n",
      "2021-04-25 17:56:49,795 [INFO] Training: 6409/6852 -- loss: 1.2752751111984253\n",
      "2021-04-25 17:56:49,845 [INFO] Training: 6410/6852 -- loss: 1.6388200521469116\n",
      "2021-04-25 17:56:49,896 [INFO] Training: 6411/6852 -- loss: 1.0694730281829834\n",
      "2021-04-25 17:56:49,946 [INFO] Training: 6412/6852 -- loss: 2.250831365585327\n",
      "2021-04-25 17:56:49,998 [INFO] Training: 6413/6852 -- loss: 1.2174828052520752\n",
      "2021-04-25 17:56:50,046 [INFO] Training: 6414/6852 -- loss: 0.7196428775787354\n",
      "2021-04-25 17:56:50,099 [INFO] Training: 6415/6852 -- loss: 1.6115354299545288\n",
      "2021-04-25 17:56:50,146 [INFO] Training: 6416/6852 -- loss: 1.2230507135391235\n",
      "2021-04-25 17:56:50,194 [INFO] Training: 6417/6852 -- loss: 1.745825171470642\n",
      "2021-04-25 17:56:50,247 [INFO] Training: 6418/6852 -- loss: 1.8293871879577637\n",
      "2021-04-25 17:56:50,297 [INFO] Training: 6419/6852 -- loss: 1.5285598039627075\n",
      "2021-04-25 17:56:50,348 [INFO] Training: 6420/6852 -- loss: 1.2799272537231445\n",
      "2021-04-25 17:56:50,397 [INFO] Training: 6421/6852 -- loss: 1.7288354635238647\n",
      "2021-04-25 17:56:50,445 [INFO] Training: 6422/6852 -- loss: 2.156162738800049\n",
      "2021-04-25 17:56:50,497 [INFO] Training: 6423/6852 -- loss: 1.8224482536315918\n",
      "2021-04-25 17:56:50,546 [INFO] Training: 6424/6852 -- loss: 1.4850956201553345\n",
      "2021-04-25 17:56:50,597 [INFO] Training: 6425/6852 -- loss: 2.687117099761963\n",
      "2021-04-25 17:56:50,649 [INFO] Training: 6426/6852 -- loss: 1.3946185111999512\n",
      "2021-04-25 17:56:50,696 [INFO] Training: 6427/6852 -- loss: 2.454444646835327\n",
      "2021-04-25 17:56:50,745 [INFO] Training: 6428/6852 -- loss: 0.6913272738456726\n",
      "2021-04-25 17:56:50,794 [INFO] Training: 6429/6852 -- loss: 1.4333235025405884\n",
      "2021-04-25 17:56:50,845 [INFO] Training: 6430/6852 -- loss: 2.2862701416015625\n",
      "2021-04-25 17:56:50,891 [INFO] Training: 6431/6852 -- loss: 2.3870506286621094\n",
      "2021-04-25 17:56:50,941 [INFO] Training: 6432/6852 -- loss: 1.9263992309570312\n",
      "2021-04-25 17:56:50,989 [INFO] Training: 6433/6852 -- loss: 1.421409010887146\n",
      "2021-04-25 17:56:51,036 [INFO] Training: 6434/6852 -- loss: 1.541254997253418\n",
      "2021-04-25 17:56:51,088 [INFO] Training: 6435/6852 -- loss: 1.2619237899780273\n",
      "2021-04-25 17:56:51,138 [INFO] Training: 6436/6852 -- loss: 1.141135573387146\n",
      "2021-04-25 17:56:51,192 [INFO] Training: 6437/6852 -- loss: 1.1549439430236816\n",
      "2021-04-25 17:56:51,242 [INFO] Training: 6438/6852 -- loss: 2.3913869857788086\n",
      "2021-04-25 17:56:51,292 [INFO] Training: 6439/6852 -- loss: 1.61604642868042\n",
      "2021-04-25 17:56:51,340 [INFO] Training: 6440/6852 -- loss: 1.561935544013977\n",
      "2021-04-25 17:56:51,387 [INFO] Training: 6441/6852 -- loss: 1.425642728805542\n",
      "2021-04-25 17:56:51,436 [INFO] Training: 6442/6852 -- loss: 0.9890871047973633\n",
      "2021-04-25 17:56:51,485 [INFO] Training: 6443/6852 -- loss: 1.8884726762771606\n",
      "2021-04-25 17:56:51,533 [INFO] Training: 6444/6852 -- loss: 1.682464838027954\n",
      "2021-04-25 17:56:51,582 [INFO] Training: 6445/6852 -- loss: 1.3520811796188354\n",
      "2021-04-25 17:56:51,631 [INFO] Training: 6446/6852 -- loss: 1.2877037525177002\n",
      "2021-04-25 17:56:51,683 [INFO] Training: 6447/6852 -- loss: 0.985514760017395\n",
      "2021-04-25 17:56:51,731 [INFO] Training: 6448/6852 -- loss: 1.0335525274276733\n",
      "2021-04-25 17:56:51,783 [INFO] Training: 6449/6852 -- loss: 0.9675866365432739\n",
      "2021-04-25 17:56:51,830 [INFO] Training: 6450/6852 -- loss: 0.564976692199707\n",
      "2021-04-25 17:56:54,685 [INFO] Training: iteration: 6450/6852 -- epoch: 11 --  train_loss: 1.654 -- train_accuracy: 1.00 valid_loss: 3.282 -- valid_accuracy: 0.30\n",
      "2021-04-25 17:56:54,726 [INFO] Training: 6451/6852 -- loss: 2.079615354537964\n",
      "2021-04-25 17:56:54,780 [INFO] Training: 6452/6852 -- loss: 1.3850294351577759\n",
      "2021-04-25 17:56:54,826 [INFO] Training: 6453/6852 -- loss: 1.8281376361846924\n",
      "2021-04-25 17:56:54,874 [INFO] Training: 6454/6852 -- loss: 2.016789436340332\n",
      "2021-04-25 17:56:54,921 [INFO] Training: 6455/6852 -- loss: 1.815778136253357\n",
      "2021-04-25 17:56:54,971 [INFO] Training: 6456/6852 -- loss: 1.897051453590393\n",
      "2021-04-25 17:56:55,024 [INFO] Training: 6457/6852 -- loss: 1.9342049360275269\n",
      "2021-04-25 17:56:55,070 [INFO] Training: 6458/6852 -- loss: 1.8153631687164307\n",
      "2021-04-25 17:56:55,118 [INFO] Training: 6459/6852 -- loss: 1.084468960762024\n",
      "2021-04-25 17:56:55,166 [INFO] Training: 6460/6852 -- loss: 2.1254849433898926\n",
      "2021-04-25 17:56:55,218 [INFO] Training: 6461/6852 -- loss: 2.3765830993652344\n",
      "2021-04-25 17:56:55,269 [INFO] Training: 6462/6852 -- loss: 1.4794161319732666\n",
      "2021-04-25 17:56:55,320 [INFO] Training: 6463/6852 -- loss: 1.313601016998291\n",
      "2021-04-25 17:56:55,370 [INFO] Training: 6464/6852 -- loss: 1.4395973682403564\n",
      "2021-04-25 17:56:55,416 [INFO] Training: 6465/6852 -- loss: 1.481896162033081\n",
      "2021-04-25 17:56:55,467 [INFO] Training: 6466/6852 -- loss: 1.9729273319244385\n",
      "2021-04-25 17:56:55,515 [INFO] Training: 6467/6852 -- loss: 1.803553581237793\n",
      "2021-04-25 17:56:55,563 [INFO] Training: 6468/6852 -- loss: 1.0092756748199463\n",
      "2021-04-25 17:56:55,614 [INFO] Training: 6469/6852 -- loss: 1.8317571878433228\n",
      "2021-04-25 17:56:55,671 [INFO] Training: 6470/6852 -- loss: 2.3679540157318115\n",
      "2021-04-25 17:56:55,723 [INFO] Training: 6471/6852 -- loss: 2.3994052410125732\n",
      "2021-04-25 17:56:55,773 [INFO] Training: 6472/6852 -- loss: 1.6717336177825928\n",
      "2021-04-25 17:56:55,821 [INFO] Training: 6473/6852 -- loss: 1.2903772592544556\n",
      "2021-04-25 17:56:55,869 [INFO] Training: 6474/6852 -- loss: 1.7930593490600586\n",
      "2021-04-25 17:56:55,920 [INFO] Training: 6475/6852 -- loss: 2.321626663208008\n",
      "2021-04-25 17:56:55,969 [INFO] Training: 6476/6852 -- loss: 1.3417763710021973\n",
      "2021-04-25 17:56:56,020 [INFO] Training: 6477/6852 -- loss: 3.290053129196167\n",
      "2021-04-25 17:56:56,066 [INFO] Training: 6478/6852 -- loss: 1.7999237775802612\n",
      "2021-04-25 17:56:56,117 [INFO] Training: 6479/6852 -- loss: 1.8021286725997925\n",
      "2021-04-25 17:56:56,164 [INFO] Training: 6480/6852 -- loss: 1.7236278057098389\n",
      "2021-04-25 17:56:56,214 [INFO] Training: 6481/6852 -- loss: 3.2369370460510254\n",
      "2021-04-25 17:56:56,266 [INFO] Training: 6482/6852 -- loss: 2.972785234451294\n",
      "2021-04-25 17:56:56,318 [INFO] Training: 6483/6852 -- loss: 1.234228491783142\n",
      "2021-04-25 17:56:56,368 [INFO] Training: 6484/6852 -- loss: 2.0201401710510254\n",
      "2021-04-25 17:56:56,416 [INFO] Training: 6485/6852 -- loss: 1.9906560182571411\n",
      "2021-04-25 17:56:56,468 [INFO] Training: 6486/6852 -- loss: 1.991442322731018\n",
      "2021-04-25 17:56:56,515 [INFO] Training: 6487/6852 -- loss: 1.7115763425827026\n",
      "2021-04-25 17:56:56,569 [INFO] Training: 6488/6852 -- loss: 2.4265294075012207\n",
      "2021-04-25 17:56:56,621 [INFO] Training: 6489/6852 -- loss: 1.6034289598464966\n",
      "2021-04-25 17:56:56,673 [INFO] Training: 6490/6852 -- loss: 1.8707075119018555\n",
      "2021-04-25 17:56:56,723 [INFO] Training: 6491/6852 -- loss: 1.0147624015808105\n",
      "2021-04-25 17:56:56,771 [INFO] Training: 6492/6852 -- loss: 1.0912418365478516\n",
      "2021-04-25 17:56:56,820 [INFO] Training: 6493/6852 -- loss: 1.7990089654922485\n",
      "2021-04-25 17:56:56,868 [INFO] Training: 6494/6852 -- loss: 0.956872820854187\n",
      "2021-04-25 17:56:56,916 [INFO] Training: 6495/6852 -- loss: 1.0257848501205444\n",
      "2021-04-25 17:56:56,969 [INFO] Training: 6496/6852 -- loss: 2.1901466846466064\n",
      "2021-04-25 17:56:57,016 [INFO] Training: 6497/6852 -- loss: 2.808757781982422\n",
      "2021-04-25 17:56:57,065 [INFO] Training: 6498/6852 -- loss: 1.354245662689209\n",
      "2021-04-25 17:56:57,115 [INFO] Training: 6499/6852 -- loss: 1.238354206085205\n",
      "2021-04-25 17:56:57,167 [INFO] Training: 6500/6852 -- loss: 0.9445791244506836\n",
      "2021-04-25 17:56:57,219 [INFO] Training: 6501/6852 -- loss: 1.4783077239990234\n",
      "2021-04-25 17:56:57,272 [INFO] Training: 6502/6852 -- loss: 2.5442166328430176\n",
      "2021-04-25 17:56:57,321 [INFO] Training: 6503/6852 -- loss: 1.803964614868164\n",
      "2021-04-25 17:56:57,369 [INFO] Training: 6504/6852 -- loss: 1.2066904306411743\n",
      "2021-04-25 17:56:57,418 [INFO] Training: 6505/6852 -- loss: 1.7719491720199585\n",
      "2021-04-25 17:56:57,467 [INFO] Training: 6506/6852 -- loss: 2.2418200969696045\n",
      "2021-04-25 17:56:57,515 [INFO] Training: 6507/6852 -- loss: 2.536113739013672\n",
      "2021-04-25 17:56:57,565 [INFO] Training: 6508/6852 -- loss: 1.3471031188964844\n",
      "2021-04-25 17:56:57,614 [INFO] Training: 6509/6852 -- loss: 1.3628822565078735\n",
      "2021-04-25 17:56:57,670 [INFO] Training: 6510/6852 -- loss: 1.7363240718841553\n",
      "2021-04-25 17:56:57,719 [INFO] Training: 6511/6852 -- loss: 0.9268695116043091\n",
      "2021-04-25 17:56:57,767 [INFO] Training: 6512/6852 -- loss: 1.4754856824874878\n",
      "2021-04-25 17:56:57,816 [INFO] Training: 6513/6852 -- loss: 1.5704154968261719\n",
      "2021-04-25 17:56:57,867 [INFO] Training: 6514/6852 -- loss: 2.5593156814575195\n",
      "2021-04-25 17:56:57,915 [INFO] Training: 6515/6852 -- loss: 1.8350920677185059\n",
      "2021-04-25 17:56:57,967 [INFO] Training: 6516/6852 -- loss: 1.1566057205200195\n",
      "2021-04-25 17:56:58,015 [INFO] Training: 6517/6852 -- loss: 2.1104955673217773\n",
      "2021-04-25 17:56:58,063 [INFO] Training: 6518/6852 -- loss: 1.946112036705017\n",
      "2021-04-25 17:56:58,115 [INFO] Training: 6519/6852 -- loss: 1.7972503900527954\n",
      "2021-04-25 17:56:58,163 [INFO] Training: 6520/6852 -- loss: 3.1427857875823975\n",
      "2021-04-25 17:56:58,213 [INFO] Training: 6521/6852 -- loss: 2.213102102279663\n",
      "2021-04-25 17:56:58,262 [INFO] Training: 6522/6852 -- loss: 2.337021827697754\n",
      "2021-04-25 17:56:58,313 [INFO] Training: 6523/6852 -- loss: 1.4429430961608887\n",
      "2021-04-25 17:56:58,361 [INFO] Training: 6524/6852 -- loss: 1.0775847434997559\n",
      "2021-04-25 17:56:58,408 [INFO] Training: 6525/6852 -- loss: 2.1939053535461426\n",
      "2021-04-25 17:56:58,459 [INFO] Training: 6526/6852 -- loss: 1.496116280555725\n",
      "2021-04-25 17:56:58,509 [INFO] Training: 6527/6852 -- loss: 1.640121340751648\n",
      "2021-04-25 17:56:58,560 [INFO] Training: 6528/6852 -- loss: 2.250615119934082\n",
      "2021-04-25 17:56:58,610 [INFO] Training: 6529/6852 -- loss: 1.806100606918335\n",
      "2021-04-25 17:56:58,661 [INFO] Training: 6530/6852 -- loss: 1.850282907485962\n",
      "2021-04-25 17:56:58,712 [INFO] Training: 6531/6852 -- loss: 1.2058361768722534\n",
      "2021-04-25 17:56:58,763 [INFO] Training: 6532/6852 -- loss: 1.1127444505691528\n",
      "2021-04-25 17:56:58,811 [INFO] Training: 6533/6852 -- loss: 1.4566279649734497\n",
      "2021-04-25 17:56:58,864 [INFO] Training: 6534/6852 -- loss: 1.7101691961288452\n",
      "2021-04-25 17:56:58,915 [INFO] Training: 6535/6852 -- loss: 1.7818207740783691\n",
      "2021-04-25 17:56:58,966 [INFO] Training: 6536/6852 -- loss: 1.6581077575683594\n",
      "2021-04-25 17:56:59,018 [INFO] Training: 6537/6852 -- loss: 0.9453089833259583\n",
      "2021-04-25 17:56:59,070 [INFO] Training: 6538/6852 -- loss: 1.531308889389038\n",
      "2021-04-25 17:56:59,119 [INFO] Training: 6539/6852 -- loss: 1.1275765895843506\n",
      "2021-04-25 17:56:59,167 [INFO] Training: 6540/6852 -- loss: 0.4048885107040405\n",
      "2021-04-25 17:56:59,217 [INFO] Training: 6541/6852 -- loss: 1.9910327196121216\n",
      "2021-04-25 17:56:59,267 [INFO] Training: 6542/6852 -- loss: 1.641204833984375\n",
      "2021-04-25 17:56:59,316 [INFO] Training: 6543/6852 -- loss: 1.9464712142944336\n",
      "2021-04-25 17:56:59,366 [INFO] Training: 6544/6852 -- loss: 1.274983525276184\n",
      "2021-04-25 17:56:59,415 [INFO] Training: 6545/6852 -- loss: 1.4097601175308228\n",
      "2021-04-25 17:56:59,467 [INFO] Training: 6546/6852 -- loss: 1.3064528703689575\n",
      "2021-04-25 17:56:59,518 [INFO] Training: 6547/6852 -- loss: 2.1178739070892334\n",
      "2021-04-25 17:56:59,571 [INFO] Training: 6548/6852 -- loss: 1.5109219551086426\n",
      "2021-04-25 17:56:59,620 [INFO] Training: 6549/6852 -- loss: 1.4776582717895508\n",
      "2021-04-25 17:56:59,668 [INFO] Training: 6550/6852 -- loss: 1.8680312633514404\n",
      "2021-04-25 17:56:59,718 [INFO] Training: 6551/6852 -- loss: 2.0179247856140137\n",
      "2021-04-25 17:56:59,770 [INFO] Training: 6552/6852 -- loss: 1.0577276945114136\n",
      "2021-04-25 17:56:59,818 [INFO] Training: 6553/6852 -- loss: 2.236107110977173\n",
      "2021-04-25 17:56:59,869 [INFO] Training: 6554/6852 -- loss: 1.3632605075836182\n",
      "2021-04-25 17:56:59,917 [INFO] Training: 6555/6852 -- loss: 1.6957013607025146\n",
      "2021-04-25 17:56:59,966 [INFO] Training: 6556/6852 -- loss: 2.1055710315704346\n",
      "2021-04-25 17:57:00,013 [INFO] Training: 6557/6852 -- loss: 1.0888252258300781\n",
      "2021-04-25 17:57:00,065 [INFO] Training: 6558/6852 -- loss: 1.3491973876953125\n",
      "2021-04-25 17:57:00,111 [INFO] Training: 6559/6852 -- loss: 2.123650074005127\n",
      "2021-04-25 17:57:00,160 [INFO] Training: 6560/6852 -- loss: 1.9246125221252441\n",
      "2021-04-25 17:57:00,210 [INFO] Training: 6561/6852 -- loss: 1.6431536674499512\n",
      "2021-04-25 17:57:00,264 [INFO] Training: 6562/6852 -- loss: 1.6456551551818848\n",
      "2021-04-25 17:57:00,317 [INFO] Training: 6563/6852 -- loss: 1.7159950733184814\n",
      "2021-04-25 17:57:00,364 [INFO] Training: 6564/6852 -- loss: 1.4476313591003418\n",
      "2021-04-25 17:57:00,414 [INFO] Training: 6565/6852 -- loss: 2.3947558403015137\n",
      "2021-04-25 17:57:00,467 [INFO] Training: 6566/6852 -- loss: 1.0100573301315308\n",
      "2021-04-25 17:57:00,518 [INFO] Training: 6567/6852 -- loss: 1.8529832363128662\n",
      "2021-04-25 17:57:00,568 [INFO] Training: 6568/6852 -- loss: 2.0372188091278076\n",
      "2021-04-25 17:57:00,617 [INFO] Training: 6569/6852 -- loss: 1.042773723602295\n",
      "2021-04-25 17:57:00,664 [INFO] Training: 6570/6852 -- loss: 2.0938796997070312\n",
      "2021-04-25 17:57:00,719 [INFO] Training: 6571/6852 -- loss: 1.567136526107788\n",
      "2021-04-25 17:57:00,765 [INFO] Training: 6572/6852 -- loss: 1.8798538446426392\n",
      "2021-04-25 17:57:00,815 [INFO] Training: 6573/6852 -- loss: 1.9618321657180786\n",
      "2021-04-25 17:57:00,864 [INFO] Training: 6574/6852 -- loss: 1.6110249757766724\n",
      "2021-04-25 17:57:00,914 [INFO] Training: 6575/6852 -- loss: 1.8053832054138184\n",
      "2021-04-25 17:57:00,965 [INFO] Training: 6576/6852 -- loss: 1.716831088066101\n",
      "2021-04-25 17:57:01,018 [INFO] Training: 6577/6852 -- loss: 1.863885521888733\n",
      "2021-04-25 17:57:01,070 [INFO] Training: 6578/6852 -- loss: 1.017027497291565\n",
      "2021-04-25 17:57:01,118 [INFO] Training: 6579/6852 -- loss: 1.3417097330093384\n",
      "2021-04-25 17:57:01,170 [INFO] Training: 6580/6852 -- loss: 2.62229585647583\n",
      "2021-04-25 17:57:01,221 [INFO] Training: 6581/6852 -- loss: 2.784796953201294\n",
      "2021-04-25 17:57:01,273 [INFO] Training: 6582/6852 -- loss: 0.7058433890342712\n",
      "2021-04-25 17:57:01,325 [INFO] Training: 6583/6852 -- loss: 1.4205671548843384\n",
      "2021-04-25 17:57:01,373 [INFO] Training: 6584/6852 -- loss: 1.6822320222854614\n",
      "2021-04-25 17:57:01,422 [INFO] Training: 6585/6852 -- loss: 1.2940346002578735\n",
      "2021-04-25 17:57:01,471 [INFO] Training: 6586/6852 -- loss: 1.2800369262695312\n",
      "2021-04-25 17:57:01,522 [INFO] Training: 6587/6852 -- loss: 1.5384974479675293\n",
      "2021-04-25 17:57:01,574 [INFO] Training: 6588/6852 -- loss: 1.0614845752716064\n",
      "2021-04-25 17:57:01,623 [INFO] Training: 6589/6852 -- loss: 0.9943553805351257\n",
      "2021-04-25 17:57:01,674 [INFO] Training: 6590/6852 -- loss: 1.000499963760376\n",
      "2021-04-25 17:57:01,721 [INFO] Training: 6591/6852 -- loss: 1.6510050296783447\n",
      "2021-04-25 17:57:01,771 [INFO] Training: 6592/6852 -- loss: 1.6624282598495483\n",
      "2021-04-25 17:57:01,819 [INFO] Training: 6593/6852 -- loss: 1.2229276895523071\n",
      "2021-04-25 17:57:01,873 [INFO] Training: 6594/6852 -- loss: 1.290830135345459\n",
      "2021-04-25 17:57:01,922 [INFO] Training: 6595/6852 -- loss: 1.0237270593643188\n",
      "2021-04-25 17:57:01,972 [INFO] Training: 6596/6852 -- loss: 2.1494202613830566\n",
      "2021-04-25 17:57:02,021 [INFO] Training: 6597/6852 -- loss: 0.9846189618110657\n",
      "2021-04-25 17:57:02,071 [INFO] Training: 6598/6852 -- loss: 0.9489074349403381\n",
      "2021-04-25 17:57:02,120 [INFO] Training: 6599/6852 -- loss: 0.8284258246421814\n",
      "2021-04-25 17:57:02,173 [INFO] Training: 6600/6852 -- loss: 2.7000014781951904\n",
      "2021-04-25 17:57:05,040 [INFO] Training: iteration: 6600/6852 -- epoch: 11 --  train_loss: 1.692 -- train_accuracy: 0.25 valid_loss: 3.292 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:57:05,079 [INFO] Training: 6601/6852 -- loss: 2.273880958557129\n",
      "2021-04-25 17:57:05,128 [INFO] Training: 6602/6852 -- loss: 3.2637288570404053\n",
      "2021-04-25 17:57:05,178 [INFO] Training: 6603/6852 -- loss: 2.2866861820220947\n",
      "2021-04-25 17:57:05,227 [INFO] Training: 6604/6852 -- loss: 2.40999698638916\n",
      "2021-04-25 17:57:05,279 [INFO] Training: 6605/6852 -- loss: 1.0905970335006714\n",
      "2021-04-25 17:57:05,331 [INFO] Training: 6606/6852 -- loss: 1.69551420211792\n",
      "2021-04-25 17:57:05,383 [INFO] Training: 6607/6852 -- loss: 1.8573209047317505\n",
      "2021-04-25 17:57:05,434 [INFO] Training: 6608/6852 -- loss: 2.3964624404907227\n",
      "2021-04-25 17:57:05,484 [INFO] Training: 6609/6852 -- loss: 1.5198071002960205\n",
      "2021-04-25 17:57:05,534 [INFO] Training: 6610/6852 -- loss: 1.7887825965881348\n",
      "2021-04-25 17:57:05,583 [INFO] Training: 6611/6852 -- loss: 1.0602970123291016\n",
      "2021-04-25 17:57:05,635 [INFO] Training: 6612/6852 -- loss: 1.1558127403259277\n",
      "2021-04-25 17:57:05,684 [INFO] Training: 6613/6852 -- loss: 0.7606133222579956\n",
      "2021-04-25 17:57:05,734 [INFO] Training: 6614/6852 -- loss: 1.0359445810317993\n",
      "2021-04-25 17:57:05,783 [INFO] Training: 6615/6852 -- loss: 2.1064858436584473\n",
      "2021-04-25 17:57:05,838 [INFO] Training: 6616/6852 -- loss: 0.9725682139396667\n",
      "2021-04-25 17:57:05,889 [INFO] Training: 6617/6852 -- loss: 1.9235832691192627\n",
      "2021-04-25 17:57:05,940 [INFO] Training: 6618/6852 -- loss: 2.191330909729004\n",
      "2021-04-25 17:57:05,988 [INFO] Training: 6619/6852 -- loss: 2.3348753452301025\n",
      "2021-04-25 17:57:06,038 [INFO] Training: 6620/6852 -- loss: 1.5253299474716187\n",
      "2021-04-25 17:57:06,085 [INFO] Training: 6621/6852 -- loss: 2.1305148601531982\n",
      "2021-04-25 17:57:06,135 [INFO] Training: 6622/6852 -- loss: 1.7401820421218872\n",
      "2021-04-25 17:57:06,184 [INFO] Training: 6623/6852 -- loss: 1.5397415161132812\n",
      "2021-04-25 17:57:06,233 [INFO] Training: 6624/6852 -- loss: 2.3390018939971924\n",
      "2021-04-25 17:57:06,282 [INFO] Training: 6625/6852 -- loss: 0.869554877281189\n",
      "2021-04-25 17:57:06,331 [INFO] Training: 6626/6852 -- loss: 1.5561901330947876\n",
      "2021-04-25 17:57:06,389 [INFO] Training: 6627/6852 -- loss: 1.3292508125305176\n",
      "2021-04-25 17:57:06,438 [INFO] Training: 6628/6852 -- loss: 1.2347850799560547\n",
      "2021-04-25 17:57:06,488 [INFO] Training: 6629/6852 -- loss: 2.1977157592773438\n",
      "2021-04-25 17:57:06,536 [INFO] Training: 6630/6852 -- loss: 1.7684155702590942\n",
      "2021-04-25 17:57:06,590 [INFO] Training: 6631/6852 -- loss: 2.8247804641723633\n",
      "2021-04-25 17:57:06,639 [INFO] Training: 6632/6852 -- loss: 1.9015010595321655\n",
      "2021-04-25 17:57:06,689 [INFO] Training: 6633/6852 -- loss: 1.9492379426956177\n",
      "2021-04-25 17:57:06,736 [INFO] Training: 6634/6852 -- loss: 1.982184886932373\n",
      "2021-04-25 17:57:06,785 [INFO] Training: 6635/6852 -- loss: 1.8735095262527466\n",
      "2021-04-25 17:57:06,835 [INFO] Training: 6636/6852 -- loss: 1.7859282493591309\n",
      "2021-04-25 17:57:06,883 [INFO] Training: 6637/6852 -- loss: 0.7985765337944031\n",
      "2021-04-25 17:57:06,934 [INFO] Training: 6638/6852 -- loss: 1.2874778509140015\n",
      "2021-04-25 17:57:06,981 [INFO] Training: 6639/6852 -- loss: 3.7030138969421387\n",
      "2021-04-25 17:57:07,032 [INFO] Training: 6640/6852 -- loss: 1.9926378726959229\n",
      "2021-04-25 17:57:07,080 [INFO] Training: 6641/6852 -- loss: 2.181791305541992\n",
      "2021-04-25 17:57:07,130 [INFO] Training: 6642/6852 -- loss: 1.2812564373016357\n",
      "2021-04-25 17:57:07,180 [INFO] Training: 6643/6852 -- loss: 1.38009512424469\n",
      "2021-04-25 17:57:07,228 [INFO] Training: 6644/6852 -- loss: 1.0235713720321655\n",
      "2021-04-25 17:57:07,277 [INFO] Training: 6645/6852 -- loss: 1.6187976598739624\n",
      "2021-04-25 17:57:07,327 [INFO] Training: 6646/6852 -- loss: 1.171201229095459\n",
      "2021-04-25 17:57:07,375 [INFO] Training: 6647/6852 -- loss: 0.901098370552063\n",
      "2021-04-25 17:57:07,424 [INFO] Training: 6648/6852 -- loss: 2.7797842025756836\n",
      "2021-04-25 17:57:07,477 [INFO] Training: 6649/6852 -- loss: 0.7936207056045532\n",
      "2021-04-25 17:57:07,527 [INFO] Training: 6650/6852 -- loss: 1.516953706741333\n",
      "2021-04-25 17:57:07,577 [INFO] Training: 6651/6852 -- loss: 1.9950966835021973\n",
      "2021-04-25 17:57:07,625 [INFO] Training: 6652/6852 -- loss: 0.624042272567749\n",
      "2021-04-25 17:57:07,672 [INFO] Training: 6653/6852 -- loss: 1.4969946146011353\n",
      "2021-04-25 17:57:07,720 [INFO] Training: 6654/6852 -- loss: 2.0278737545013428\n",
      "2021-04-25 17:57:07,767 [INFO] Training: 6655/6852 -- loss: 1.3653504848480225\n",
      "2021-04-25 17:57:07,814 [INFO] Training: 6656/6852 -- loss: 2.118389368057251\n",
      "2021-04-25 17:57:07,863 [INFO] Training: 6657/6852 -- loss: 1.7695281505584717\n",
      "2021-04-25 17:57:07,912 [INFO] Training: 6658/6852 -- loss: 2.7222604751586914\n",
      "2021-04-25 17:57:07,964 [INFO] Training: 6659/6852 -- loss: 1.6554198265075684\n",
      "2021-04-25 17:57:08,011 [INFO] Training: 6660/6852 -- loss: 2.6155974864959717\n",
      "2021-04-25 17:57:08,058 [INFO] Training: 6661/6852 -- loss: 0.8997594118118286\n",
      "2021-04-25 17:57:08,110 [INFO] Training: 6662/6852 -- loss: 1.9375245571136475\n",
      "2021-04-25 17:57:08,159 [INFO] Training: 6663/6852 -- loss: 2.171461582183838\n",
      "2021-04-25 17:57:08,207 [INFO] Training: 6664/6852 -- loss: 1.6337202787399292\n",
      "2021-04-25 17:57:08,255 [INFO] Training: 6665/6852 -- loss: 1.2204749584197998\n",
      "2021-04-25 17:57:08,307 [INFO] Training: 6666/6852 -- loss: 1.126038670539856\n",
      "2021-04-25 17:57:08,355 [INFO] Training: 6667/6852 -- loss: 1.3583217859268188\n",
      "2021-04-25 17:57:08,405 [INFO] Training: 6668/6852 -- loss: 1.541735291481018\n",
      "2021-04-25 17:57:08,457 [INFO] Training: 6669/6852 -- loss: 1.3139283657073975\n",
      "2021-04-25 17:57:08,505 [INFO] Training: 6670/6852 -- loss: 2.3747730255126953\n",
      "2021-04-25 17:57:08,556 [INFO] Training: 6671/6852 -- loss: 1.043623447418213\n",
      "2021-04-25 17:57:08,606 [INFO] Training: 6672/6852 -- loss: 1.2662510871887207\n",
      "2021-04-25 17:57:08,657 [INFO] Training: 6673/6852 -- loss: 1.0567080974578857\n",
      "2021-04-25 17:57:08,705 [INFO] Training: 6674/6852 -- loss: 1.4180833101272583\n",
      "2021-04-25 17:57:08,754 [INFO] Training: 6675/6852 -- loss: 1.0925555229187012\n",
      "2021-04-25 17:57:08,804 [INFO] Training: 6676/6852 -- loss: 2.928079843521118\n",
      "2021-04-25 17:57:08,853 [INFO] Training: 6677/6852 -- loss: 1.5450377464294434\n",
      "2021-04-25 17:57:08,904 [INFO] Training: 6678/6852 -- loss: 1.8008768558502197\n",
      "2021-04-25 17:57:08,953 [INFO] Training: 6679/6852 -- loss: 0.7821722030639648\n",
      "2021-04-25 17:57:09,003 [INFO] Training: 6680/6852 -- loss: 2.1091253757476807\n",
      "2021-04-25 17:57:09,052 [INFO] Training: 6681/6852 -- loss: 1.6299209594726562\n",
      "2021-04-25 17:57:09,102 [INFO] Training: 6682/6852 -- loss: 2.845182180404663\n",
      "2021-04-25 17:57:09,154 [INFO] Training: 6683/6852 -- loss: 1.3574138879776\n",
      "2021-04-25 17:57:09,206 [INFO] Training: 6684/6852 -- loss: 1.2295335531234741\n",
      "2021-04-25 17:57:09,256 [INFO] Training: 6685/6852 -- loss: 0.709842324256897\n",
      "2021-04-25 17:57:09,309 [INFO] Training: 6686/6852 -- loss: 1.0906602144241333\n",
      "2021-04-25 17:57:09,361 [INFO] Training: 6687/6852 -- loss: 1.2573683261871338\n",
      "2021-04-25 17:57:09,410 [INFO] Training: 6688/6852 -- loss: 1.2952203750610352\n",
      "2021-04-25 17:57:09,462 [INFO] Training: 6689/6852 -- loss: 1.0036742687225342\n",
      "2021-04-25 17:57:09,511 [INFO] Training: 6690/6852 -- loss: 1.5730006694793701\n",
      "2021-04-25 17:57:09,565 [INFO] Training: 6691/6852 -- loss: 2.1998164653778076\n",
      "2021-04-25 17:57:09,619 [INFO] Training: 6692/6852 -- loss: 1.5460386276245117\n",
      "2021-04-25 17:57:09,669 [INFO] Training: 6693/6852 -- loss: 2.336317539215088\n",
      "2021-04-25 17:57:09,717 [INFO] Training: 6694/6852 -- loss: 1.5342824459075928\n",
      "2021-04-25 17:57:09,764 [INFO] Training: 6695/6852 -- loss: 2.0948126316070557\n",
      "2021-04-25 17:57:09,813 [INFO] Training: 6696/6852 -- loss: 3.249584913253784\n",
      "2021-04-25 17:57:09,866 [INFO] Training: 6697/6852 -- loss: 0.6477733254432678\n",
      "2021-04-25 17:57:09,917 [INFO] Training: 6698/6852 -- loss: 2.1552062034606934\n",
      "2021-04-25 17:57:09,968 [INFO] Training: 6699/6852 -- loss: 2.4784762859344482\n",
      "2021-04-25 17:57:10,016 [INFO] Training: 6700/6852 -- loss: 0.9690645337104797\n",
      "2021-04-25 17:57:10,069 [INFO] Training: 6701/6852 -- loss: 2.2111949920654297\n",
      "2021-04-25 17:57:10,120 [INFO] Training: 6702/6852 -- loss: 1.8610999584197998\n",
      "2021-04-25 17:57:10,173 [INFO] Training: 6703/6852 -- loss: 1.745412826538086\n",
      "2021-04-25 17:57:10,226 [INFO] Training: 6704/6852 -- loss: 1.1124857664108276\n",
      "2021-04-25 17:57:10,280 [INFO] Training: 6705/6852 -- loss: 1.621290922164917\n",
      "2021-04-25 17:57:10,327 [INFO] Training: 6706/6852 -- loss: 1.849404215812683\n",
      "2021-04-25 17:57:10,375 [INFO] Training: 6707/6852 -- loss: 1.9696378707885742\n",
      "2021-04-25 17:57:10,425 [INFO] Training: 6708/6852 -- loss: 2.2672882080078125\n",
      "2021-04-25 17:57:10,472 [INFO] Training: 6709/6852 -- loss: 1.7507742643356323\n",
      "2021-04-25 17:57:10,521 [INFO] Training: 6710/6852 -- loss: 2.1323020458221436\n",
      "2021-04-25 17:57:10,569 [INFO] Training: 6711/6852 -- loss: 2.8554463386535645\n",
      "2021-04-25 17:57:10,617 [INFO] Training: 6712/6852 -- loss: 0.9823275208473206\n",
      "2021-04-25 17:57:10,665 [INFO] Training: 6713/6852 -- loss: 1.2610481977462769\n",
      "2021-04-25 17:57:10,716 [INFO] Training: 6714/6852 -- loss: 2.038273811340332\n",
      "2021-04-25 17:57:10,767 [INFO] Training: 6715/6852 -- loss: 3.5794472694396973\n",
      "2021-04-25 17:57:10,814 [INFO] Training: 6716/6852 -- loss: 2.162619113922119\n",
      "2021-04-25 17:57:10,862 [INFO] Training: 6717/6852 -- loss: 2.1115124225616455\n",
      "2021-04-25 17:57:10,910 [INFO] Training: 6718/6852 -- loss: 1.6429888010025024\n",
      "2021-04-25 17:57:10,958 [INFO] Training: 6719/6852 -- loss: 0.9713364839553833\n",
      "2021-04-25 17:57:11,010 [INFO] Training: 6720/6852 -- loss: 2.235419988632202\n",
      "2021-04-25 17:57:11,057 [INFO] Training: 6721/6852 -- loss: 2.0559988021850586\n",
      "2021-04-25 17:57:11,110 [INFO] Training: 6722/6852 -- loss: 2.591818332672119\n",
      "2021-04-25 17:57:11,163 [INFO] Training: 6723/6852 -- loss: 0.65140300989151\n",
      "2021-04-25 17:57:11,212 [INFO] Training: 6724/6852 -- loss: 1.4363106489181519\n",
      "2021-04-25 17:57:11,262 [INFO] Training: 6725/6852 -- loss: 1.9024051427841187\n",
      "2021-04-25 17:57:11,313 [INFO] Training: 6726/6852 -- loss: 1.824484944343567\n",
      "2021-04-25 17:57:11,362 [INFO] Training: 6727/6852 -- loss: 1.134363055229187\n",
      "2021-04-25 17:57:11,415 [INFO] Training: 6728/6852 -- loss: 2.1954591274261475\n",
      "2021-04-25 17:57:11,469 [INFO] Training: 6729/6852 -- loss: 0.8517763614654541\n",
      "2021-04-25 17:57:11,520 [INFO] Training: 6730/6852 -- loss: 1.729751706123352\n",
      "2021-04-25 17:57:11,572 [INFO] Training: 6731/6852 -- loss: 2.690641403198242\n",
      "2021-04-25 17:57:11,622 [INFO] Training: 6732/6852 -- loss: 3.303455352783203\n",
      "2021-04-25 17:57:11,670 [INFO] Training: 6733/6852 -- loss: 1.649427890777588\n",
      "2021-04-25 17:57:11,722 [INFO] Training: 6734/6852 -- loss: 1.4998615980148315\n",
      "2021-04-25 17:57:11,773 [INFO] Training: 6735/6852 -- loss: 2.0320425033569336\n",
      "2021-04-25 17:57:11,827 [INFO] Training: 6736/6852 -- loss: 1.0632877349853516\n",
      "2021-04-25 17:57:11,876 [INFO] Training: 6737/6852 -- loss: 2.2769789695739746\n",
      "2021-04-25 17:57:11,929 [INFO] Training: 6738/6852 -- loss: 2.269146680831909\n",
      "2021-04-25 17:57:11,979 [INFO] Training: 6739/6852 -- loss: 1.809621810913086\n",
      "2021-04-25 17:57:12,027 [INFO] Training: 6740/6852 -- loss: 2.193737268447876\n",
      "2021-04-25 17:57:12,075 [INFO] Training: 6741/6852 -- loss: 3.314028263092041\n",
      "2021-04-25 17:57:12,129 [INFO] Training: 6742/6852 -- loss: 2.323007822036743\n",
      "2021-04-25 17:57:12,181 [INFO] Training: 6743/6852 -- loss: 1.7248780727386475\n",
      "2021-04-25 17:57:12,230 [INFO] Training: 6744/6852 -- loss: 2.4163219928741455\n",
      "2021-04-25 17:57:12,278 [INFO] Training: 6745/6852 -- loss: 1.0565822124481201\n",
      "2021-04-25 17:57:12,329 [INFO] Training: 6746/6852 -- loss: 1.9058035612106323\n",
      "2021-04-25 17:57:12,376 [INFO] Training: 6747/6852 -- loss: 1.149834156036377\n",
      "2021-04-25 17:57:12,423 [INFO] Training: 6748/6852 -- loss: 1.2152934074401855\n",
      "2021-04-25 17:57:12,477 [INFO] Training: 6749/6852 -- loss: 2.0228002071380615\n",
      "2021-04-25 17:57:12,524 [INFO] Training: 6750/6852 -- loss: 1.3038016557693481\n",
      "2021-04-25 17:57:15,391 [INFO] Training: iteration: 6750/6852 -- epoch: 11 --  train_loss: 1.755 -- train_accuracy: 0.75 valid_loss: 3.282 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:57:15,435 [INFO] Training: 6751/6852 -- loss: 1.6331844329833984\n",
      "2021-04-25 17:57:15,482 [INFO] Training: 6752/6852 -- loss: 1.8298828601837158\n",
      "2021-04-25 17:57:15,537 [INFO] Training: 6753/6852 -- loss: 1.5257515907287598\n",
      "2021-04-25 17:57:15,589 [INFO] Training: 6754/6852 -- loss: 1.3304575681686401\n",
      "2021-04-25 17:57:15,638 [INFO] Training: 6755/6852 -- loss: 1.7163965702056885\n",
      "2021-04-25 17:57:15,686 [INFO] Training: 6756/6852 -- loss: 2.1198201179504395\n",
      "2021-04-25 17:57:15,735 [INFO] Training: 6757/6852 -- loss: 1.284566044807434\n",
      "2021-04-25 17:57:15,787 [INFO] Training: 6758/6852 -- loss: 1.6595056056976318\n",
      "2021-04-25 17:57:15,834 [INFO] Training: 6759/6852 -- loss: 1.0117131471633911\n",
      "2021-04-25 17:57:15,884 [INFO] Training: 6760/6852 -- loss: 2.198636054992676\n",
      "2021-04-25 17:57:15,936 [INFO] Training: 6761/6852 -- loss: 1.4033515453338623\n",
      "2021-04-25 17:57:15,986 [INFO] Training: 6762/6852 -- loss: 1.3882042169570923\n",
      "2021-04-25 17:57:16,034 [INFO] Training: 6763/6852 -- loss: 2.275454044342041\n",
      "2021-04-25 17:57:16,084 [INFO] Training: 6764/6852 -- loss: 1.575094223022461\n",
      "2021-04-25 17:57:16,133 [INFO] Training: 6765/6852 -- loss: 1.4945824146270752\n",
      "2021-04-25 17:57:16,183 [INFO] Training: 6766/6852 -- loss: 2.734127998352051\n",
      "2021-04-25 17:57:16,233 [INFO] Training: 6767/6852 -- loss: 2.1966030597686768\n",
      "2021-04-25 17:57:16,282 [INFO] Training: 6768/6852 -- loss: 1.1240732669830322\n",
      "2021-04-25 17:57:16,338 [INFO] Training: 6769/6852 -- loss: 1.8084700107574463\n",
      "2021-04-25 17:57:16,387 [INFO] Training: 6770/6852 -- loss: 1.7548635005950928\n",
      "2021-04-25 17:57:16,435 [INFO] Training: 6771/6852 -- loss: 1.8112221956253052\n",
      "2021-04-25 17:57:16,483 [INFO] Training: 6772/6852 -- loss: 1.6063189506530762\n",
      "2021-04-25 17:57:16,531 [INFO] Training: 6773/6852 -- loss: 2.02724027633667\n",
      "2021-04-25 17:57:16,588 [INFO] Training: 6774/6852 -- loss: 1.5528502464294434\n",
      "2021-04-25 17:57:16,638 [INFO] Training: 6775/6852 -- loss: 1.8076056241989136\n",
      "2021-04-25 17:57:16,689 [INFO] Training: 6776/6852 -- loss: 1.3118400573730469\n",
      "2021-04-25 17:57:16,737 [INFO] Training: 6777/6852 -- loss: 1.8501160144805908\n",
      "2021-04-25 17:57:16,784 [INFO] Training: 6778/6852 -- loss: 1.6448503732681274\n",
      "2021-04-25 17:57:16,835 [INFO] Training: 6779/6852 -- loss: 1.6733102798461914\n",
      "2021-04-25 17:57:16,884 [INFO] Training: 6780/6852 -- loss: 2.017695426940918\n",
      "2021-04-25 17:57:16,935 [INFO] Training: 6781/6852 -- loss: 1.5366053581237793\n",
      "2021-04-25 17:57:16,986 [INFO] Training: 6782/6852 -- loss: 1.805643081665039\n",
      "2021-04-25 17:57:17,037 [INFO] Training: 6783/6852 -- loss: 1.1117877960205078\n",
      "2021-04-25 17:57:17,086 [INFO] Training: 6784/6852 -- loss: 1.9900000095367432\n",
      "2021-04-25 17:57:17,138 [INFO] Training: 6785/6852 -- loss: 2.014549493789673\n",
      "2021-04-25 17:57:17,186 [INFO] Training: 6786/6852 -- loss: 1.491303563117981\n",
      "2021-04-25 17:57:17,233 [INFO] Training: 6787/6852 -- loss: 1.803560495376587\n",
      "2021-04-25 17:57:17,282 [INFO] Training: 6788/6852 -- loss: 1.7027239799499512\n",
      "2021-04-25 17:57:17,329 [INFO] Training: 6789/6852 -- loss: 1.6015034914016724\n",
      "2021-04-25 17:57:17,382 [INFO] Training: 6790/6852 -- loss: 1.821516752243042\n",
      "2021-04-25 17:57:17,436 [INFO] Training: 6791/6852 -- loss: 1.035965919494629\n",
      "2021-04-25 17:57:17,484 [INFO] Training: 6792/6852 -- loss: 1.1648924350738525\n",
      "2021-04-25 17:57:17,533 [INFO] Training: 6793/6852 -- loss: 0.857239305973053\n",
      "2021-04-25 17:57:17,586 [INFO] Training: 6794/6852 -- loss: 1.9622130393981934\n",
      "2021-04-25 17:57:17,638 [INFO] Training: 6795/6852 -- loss: 1.9575817584991455\n",
      "2021-04-25 17:57:17,687 [INFO] Training: 6796/6852 -- loss: 1.2451426982879639\n",
      "2021-04-25 17:57:17,734 [INFO] Training: 6797/6852 -- loss: 1.8857909440994263\n",
      "2021-04-25 17:57:17,784 [INFO] Training: 6798/6852 -- loss: 2.9968671798706055\n",
      "2021-04-25 17:57:17,833 [INFO] Training: 6799/6852 -- loss: 1.1447734832763672\n",
      "2021-04-25 17:57:17,884 [INFO] Training: 6800/6852 -- loss: 2.6094179153442383\n",
      "2021-04-25 17:57:17,934 [INFO] Training: 6801/6852 -- loss: 1.0406444072723389\n",
      "2021-04-25 17:57:17,982 [INFO] Training: 6802/6852 -- loss: 2.0423080921173096\n",
      "2021-04-25 17:57:18,036 [INFO] Training: 6803/6852 -- loss: 1.1526354551315308\n",
      "2021-04-25 17:57:18,084 [INFO] Training: 6804/6852 -- loss: 1.6592235565185547\n",
      "2021-04-25 17:57:18,135 [INFO] Training: 6805/6852 -- loss: 2.7968318462371826\n",
      "2021-04-25 17:57:18,188 [INFO] Training: 6806/6852 -- loss: 2.367457866668701\n",
      "2021-04-25 17:57:18,239 [INFO] Training: 6807/6852 -- loss: 1.240968942642212\n",
      "2021-04-25 17:57:18,288 [INFO] Training: 6808/6852 -- loss: 1.7505745887756348\n",
      "2021-04-25 17:57:18,341 [INFO] Training: 6809/6852 -- loss: 1.4685337543487549\n",
      "2021-04-25 17:57:18,388 [INFO] Training: 6810/6852 -- loss: 2.605302095413208\n",
      "2021-04-25 17:57:18,438 [INFO] Training: 6811/6852 -- loss: 1.370343565940857\n",
      "2021-04-25 17:57:18,487 [INFO] Training: 6812/6852 -- loss: 0.8377819657325745\n",
      "2021-04-25 17:57:18,538 [INFO] Training: 6813/6852 -- loss: 2.450909376144409\n",
      "2021-04-25 17:57:18,585 [INFO] Training: 6814/6852 -- loss: 2.483657121658325\n",
      "2021-04-25 17:57:18,634 [INFO] Training: 6815/6852 -- loss: 2.594970941543579\n",
      "2021-04-25 17:57:18,685 [INFO] Training: 6816/6852 -- loss: 2.4212100505828857\n",
      "2021-04-25 17:57:18,732 [INFO] Training: 6817/6852 -- loss: 1.9419631958007812\n",
      "2021-04-25 17:57:18,783 [INFO] Training: 6818/6852 -- loss: 1.9613838195800781\n",
      "2021-04-25 17:57:18,832 [INFO] Training: 6819/6852 -- loss: 2.325767993927002\n",
      "2021-04-25 17:57:18,883 [INFO] Training: 6820/6852 -- loss: 1.0064438581466675\n",
      "2021-04-25 17:57:18,932 [INFO] Training: 6821/6852 -- loss: 0.8859396576881409\n",
      "2021-04-25 17:57:18,983 [INFO] Training: 6822/6852 -- loss: 1.6458147764205933\n",
      "2021-04-25 17:57:19,036 [INFO] Training: 6823/6852 -- loss: 1.3891382217407227\n",
      "2021-04-25 17:57:19,085 [INFO] Training: 6824/6852 -- loss: 1.7600924968719482\n",
      "2021-04-25 17:57:19,137 [INFO] Training: 6825/6852 -- loss: 1.1365606784820557\n",
      "2021-04-25 17:57:19,187 [INFO] Training: 6826/6852 -- loss: 1.190996527671814\n",
      "2021-04-25 17:57:19,235 [INFO] Training: 6827/6852 -- loss: 1.447811245918274\n",
      "2021-04-25 17:57:19,285 [INFO] Training: 6828/6852 -- loss: 2.372433662414551\n",
      "2021-04-25 17:57:19,339 [INFO] Training: 6829/6852 -- loss: 1.5624786615371704\n",
      "2021-04-25 17:57:19,392 [INFO] Training: 6830/6852 -- loss: 1.5382983684539795\n",
      "2021-04-25 17:57:19,442 [INFO] Training: 6831/6852 -- loss: 1.802586555480957\n",
      "2021-04-25 17:57:19,492 [INFO] Training: 6832/6852 -- loss: 1.7167840003967285\n",
      "2021-04-25 17:57:19,542 [INFO] Training: 6833/6852 -- loss: 0.7614133954048157\n",
      "2021-04-25 17:57:19,598 [INFO] Training: 6834/6852 -- loss: 1.5452841520309448\n",
      "2021-04-25 17:57:19,645 [INFO] Training: 6835/6852 -- loss: 2.282632350921631\n",
      "2021-04-25 17:57:19,695 [INFO] Training: 6836/6852 -- loss: 2.384761333465576\n",
      "2021-04-25 17:57:19,744 [INFO] Training: 6837/6852 -- loss: 2.274963140487671\n",
      "2021-04-25 17:57:19,796 [INFO] Training: 6838/6852 -- loss: 1.5310057401657104\n",
      "2021-04-25 17:57:19,847 [INFO] Training: 6839/6852 -- loss: 1.4707838296890259\n",
      "2021-04-25 17:57:19,900 [INFO] Training: 6840/6852 -- loss: 1.9864450693130493\n",
      "2021-04-25 17:57:19,950 [INFO] Training: 6841/6852 -- loss: 2.9213085174560547\n",
      "2021-04-25 17:57:20,000 [INFO] Training: 6842/6852 -- loss: 1.9382225275039673\n",
      "2021-04-25 17:57:20,051 [INFO] Training: 6843/6852 -- loss: 1.2271971702575684\n",
      "2021-04-25 17:57:20,106 [INFO] Training: 6844/6852 -- loss: 2.0314059257507324\n",
      "2021-04-25 17:57:20,153 [INFO] Training: 6845/6852 -- loss: 1.617313265800476\n",
      "2021-04-25 17:57:20,200 [INFO] Training: 6846/6852 -- loss: 2.0533854961395264\n",
      "2021-04-25 17:57:20,253 [INFO] Training: 6847/6852 -- loss: 1.686218500137329\n",
      "2021-04-25 17:57:20,300 [INFO] Training: 6848/6852 -- loss: 2.5481083393096924\n",
      "2021-04-25 17:57:20,349 [INFO] Training: 6849/6852 -- loss: 1.9659351110458374\n",
      "2021-04-25 17:57:20,396 [INFO] Training: 6850/6852 -- loss: 2.3054699897766113\n",
      "2021-04-25 17:57:20,441 [INFO] Training: 6851/6852 -- loss: 1.4685637950897217\n",
      "2021-04-25 17:57:23,293 [INFO] Training: iteration: 6851/6852 -- epoch: 11 --  train_loss: 1.753 -- train_accuracy: 0.57 valid_loss: 3.287 -- valid_accuracy: 0.29\n",
      "2021-04-25 17:57:23,666 [INFO] Training: model saved to: ./models/model_12_epochs_last_train.pt\n",
      "2021-04-25 17:57:23,671 [INFO] Training: results saved to: ./results/resutls_12_epochs_last_train.pkl\n"
     ]
    }
   ],
   "source": [
    "traintest = TrainTest(model, optimizer, scheduler, F.nll_loss, logger)\n",
    "traintest.train(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    eval_interval,\n",
    "    model_path='./models/',\n",
    "    save_per_epoch=10,\n",
    "    results_path='./results/',\n",
    "    clip=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAz26kdhiX2O",
    "outputId": "77047bee-94ea-409d-df3e-944b4a66c7bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/models.py:58: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_logits = F.log_softmax(logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([209,  21,   0,  ...,   9, 211,  28])\n",
      "tensor([206,  68,  11,  ...,  11, 222,  43])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2021-04-25 18:01:19,870 [INFO] Training: results saved to: ./results/resutls_test.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: test_loss: 3.300 -- test_accurcy: 0.29 -- test_wups: 0.49\n"
     ]
    }
   ],
   "source": [
    "traintest.test(test_loader, device, label2word, results_path='./results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "id": "9VWUWEJNvQxn",
    "outputId": "09034386-5d51-4cfb-fb6d-98f5c1aab9f4"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_99ddbe60-21c7-46a0-9c11-bfe953fb4bd9\", \"results_10_epochs_train.pkl\", 2105)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_032d8d0a-3647-4b4a-9f3f-2624b9c7c6a3\", \"results_test.pkl\", 461257)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_e68c60fa-25ad-42dc-954f-af2715f12c08\", \"results_12_epochs_last_train.pkl\", 2497)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_dirs(['./results/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Z2dv2vPiO5c",
    "outputId": "af2883f7-cc72-4a9d-f673-195b1fe86977"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_accuracy': [0.0,\n",
       "  0.0,\n",
       "  0.125,\n",
       "  0.25,\n",
       "  0.25,\n",
       "  0.125,\n",
       "  0.0,\n",
       "  0.125,\n",
       "  0.0,\n",
       "  0.125,\n",
       "  0.25,\n",
       "  0.0,\n",
       "  0.25,\n",
       "  0.375,\n",
       "  0.25,\n",
       "  0.125,\n",
       "  0.625,\n",
       "  0.25,\n",
       "  0.5,\n",
       "  0.375,\n",
       "  0.25,\n",
       "  0.75,\n",
       "  0.125,\n",
       "  0.5,\n",
       "  0.375,\n",
       "  0.375,\n",
       "  0.25,\n",
       "  0.75,\n",
       "  0.25,\n",
       "  0.375,\n",
       "  0.25,\n",
       "  0.75,\n",
       "  0.5,\n",
       "  0.25,\n",
       "  0.75,\n",
       "  0.125,\n",
       "  0.5,\n",
       "  0.625,\n",
       "  0.625,\n",
       "  0.25,\n",
       "  0.625,\n",
       "  0.375,\n",
       "  0.75,\n",
       "  1.0,\n",
       "  0.25,\n",
       "  0.75,\n",
       "  0.5714285714285714],\n",
       " 'train_loss': [5.49746561050415,\n",
       "  4.549512939453125,\n",
       "  4.084267985026042,\n",
       "  3.784013264973958,\n",
       "  3.5651949055989585,\n",
       "  3.4850537109375,\n",
       "  3.2959336344401042,\n",
       "  3.3679276529947915,\n",
       "  3.2670263671875,\n",
       "  3.185530802408854,\n",
       "  3.0925,\n",
       "  3.0877278645833335,\n",
       "  2.886314697265625,\n",
       "  2.868921712239583,\n",
       "  2.795571492513021,\n",
       "  2.8647607421875,\n",
       "  2.726148885091146,\n",
       "  2.579697469075521,\n",
       "  2.5985858154296877,\n",
       "  2.7485972086588544,\n",
       "  2.3664036051432293,\n",
       "  2.476529337565104,\n",
       "  2.5094720458984376,\n",
       "  2.4417911783854165,\n",
       "  2.2969203694661458,\n",
       "  2.3583579508463544,\n",
       "  2.213961385091146,\n",
       "  2.1399751790364583,\n",
       "  2.1475677490234375,\n",
       "  2.153079833984375,\n",
       "  2.1282503255208334,\n",
       "  2.0666092936197917,\n",
       "  1.9261517333984375,\n",
       "  2.0478645833333333,\n",
       "  2.0136688232421873,\n",
       "  1.9021575927734375,\n",
       "  1.8738358561197916,\n",
       "  1.8915285237630208,\n",
       "  1.8736051432291667,\n",
       "  1.7476979573567708,\n",
       "  1.7511794026692709,\n",
       "  1.827780965169271,\n",
       "  1.7888199869791668,\n",
       "  1.6537210083007812,\n",
       "  1.6917942301432292,\n",
       "  1.7551444498697917,\n",
       "  1.7532193023379485],\n",
       " 'valid_accuracy': [0.029296875,\n",
       "  0.08984375,\n",
       "  0.15625,\n",
       "  0.15234375,\n",
       "  0.18359375,\n",
       "  0.201171875,\n",
       "  0.212890625,\n",
       "  0.185546875,\n",
       "  0.208984375,\n",
       "  0.22265625,\n",
       "  0.228515625,\n",
       "  0.26953125,\n",
       "  0.279296875,\n",
       "  0.232421875,\n",
       "  0.28515625,\n",
       "  0.26171875,\n",
       "  0.287109375,\n",
       "  0.302734375,\n",
       "  0.279296875,\n",
       "  0.294921875,\n",
       "  0.298828125,\n",
       "  0.287109375,\n",
       "  0.306640625,\n",
       "  0.291015625,\n",
       "  0.31640625,\n",
       "  0.296875,\n",
       "  0.298828125,\n",
       "  0.30078125,\n",
       "  0.2890625,\n",
       "  0.2890625,\n",
       "  0.296875,\n",
       "  0.310546875,\n",
       "  0.30859375,\n",
       "  0.291015625,\n",
       "  0.302734375,\n",
       "  0.2890625,\n",
       "  0.2890625,\n",
       "  0.298828125,\n",
       "  0.2890625,\n",
       "  0.29296875,\n",
       "  0.29296875,\n",
       "  0.291015625,\n",
       "  0.2890625,\n",
       "  0.30078125,\n",
       "  0.28515625,\n",
       "  0.29296875,\n",
       "  0.29296875],\n",
       " 'valid_loss': [5.4094557762146,\n",
       "  4.061524868011475,\n",
       "  3.823542594909668,\n",
       "  3.58734393119812,\n",
       "  3.527411460876465,\n",
       "  3.444693088531494,\n",
       "  3.387580394744873,\n",
       "  3.359874725341797,\n",
       "  3.2549099922180176,\n",
       "  3.24342942237854,\n",
       "  3.1549911499023438,\n",
       "  3.164034843444824,\n",
       "  3.1074798107147217,\n",
       "  3.154093027114868,\n",
       "  3.078976631164551,\n",
       "  3.0753884315490723,\n",
       "  3.088113307952881,\n",
       "  3.0573678016662598,\n",
       "  3.0125787258148193,\n",
       "  2.975970983505249,\n",
       "  3.016056776046753,\n",
       "  3.055936574935913,\n",
       "  3.0464274883270264,\n",
       "  3.04514217376709,\n",
       "  3.054990768432617,\n",
       "  3.0388197898864746,\n",
       "  3.0701966285705566,\n",
       "  3.108978509902954,\n",
       "  3.1113665103912354,\n",
       "  3.1118273735046387,\n",
       "  3.1253862380981445,\n",
       "  3.1330831050872803,\n",
       "  3.1968281269073486,\n",
       "  3.191056489944458,\n",
       "  3.1354730129241943,\n",
       "  3.21919322013855,\n",
       "  3.189883232116699,\n",
       "  3.180145025253296,\n",
       "  3.1850552558898926,\n",
       "  3.248554229736328,\n",
       "  3.247307300567627,\n",
       "  3.230273962020874,\n",
       "  3.292243003845215,\n",
       "  3.2821054458618164,\n",
       "  3.292189121246338,\n",
       "  3.282191753387451,\n",
       "  3.286936044692993]}"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.tr_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xe4mSn5ojNp1",
    "outputId": "c91cd914-b778-4267-d6f0-a76c6d0a2bb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0,\n",
       " '10': 1,\n",
       " '11': 2,\n",
       " '12': 3,\n",
       " '14': 4,\n",
       " '15': 5,\n",
       " '16': 6,\n",
       " '18': 7,\n",
       " '19': 8,\n",
       " '2': 9,\n",
       " '22': 10,\n",
       " '3': 11,\n",
       " '4': 12,\n",
       " '5': 13,\n",
       " '6': 14,\n",
       " '7': 15,\n",
       " '8': 16,\n",
       " '9': 17,\n",
       " 'alarm': 18,\n",
       " 'album': 19,\n",
       " 'backpack': 20,\n",
       " 'bag': 21,\n",
       " 'ball': 22,\n",
       " 'balloon': 23,\n",
       " 'banana': 24,\n",
       " 'banister': 25,\n",
       " 'basket': 26,\n",
       " 'bathtub': 27,\n",
       " 'bed': 28,\n",
       " 'belt': 29,\n",
       " 'bench': 30,\n",
       " 'bicycle': 31,\n",
       " 'bin': 32,\n",
       " 'binder': 33,\n",
       " 'black': 34,\n",
       " 'blackboard': 35,\n",
       " 'blanket': 36,\n",
       " 'blinds': 37,\n",
       " 'blue': 38,\n",
       " 'board': 39,\n",
       " 'book': 40,\n",
       " 'bookrack': 41,\n",
       " 'books': 42,\n",
       " 'bookshelf': 43,\n",
       " 'bottle': 44,\n",
       " 'bowl': 45,\n",
       " 'box': 46,\n",
       " 'bread': 47,\n",
       " 'brick': 48,\n",
       " 'briefcase': 49,\n",
       " 'broom': 50,\n",
       " 'brown': 51,\n",
       " 'bucket': 52,\n",
       " 'bulb': 53,\n",
       " 'cabinet': 54,\n",
       " 'cables': 55,\n",
       " 'calculator': 56,\n",
       " 'calendar': 57,\n",
       " 'can': 58,\n",
       " 'candelabra': 59,\n",
       " 'candle': 60,\n",
       " 'candlestick': 61,\n",
       " 'cane': 62,\n",
       " 'carton': 63,\n",
       " 'case': 64,\n",
       " 'cd': 65,\n",
       " 'ceiling': 66,\n",
       " 'certificate': 67,\n",
       " 'chair': 68,\n",
       " 'chandelier': 69,\n",
       " 'charger': 70,\n",
       " 'chart': 71,\n",
       " 'chessboard': 72,\n",
       " 'chest': 73,\n",
       " 'clock': 74,\n",
       " 'clothes': 75,\n",
       " 'column': 76,\n",
       " 'comforter': 77,\n",
       " 'computer': 78,\n",
       " 'container': 79,\n",
       " 'counter': 80,\n",
       " 'cradle': 81,\n",
       " 'cream': 82,\n",
       " 'crib': 83,\n",
       " 'cup': 84,\n",
       " 'curtain': 85,\n",
       " 'deoderant': 86,\n",
       " 'desk': 87,\n",
       " 'dishes': 88,\n",
       " 'dishwasher': 89,\n",
       " 'dog': 90,\n",
       " 'doll': 91,\n",
       " 'door': 92,\n",
       " 'drawer': 93,\n",
       " 'dresser': 94,\n",
       " 'dvd': 95,\n",
       " 'dvds': 96,\n",
       " 'eggplant': 97,\n",
       " 'envelope': 98,\n",
       " 'fan': 99,\n",
       " 'faucet': 100,\n",
       " 'file': 101,\n",
       " 'fireplace': 102,\n",
       " 'floor': 103,\n",
       " 'folder': 104,\n",
       " 'folders': 105,\n",
       " 'fruit': 106,\n",
       " 'glass': 107,\n",
       " 'globe': 108,\n",
       " 'gray': 109,\n",
       " 'green': 110,\n",
       " 'grill': 111,\n",
       " 'guitar': 112,\n",
       " 'hanger': 113,\n",
       " 'hangers': 114,\n",
       " 'hat': 115,\n",
       " 'heater': 116,\n",
       " 'hooks': 117,\n",
       " 'jacket': 118,\n",
       " 'jeans': 119,\n",
       " 'jersey': 120,\n",
       " 'jug': 121,\n",
       " 'juicer': 122,\n",
       " 'keyboard': 123,\n",
       " 'knife': 124,\n",
       " 'knob': 125,\n",
       " 'knobs': 126,\n",
       " 'ladder': 127,\n",
       " 'ladel': 128,\n",
       " 'lamp': 129,\n",
       " 'laptop': 130,\n",
       " 'lego': 131,\n",
       " 'light': 132,\n",
       " 'machine': 133,\n",
       " 'magazine': 134,\n",
       " 'magnet': 135,\n",
       " 'mantel': 136,\n",
       " 'map': 137,\n",
       " 'mask': 138,\n",
       " 'mattress': 139,\n",
       " 'medal': 140,\n",
       " 'microwave': 141,\n",
       " 'mirror': 142,\n",
       " 'modem': 143,\n",
       " 'monitor': 144,\n",
       " 'mouse': 145,\n",
       " 'nailclipper': 146,\n",
       " 'napkin': 147,\n",
       " 'newspapers': 148,\n",
       " 'notebook': 149,\n",
       " 'notecards': 150,\n",
       " 'orange': 151,\n",
       " 'ottoman': 152,\n",
       " 'oven': 153,\n",
       " 'paper': 154,\n",
       " 'papers': 155,\n",
       " 'pen': 156,\n",
       " 'pencil': 157,\n",
       " 'perfume': 158,\n",
       " 'person': 159,\n",
       " 'photo': 160,\n",
       " 'piano': 161,\n",
       " 'picture': 162,\n",
       " 'pillow': 163,\n",
       " 'pink': 164,\n",
       " 'pipe': 165,\n",
       " 'pitcher': 166,\n",
       " 'plant': 167,\n",
       " 'plate': 168,\n",
       " 'pot': 169,\n",
       " 'printer': 170,\n",
       " 'projector': 171,\n",
       " 'purple': 172,\n",
       " 'purse': 173,\n",
       " 'radiator': 174,\n",
       " 'radio': 175,\n",
       " 'railing': 176,\n",
       " 'red': 177,\n",
       " 'refridgerator': 178,\n",
       " 'router': 179,\n",
       " 'rug': 180,\n",
       " 'scale': 181,\n",
       " 'scissor': 182,\n",
       " 'shaver': 183,\n",
       " 'sheet': 184,\n",
       " 'sheets': 185,\n",
       " 'shelves': 186,\n",
       " 'shoe': 187,\n",
       " 'sign': 188,\n",
       " 'sink': 189,\n",
       " 'soap': 190,\n",
       " 'sofa': 191,\n",
       " 'speaker': 192,\n",
       " 'sponge': 193,\n",
       " 'stairs': 194,\n",
       " 'stamp': 195,\n",
       " 'stand': 196,\n",
       " 'stapler': 197,\n",
       " 'stick': 198,\n",
       " 'sticker': 199,\n",
       " 'stones': 200,\n",
       " 'stool': 201,\n",
       " 'stove': 202,\n",
       " 'stroller': 203,\n",
       " 'suitcase': 204,\n",
       " 'switchbox': 205,\n",
       " 'table': 206,\n",
       " 'tablecloth': 207,\n",
       " 'tape': 208,\n",
       " 'telephone': 209,\n",
       " 'telescope': 210,\n",
       " 'television': 211,\n",
       " 'tissue': 212,\n",
       " 'toaster': 213,\n",
       " 'toilet': 214,\n",
       " 'toiletries': 215,\n",
       " 'toothbrush': 216,\n",
       " 'toothpaste': 217,\n",
       " 'towel': 218,\n",
       " 'toy': 219,\n",
       " 'trampoline': 220,\n",
       " 'tray': 221,\n",
       " 'treadmill': 222,\n",
       " 'tricycle': 223,\n",
       " 'trolley': 224,\n",
       " 'tupperware': 225,\n",
       " 'typewriter': 226,\n",
       " 'umbrella': 227,\n",
       " 'utensil': 228,\n",
       " 'utensils': 229,\n",
       " 'vase': 230,\n",
       " 'vegetable': 231,\n",
       " 'vessel': 232,\n",
       " 'wall': 233,\n",
       " 'wardrobe': 234,\n",
       " 'white': 235,\n",
       " 'whiteboard': 236,\n",
       " 'window': 237,\n",
       " 'wire': 238,\n",
       " 'yellow': 239}"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jj-dK6DmJZ4U"
   },
   "outputs": [],
   "source": [
    "def report_results(\n",
    "    results_dir, train_results_file, eval_interval, just_train=False,\n",
    "    test_results_file=None, class_mapping=None, **kwargs\n",
    "):\n",
    "    with open(os.path.join(results_dir, train_results_file), 'rb') as results_file:\n",
    "        train_results = pickle.load(results_file)\n",
    "    iterations = [i*eval_interval for i in range(len(train_results['train_loss']))]\n",
    "    plt.plot(iterations, train_results['train_loss'], label=f'train loss')\n",
    "    plt.plot(iterations, train_results['valid_loss'], label=f'valid loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(results_dir, 'train-validation-loss.png'), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.figure()\n",
    "    plt.plot(iterations, train_results['train_accuracy'], label=f'train accuracy')\n",
    "    plt.plot(iterations, train_results['valid_accuracy'], label=f'valid accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(results_dir, 'train-validation-accuracy.png'), dpi=300, bbox_inches=\"tight\")\n",
    "    if not just_train:\n",
    "        with open(os.path.join(results_dir, test_results_file), 'rb') as results_file:\n",
    "            test_results = pickle.load(results_file)\n",
    "        class_mapping = sorted(\n",
    "            list(class_mapping.items()), key=lambda x: x[1]\n",
    "        )\n",
    "        classes = [x[0] for x in class_mapping]\n",
    "        plt.figure()\n",
    "        test_confm = pd.DataFrame(test_results['confusion_matrix'], classes, classes)\n",
    "        sn.set(font_scale=1)\n",
    "        sn.heatmap(\n",
    "            test_confm, \n",
    "            annot=kwargs['conf_annot'] if 'conf_annot' in kwargs else True, \n",
    "            annot_kws={\"size\": kwargs['font-size'] if 'font-size' in kwargs else 10}\n",
    "        )\n",
    "        plt.autoscale(True)\n",
    "        plt.savefig(os.path.join(results_dir, 'test-confusion-matrix.png'), dpi=300, bbox_inches=\"tight\")\n",
    "        print(f'{\"*\"*20} Test Metrics: {\"*\"*20}\\n'\n",
    "              f'Loss: {test_results[\"loss\"]:.3f}\\n'\n",
    "              f'Accuracy: {test_results[\"accuracy\"]:.3f}\\n'\n",
    "              f'WUPS: {test_results[\"wups\"]:.3f}\\n'\n",
    "              f'Weighted Precision: {test_results[\"precision\"]:.3f}\\n'\n",
    "              f'Weighted Recall: {test_results[\"recall\"]:.3f}\\n'\n",
    "              f'Weighted F1-score: {test_results[\"f1_score\"]:.3f}\\n'\n",
    "              f'{\"*\"*55}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Test Metrics: ********************\n",
      "Loss: 3.300\n",
      "Accuracy: 0.287\n",
      "WUPS: 0.493\n",
      "Weighted Precision: 0.242\n",
      "Weighted Recall: 0.287\n",
      "Weighted F1-score: 0.253\n",
      "*******************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_dir = 'VQA-results'\n",
    "test_results_file = 'results_test.pkl'\n",
    "train_results_file = 'results_12_epochs_last_train.pkl'\n",
    "report_results(\n",
    "    results_dir, train_results_file, eval_interval,\n",
    "    test_results_file=test_results_file,\n",
    "    class_mapping=dict(zip(range(len(answer_mapping)), range(len(answer_mapping)))), conf_annot=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vqa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
